{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# package-third-party-pandas\n",
    "> [TABLE OF CONTENTS](https://nbviewer.jupyter.org/github/SeanOhAileasa/fubar-python/blob/main/fubar-python.ipynb#top)\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- pandas - is a really useful library for investigating datasets - so its typically used in an interactive session with python - you type one pandas command - have a look at the output of that - and then maybe come up with another pandas commands to do some further analysis or investigation on a data set - and so typically - like the workflow for a data analyst is they receive a data set - they load the data set up in something like pandas - and they start digging around in the data set to see what is what - figure out the names of columns - and where the interesting data points might be within the set [2.5]\n",
    "\n",
    "\n",
    "- they come up with some workflow - some series of steps - that when you start with the raw data set - you can get to an interesting piece of information about the data set by taking the following steps such as - give me this column - then give me another column - multiply those two columns together - maybe add that result together - and then you get some metric that you might be interested in or something like that [2.5]\n",
    "\n",
    "\n",
    "- the work of a data analyst is initially to investigate the data set - then come up with the workflow - and once you go over the workflow - like if you think its a workflow that you will be doing again - might write a script that automates that workflow - so initially - you were digging around in the dataset with pandas - typing commands - waiting for the output - how to look at the output - and then deciding what to do next - but once you figure out all the steps that you want to take to get from your raw data set to the sort of output that you want - like maybe a report or something like that - typically then you write python scripts to automate that - as best you can - and sometimes once you automate it you no longer really require pandas - now - you can still use pandas in your script or whatever - but sometimes you can get away without having to import pandas and using the functionality in pandas - but either way - pandas is a great library for just looking at data sets - really sort of user friendly for the programer - as opposed to an end user and its really fast [2.5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- built on top of - numpy - provides an efficient implementation of a - DataFrame - essentially multidimensional arrays with attached row and column labels and often with heterogeneous - diverse in character or content - types and/or missing data - as well as offering a convenient storage interface for labeled data - implements a number of powerful data operations familiar to users of both database  frameworks and spreadsheet programs [9.97]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- numpy - data structure - ndarray - provides essential features for the type of clean well-organized data typically seen in numerical computing tasks - while it serves this purpose well - its limitations become clear with the need for more flexibility - attaching labels to data - working with missing data etc - and when attempting operations that do not map well to element-wise broadcasting - groupings - pivots etc - each of which is an important piece of analyzing the less structured data available [9.97]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- pandas - in particular its objects - Series - DataFrame - builds on the numpy array structure and provides efficient access to these sorts of - data munging - tasks that occupy much of a data scientist time [9.97]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# b_T_hird_P_arty-imports\n",
    "import pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "pandas - a powerful data analysis and manipulation library for Python\n",
      "=====================================================================\n",
      "\n",
      "**pandas** is a Python package providing fast, flexible, and expressive data\n",
      "structures designed to make working with \"relational\" or \"labeled\" data both\n",
      "easy and intuitive. It aims to be the fundamental high-level building block for\n",
      "doing practical, **real world** data analysis in Python. Additionally, it has\n",
      "the broader goal of becoming **the most powerful and flexible open source data\n",
      "analysis / manipulation tool available in any language**. It is already well on\n",
      "its way toward this goal.\n",
      "\n",
      "Main Features\n",
      "-------------\n",
      "Here are just a few of the things that pandas does well:\n",
      "\n",
      "  - Easy handling of missing data in floating point as well as non-floating\n",
      "    point data.\n",
      "  - Size mutability: columns can be inserted and deleted from DataFrame and\n",
      "    higher dimensional objects\n",
      "  - Automatic and explicit data alignment: objects can be explicitly aligned\n",
      "    to a set of labels, or the user can simply ignore the labels and let\n",
      "    `Series`, `DataFrame`, etc. automatically align the data for you in\n",
      "    computations.\n",
      "  - Powerful, flexible group by functionality to perform split-apply-combine\n",
      "    operations on data sets, for both aggregating and transforming data.\n",
      "  - Make it easy to convert ragged, differently-indexed data in other Python\n",
      "    and NumPy data structures into DataFrame objects.\n",
      "  - Intelligent label-based slicing, fancy indexing, and subsetting of large\n",
      "    data sets.\n",
      "  - Intuitive merging and joining data sets.\n",
      "  - Flexible reshaping and pivoting of data sets.\n",
      "  - Hierarchical labeling of axes (possible to have multiple labels per tick).\n",
      "  - Robust IO tools for loading data from flat files (CSV and delimited),\n",
      "    Excel files, databases, and saving/loading data from the ultrafast HDF5\n",
      "    format.\n",
      "  - Time series-specific functionality: date range generation and frequency\n",
      "    conversion, moving window statistics, date shifting and lagging.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# package pandas - attribute __doc__ - access\n",
    "print(pandas.__doc__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Kernel - Restart\n",
    "exit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# b_T_hird_P_arty-imports\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'pandas'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# package pandas alias pd - attribute __package__ - access\n",
    "pd.__package__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['C:\\\\Users\\\\E6985\\\\anaconda3\\\\lib\\\\site-packages\\\\pandas']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# package pandas alias pd - attribute __path__ - access\n",
    "pd.__path__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:\\\\Users\\\\E6985\\\\anaconda3\\\\lib\\\\site-packages\\\\pandas\\\\__init__.py'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# package pandas alias pd - attribute __file__ - access\n",
    "pd.__file__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.0.5'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# package pandas alias pd - attribute __version__ - access\n",
    "pd.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Kernel - Restart\n",
    "exit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# b_T_hird_P_arty-imports\n",
    "from pandas import _version as pdv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:\\\\Users\\\\E6985\\\\anaconda3\\\\lib\\\\site-packages\\\\pandas\\\\_version.py'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# package pandas - module _version alias pdv - attribute __file__ - access\n",
    "pdv.__file__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r\n",
      "# This file was generated by 'versioneer.py' (0.15) from\r\n",
      "# revision-control system data, or from the parent directory name of an\r\n",
      "# unpacked source archive. Distribution tarballs contain a pre-generated copy\r\n",
      "# of this file.\r\n",
      "\r\n",
      "from warnings import catch_warnings\r\n",
      "with catch_warnings(record=True):\r\n",
      "    import json\r\n",
      "import sys\r\n",
      "\r\n",
      "version_json = '''\r\n",
      "{\r\n",
      " \"dirty\": false,\r\n",
      " \"error\": null,\r\n",
      " \"full-revisionid\": \"b687cd4d9e520666a956a60849568a98dd00c672\",\r\n",
      " \"version\": \"1.0.5\"\r\n",
      "}\r\n",
      "'''  # END VERSION_JSON\r\n",
      "\r\n",
      "\r\n",
      "def get_versions():\r\n",
      "    return json.loads(version_json)\r\n"
     ]
    }
   ],
   "source": [
    "%%script bash\n",
    "cat ~/anaconda3/lib/site-packages/pandas/_version.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.0.5'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# package pandas - module _version alias pdv - function get_versions - call - json name - version - access\n",
    "pdv.get_versions()[\"version\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "# END"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
