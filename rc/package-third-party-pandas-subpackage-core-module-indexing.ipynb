{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# package-third-party-pandas-subpackage-core-module-indexing\n",
    "> [TABLE OF CONTENTS](https://nbviewer.jupyter.org/github/SeanOhAileasa/fubar-python/blob/main/fubar-python.ipynb#top)\n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# b_T_hird_P_arty-imports\n",
    "from pandas.core import indexing as idg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:\\\\Users\\\\E6985\\\\anaconda3\\\\lib\\\\site-packages\\\\pandas\\\\core\\\\indexing.py'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# package pandas - subpackage core - module indexing alias idg - attribute __file__ - access\n",
    "idg.__file__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "from typing import Hashable, List, Tuple, Union\n",
      "\n",
      "import numpy as np\n",
      "\n",
      "from pandas._libs.indexing import _NDFrameIndexerBase\n",
      "from pandas._libs.lib import item_from_zerodim\n",
      "from pandas.errors import AbstractMethodError\n",
      "from pandas.util._decorators import Appender\n",
      "\n",
      "from pandas.core.dtypes.common import (\n",
      "    is_float,\n",
      "    is_integer,\n",
      "    is_iterator,\n",
      "    is_list_like,\n",
      "    is_numeric_dtype,\n",
      "    is_object_dtype,\n",
      "    is_scalar,\n",
      "    is_sequence,\n",
      ")\n",
      "from pandas.core.dtypes.concat import concat_compat\n",
      "from pandas.core.dtypes.generic import ABCDataFrame, ABCMultiIndex, ABCSeries\n",
      "from pandas.core.dtypes.missing import _infer_fill_value, isna\n",
      "\n",
      "import pandas.core.common as com\n",
      "from pandas.core.indexers import (\n",
      "    check_array_indexer,\n",
      "    is_list_like_indexer,\n",
      "    length_of_indexer,\n",
      ")\n",
      "from pandas.core.indexes.api import Index, InvalidIndexError\n",
      "\n",
      "# \"null slice\"\n",
      "_NS = slice(None, None)\n",
      "\n",
      "\n",
      "# the public IndexSlicerMaker\n",
      "class _IndexSlice:\n",
      "    \"\"\"\n",
      "    Create an object to more easily perform multi-index slicing.\n",
      "\n",
      "    See Also\n",
      "    --------\n",
      "    MultiIndex.remove_unused_levels : New MultiIndex with no unused levels.\n",
      "\n",
      "    Notes\n",
      "    -----\n",
      "    See :ref:`Defined Levels <advanced.shown_levels>`\n",
      "    for further info on slicing a MultiIndex.\n",
      "\n",
      "    Examples\n",
      "    --------\n",
      "\n",
      "    >>> midx = pd.MultiIndex.from_product([['A0','A1'], ['B0','B1','B2','B3']])\n",
      "    >>> columns = ['foo', 'bar']\n",
      "    >>> dfmi = pd.DataFrame(np.arange(16).reshape((len(midx), len(columns))),\n",
      "                            index=midx, columns=columns)\n",
      "\n",
      "    Using the default slice command:\n",
      "\n",
      "    >>> dfmi.loc[(slice(None), slice('B0', 'B1')), :]\n",
      "               foo  bar\n",
      "        A0 B0    0    1\n",
      "           B1    2    3\n",
      "        A1 B0    8    9\n",
      "           B1   10   11\n",
      "\n",
      "    Using the IndexSlice class for a more intuitive command:\n",
      "\n",
      "    >>> idx = pd.IndexSlice\n",
      "    >>> dfmi.loc[idx[:, 'B0':'B1'], :]\n",
      "               foo  bar\n",
      "        A0 B0    0    1\n",
      "           B1    2    3\n",
      "        A1 B0    8    9\n",
      "           B1   10   11\n",
      "    \"\"\"\n",
      "\n",
      "    def __getitem__(self, arg):\n",
      "        return arg\n",
      "\n",
      "\n",
      "IndexSlice = _IndexSlice()\n",
      "\n",
      "\n",
      "class IndexingError(Exception):\n",
      "    pass\n",
      "\n",
      "\n",
      "class IndexingMixin:\n",
      "    \"\"\"Mixin for adding .loc/.iloc/.at/.iat to Datafames and Series.\n",
      "    \"\"\"\n",
      "\n",
      "    @property\n",
      "    def iloc(self) -> \"_iLocIndexer\":\n",
      "        \"\"\"\n",
      "        Purely integer-location based indexing for selection by position.\n",
      "\n",
      "        ``.iloc[]`` is primarily integer position based (from ``0`` to\n",
      "        ``length-1`` of the axis), but may also be used with a boolean\n",
      "        array.\n",
      "\n",
      "        Allowed inputs are:\n",
      "\n",
      "        - An integer, e.g. ``5``.\n",
      "        - A list or array of integers, e.g. ``[4, 3, 0]``.\n",
      "        - A slice object with ints, e.g. ``1:7``.\n",
      "        - A boolean array.\n",
      "        - A ``callable`` function with one argument (the calling Series or\n",
      "          DataFrame) and that returns valid output for indexing (one of the above).\n",
      "          This is useful in method chains, when you don't have a reference to the\n",
      "          calling object, but would like to base your selection on some value.\n",
      "\n",
      "        ``.iloc`` will raise ``IndexError`` if a requested indexer is\n",
      "        out-of-bounds, except *slice* indexers which allow out-of-bounds\n",
      "        indexing (this conforms with python/numpy *slice* semantics).\n",
      "\n",
      "        See more at :ref:`Selection by Position <indexing.integer>`.\n",
      "\n",
      "        See Also\n",
      "        --------\n",
      "        DataFrame.iat : Fast integer location scalar accessor.\n",
      "        DataFrame.loc : Purely label-location based indexer for selection by label.\n",
      "        Series.iloc : Purely integer-location based indexing for\n",
      "                       selection by position.\n",
      "\n",
      "        Examples\n",
      "        --------\n",
      "\n",
      "        >>> mydict = [{'a': 1, 'b': 2, 'c': 3, 'd': 4},\n",
      "        ...           {'a': 100, 'b': 200, 'c': 300, 'd': 400},\n",
      "        ...           {'a': 1000, 'b': 2000, 'c': 3000, 'd': 4000 }]\n",
      "        >>> df = pd.DataFrame(mydict)\n",
      "        >>> df\n",
      "              a     b     c     d\n",
      "        0     1     2     3     4\n",
      "        1   100   200   300   400\n",
      "        2  1000  2000  3000  4000\n",
      "\n",
      "        **Indexing just the rows**\n",
      "\n",
      "        With a scalar integer.\n",
      "\n",
      "        >>> type(df.iloc[0])\n",
      "        <class 'pandas.core.series.Series'>\n",
      "        >>> df.iloc[0]\n",
      "        a    1\n",
      "        b    2\n",
      "        c    3\n",
      "        d    4\n",
      "        Name: 0, dtype: int64\n",
      "\n",
      "        With a list of integers.\n",
      "\n",
      "        >>> df.iloc[[0]]\n",
      "           a  b  c  d\n",
      "        0  1  2  3  4\n",
      "        >>> type(df.iloc[[0]])\n",
      "        <class 'pandas.core.frame.DataFrame'>\n",
      "\n",
      "        >>> df.iloc[[0, 1]]\n",
      "             a    b    c    d\n",
      "        0    1    2    3    4\n",
      "        1  100  200  300  400\n",
      "\n",
      "        With a `slice` object.\n",
      "\n",
      "        >>> df.iloc[:3]\n",
      "              a     b     c     d\n",
      "        0     1     2     3     4\n",
      "        1   100   200   300   400\n",
      "        2  1000  2000  3000  4000\n",
      "\n",
      "        With a boolean mask the same length as the index.\n",
      "\n",
      "        >>> df.iloc[[True, False, True]]\n",
      "              a     b     c     d\n",
      "        0     1     2     3     4\n",
      "        2  1000  2000  3000  4000\n",
      "\n",
      "        With a callable, useful in method chains. The `x` passed\n",
      "        to the ``lambda`` is the DataFrame being sliced. This selects\n",
      "        the rows whose index label even.\n",
      "\n",
      "        >>> df.iloc[lambda x: x.index % 2 == 0]\n",
      "              a     b     c     d\n",
      "        0     1     2     3     4\n",
      "        2  1000  2000  3000  4000\n",
      "\n",
      "        **Indexing both axes**\n",
      "\n",
      "        You can mix the indexer types for the index and columns. Use ``:`` to\n",
      "        select the entire axis.\n",
      "\n",
      "        With scalar integers.\n",
      "\n",
      "        >>> df.iloc[0, 1]\n",
      "        2\n",
      "\n",
      "        With lists of integers.\n",
      "\n",
      "        >>> df.iloc[[0, 2], [1, 3]]\n",
      "              b     d\n",
      "        0     2     4\n",
      "        2  2000  4000\n",
      "\n",
      "        With `slice` objects.\n",
      "\n",
      "        >>> df.iloc[1:3, 0:3]\n",
      "              a     b     c\n",
      "        1   100   200   300\n",
      "        2  1000  2000  3000\n",
      "\n",
      "        With a boolean array whose length matches the columns.\n",
      "\n",
      "        >>> df.iloc[:, [True, False, True, False]]\n",
      "              a     c\n",
      "        0     1     3\n",
      "        1   100   300\n",
      "        2  1000  3000\n",
      "\n",
      "        With a callable function that expects the Series or DataFrame.\n",
      "\n",
      "        >>> df.iloc[:, lambda df: [0, 2]]\n",
      "              a     c\n",
      "        0     1     3\n",
      "        1   100   300\n",
      "        2  1000  3000\n",
      "        \"\"\"\n",
      "        return _iLocIndexer(\"iloc\", self)\n",
      "\n",
      "    @property\n",
      "    def loc(self) -> \"_LocIndexer\":\n",
      "        \"\"\"\n",
      "        Access a group of rows and columns by label(s) or a boolean array.\n",
      "\n",
      "        ``.loc[]`` is primarily label based, but may also be used with a\n",
      "        boolean array.\n",
      "\n",
      "        Allowed inputs are:\n",
      "\n",
      "        - A single label, e.g. ``5`` or ``'a'``, (note that ``5`` is\n",
      "          interpreted as a *label* of the index, and **never** as an\n",
      "          integer position along the index).\n",
      "        - A list or array of labels, e.g. ``['a', 'b', 'c']``.\n",
      "        - A slice object with labels, e.g. ``'a':'f'``.\n",
      "\n",
      "          .. warning:: Note that contrary to usual python slices, **both** the\n",
      "              start and the stop are included\n",
      "\n",
      "        - A boolean array of the same length as the axis being sliced,\n",
      "          e.g. ``[True, False, True]``.\n",
      "        - A ``callable`` function with one argument (the calling Series or\n",
      "          DataFrame) and that returns valid output for indexing (one of the above)\n",
      "\n",
      "        See more at :ref:`Selection by Label <indexing.label>`\n",
      "\n",
      "        Raises\n",
      "        ------\n",
      "        KeyError\n",
      "            If any items are not found.\n",
      "\n",
      "        See Also\n",
      "        --------\n",
      "        DataFrame.at : Access a single value for a row/column label pair.\n",
      "        DataFrame.iloc : Access group of rows and columns by integer position(s).\n",
      "        DataFrame.xs : Returns a cross-section (row(s) or column(s)) from the\n",
      "            Series/DataFrame.\n",
      "        Series.loc : Access group of values using labels.\n",
      "\n",
      "        Examples\n",
      "        --------\n",
      "        **Getting values**\n",
      "\n",
      "        >>> df = pd.DataFrame([[1, 2], [4, 5], [7, 8]],\n",
      "        ...      index=['cobra', 'viper', 'sidewinder'],\n",
      "        ...      columns=['max_speed', 'shield'])\n",
      "        >>> df\n",
      "                    max_speed  shield\n",
      "        cobra               1       2\n",
      "        viper               4       5\n",
      "        sidewinder          7       8\n",
      "\n",
      "        Single label. Note this returns the row as a Series.\n",
      "\n",
      "        >>> df.loc['viper']\n",
      "        max_speed    4\n",
      "        shield       5\n",
      "        Name: viper, dtype: int64\n",
      "\n",
      "        List of labels. Note using ``[[]]`` returns a DataFrame.\n",
      "\n",
      "        >>> df.loc[['viper', 'sidewinder']]\n",
      "                    max_speed  shield\n",
      "        viper               4       5\n",
      "        sidewinder          7       8\n",
      "\n",
      "        Single label for row and column\n",
      "\n",
      "        >>> df.loc['cobra', 'shield']\n",
      "        2\n",
      "\n",
      "        Slice with labels for row and single label for column. As mentioned\n",
      "        above, note that both the start and stop of the slice are included.\n",
      "\n",
      "        >>> df.loc['cobra':'viper', 'max_speed']\n",
      "        cobra    1\n",
      "        viper    4\n",
      "        Name: max_speed, dtype: int64\n",
      "\n",
      "        Boolean list with the same length as the row axis\n",
      "\n",
      "        >>> df.loc[[False, False, True]]\n",
      "                    max_speed  shield\n",
      "        sidewinder          7       8\n",
      "\n",
      "        Conditional that returns a boolean Series\n",
      "\n",
      "        >>> df.loc[df['shield'] > 6]\n",
      "                    max_speed  shield\n",
      "        sidewinder          7       8\n",
      "\n",
      "        Conditional that returns a boolean Series with column labels specified\n",
      "\n",
      "        >>> df.loc[df['shield'] > 6, ['max_speed']]\n",
      "                    max_speed\n",
      "        sidewinder          7\n",
      "\n",
      "        Callable that returns a boolean Series\n",
      "\n",
      "        >>> df.loc[lambda df: df['shield'] == 8]\n",
      "                    max_speed  shield\n",
      "        sidewinder          7       8\n",
      "\n",
      "        **Setting values**\n",
      "\n",
      "        Set value for all items matching the list of labels\n",
      "\n",
      "        >>> df.loc[['viper', 'sidewinder'], ['shield']] = 50\n",
      "        >>> df\n",
      "                    max_speed  shield\n",
      "        cobra               1       2\n",
      "        viper               4      50\n",
      "        sidewinder          7      50\n",
      "\n",
      "        Set value for an entire row\n",
      "\n",
      "        >>> df.loc['cobra'] = 10\n",
      "        >>> df\n",
      "                    max_speed  shield\n",
      "        cobra              10      10\n",
      "        viper               4      50\n",
      "        sidewinder          7      50\n",
      "\n",
      "        Set value for an entire column\n",
      "\n",
      "        >>> df.loc[:, 'max_speed'] = 30\n",
      "        >>> df\n",
      "                    max_speed  shield\n",
      "        cobra              30      10\n",
      "        viper              30      50\n",
      "        sidewinder         30      50\n",
      "\n",
      "        Set value for rows matching callable condition\n",
      "\n",
      "        >>> df.loc[df['shield'] > 35] = 0\n",
      "        >>> df\n",
      "                    max_speed  shield\n",
      "        cobra              30      10\n",
      "        viper               0       0\n",
      "        sidewinder          0       0\n",
      "\n",
      "        **Getting values on a DataFrame with an index that has integer labels**\n",
      "\n",
      "        Another example using integers for the index\n",
      "\n",
      "        >>> df = pd.DataFrame([[1, 2], [4, 5], [7, 8]],\n",
      "        ...      index=[7, 8, 9], columns=['max_speed', 'shield'])\n",
      "        >>> df\n",
      "           max_speed  shield\n",
      "        7          1       2\n",
      "        8          4       5\n",
      "        9          7       8\n",
      "\n",
      "        Slice with integer labels for rows. As mentioned above, note that both\n",
      "        the start and stop of the slice are included.\n",
      "\n",
      "        >>> df.loc[7:9]\n",
      "           max_speed  shield\n",
      "        7          1       2\n",
      "        8          4       5\n",
      "        9          7       8\n",
      "\n",
      "        **Getting values with a MultiIndex**\n",
      "\n",
      "        A number of examples using a DataFrame with a MultiIndex\n",
      "\n",
      "        >>> tuples = [\n",
      "        ...    ('cobra', 'mark i'), ('cobra', 'mark ii'),\n",
      "        ...    ('sidewinder', 'mark i'), ('sidewinder', 'mark ii'),\n",
      "        ...    ('viper', 'mark ii'), ('viper', 'mark iii')\n",
      "        ... ]\n",
      "        >>> index = pd.MultiIndex.from_tuples(tuples)\n",
      "        >>> values = [[12, 2], [0, 4], [10, 20],\n",
      "        ...         [1, 4], [7, 1], [16, 36]]\n",
      "        >>> df = pd.DataFrame(values, columns=['max_speed', 'shield'], index=index)\n",
      "        >>> df\n",
      "                             max_speed  shield\n",
      "        cobra      mark i           12       2\n",
      "                   mark ii           0       4\n",
      "        sidewinder mark i           10      20\n",
      "                   mark ii           1       4\n",
      "        viper      mark ii           7       1\n",
      "                   mark iii         16      36\n",
      "\n",
      "        Single label. Note this returns a DataFrame with a single index.\n",
      "\n",
      "        >>> df.loc['cobra']\n",
      "                 max_speed  shield\n",
      "        mark i          12       2\n",
      "        mark ii          0       4\n",
      "\n",
      "        Single index tuple. Note this returns a Series.\n",
      "\n",
      "        >>> df.loc[('cobra', 'mark ii')]\n",
      "        max_speed    0\n",
      "        shield       4\n",
      "        Name: (cobra, mark ii), dtype: int64\n",
      "\n",
      "        Single label for row and column. Similar to passing in a tuple, this\n",
      "        returns a Series.\n",
      "\n",
      "        >>> df.loc['cobra', 'mark i']\n",
      "        max_speed    12\n",
      "        shield        2\n",
      "        Name: (cobra, mark i), dtype: int64\n",
      "\n",
      "        Single tuple. Note using ``[[]]`` returns a DataFrame.\n",
      "\n",
      "        >>> df.loc[[('cobra', 'mark ii')]]\n",
      "                       max_speed  shield\n",
      "        cobra mark ii          0       4\n",
      "\n",
      "        Single tuple for the index with a single label for the column\n",
      "\n",
      "        >>> df.loc[('cobra', 'mark i'), 'shield']\n",
      "        2\n",
      "\n",
      "        Slice from index tuple to single label\n",
      "\n",
      "        >>> df.loc[('cobra', 'mark i'):'viper']\n",
      "                             max_speed  shield\n",
      "        cobra      mark i           12       2\n",
      "                   mark ii           0       4\n",
      "        sidewinder mark i           10      20\n",
      "                   mark ii           1       4\n",
      "        viper      mark ii           7       1\n",
      "                   mark iii         16      36\n",
      "\n",
      "        Slice from index tuple to index tuple\n",
      "\n",
      "        >>> df.loc[('cobra', 'mark i'):('viper', 'mark ii')]\n",
      "                            max_speed  shield\n",
      "        cobra      mark i          12       2\n",
      "                   mark ii          0       4\n",
      "        sidewinder mark i          10      20\n",
      "                   mark ii          1       4\n",
      "        viper      mark ii          7       1\n",
      "        \"\"\"\n",
      "        return _LocIndexer(\"loc\", self)\n",
      "\n",
      "    @property\n",
      "    def at(self) -> \"_AtIndexer\":\n",
      "        \"\"\"\n",
      "        Access a single value for a row/column label pair.\n",
      "\n",
      "        Similar to ``loc``, in that both provide label-based lookups. Use\n",
      "        ``at`` if you only need to get or set a single value in a DataFrame\n",
      "        or Series.\n",
      "\n",
      "        Raises\n",
      "        ------\n",
      "        KeyError\n",
      "            If 'label' does not exist in DataFrame.\n",
      "\n",
      "        See Also\n",
      "        --------\n",
      "        DataFrame.iat : Access a single value for a row/column pair by integer\n",
      "            position.\n",
      "        DataFrame.loc : Access a group of rows and columns by label(s).\n",
      "        Series.at : Access a single value using a label.\n",
      "\n",
      "        Examples\n",
      "        --------\n",
      "        >>> df = pd.DataFrame([[0, 2, 3], [0, 4, 1], [10, 20, 30]],\n",
      "        ...                   index=[4, 5, 6], columns=['A', 'B', 'C'])\n",
      "        >>> df\n",
      "            A   B   C\n",
      "        4   0   2   3\n",
      "        5   0   4   1\n",
      "        6  10  20  30\n",
      "\n",
      "        Get value at specified row/column pair\n",
      "\n",
      "        >>> df.at[4, 'B']\n",
      "        2\n",
      "\n",
      "        Set value at specified row/column pair\n",
      "\n",
      "        >>> df.at[4, 'B'] = 10\n",
      "        >>> df.at[4, 'B']\n",
      "        10\n",
      "\n",
      "        Get value within a Series\n",
      "\n",
      "        >>> df.loc[5].at['B']\n",
      "        4\n",
      "        \"\"\"\n",
      "        return _AtIndexer(\"at\", self)\n",
      "\n",
      "    @property\n",
      "    def iat(self) -> \"_iAtIndexer\":\n",
      "        \"\"\"\n",
      "        Access a single value for a row/column pair by integer position.\n",
      "\n",
      "        Similar to ``iloc``, in that both provide integer-based lookups. Use\n",
      "        ``iat`` if you only need to get or set a single value in a DataFrame\n",
      "        or Series.\n",
      "\n",
      "        Raises\n",
      "        ------\n",
      "        IndexError\n",
      "            When integer position is out of bounds.\n",
      "\n",
      "        See Also\n",
      "        --------\n",
      "        DataFrame.at : Access a single value for a row/column label pair.\n",
      "        DataFrame.loc : Access a group of rows and columns by label(s).\n",
      "        DataFrame.iloc : Access a group of rows and columns by integer position(s).\n",
      "\n",
      "        Examples\n",
      "        --------\n",
      "        >>> df = pd.DataFrame([[0, 2, 3], [0, 4, 1], [10, 20, 30]],\n",
      "        ...                   columns=['A', 'B', 'C'])\n",
      "        >>> df\n",
      "            A   B   C\n",
      "        0   0   2   3\n",
      "        1   0   4   1\n",
      "        2  10  20  30\n",
      "\n",
      "        Get value at specified row/column pair\n",
      "\n",
      "        >>> df.iat[1, 2]\n",
      "        1\n",
      "\n",
      "        Set value at specified row/column pair\n",
      "\n",
      "        >>> df.iat[1, 2] = 10\n",
      "        >>> df.iat[1, 2]\n",
      "        10\n",
      "\n",
      "        Get value within a series\n",
      "\n",
      "        >>> df.loc[0].iat[1]\n",
      "        2\n",
      "        \"\"\"\n",
      "        return _iAtIndexer(\"iat\", self)\n",
      "\n",
      "\n",
      "class _NDFrameIndexer(_NDFrameIndexerBase):\n",
      "    _valid_types: str\n",
      "    axis = None\n",
      "\n",
      "    def __call__(self, axis=None):\n",
      "        # we need to return a copy of ourselves\n",
      "        new_self = type(self)(self.name, self.obj)\n",
      "\n",
      "        if axis is not None:\n",
      "            axis = self.obj._get_axis_number(axis)\n",
      "        new_self.axis = axis\n",
      "        return new_self\n",
      "\n",
      "    # TODO: remove once geopandas no longer needs this\n",
      "    def __getitem__(self, key):\n",
      "        # Used in ix and downstream in geopandas _CoordinateIndexer\n",
      "        if type(key) is tuple:\n",
      "            # Note: we check the type exactly instead of with isinstance\n",
      "            #  because NamedTuple is checked separately.\n",
      "            key = tuple(com.apply_if_callable(x, self.obj) for x in key)\n",
      "            try:\n",
      "                values = self.obj._get_value(*key)\n",
      "            except (KeyError, TypeError, InvalidIndexError, AttributeError):\n",
      "                # TypeError occurs here if the key has non-hashable entries,\n",
      "                #  generally slice or list.\n",
      "                # TODO(ix): most/all of the TypeError cases here are for ix,\n",
      "                #  so this check can be removed once ix is removed.\n",
      "                # The InvalidIndexError is only catched for compatibility\n",
      "                #  with geopandas, see\n",
      "                #  https://github.com/pandas-dev/pandas/issues/27258\n",
      "                # TODO: The AttributeError is for IntervalIndex which\n",
      "                #  incorrectly implements get_value, see\n",
      "                #  https://github.com/pandas-dev/pandas/issues/27865\n",
      "                pass\n",
      "            else:\n",
      "                if is_scalar(values):\n",
      "                    return values\n",
      "\n",
      "            return self._getitem_tuple(key)\n",
      "        else:\n",
      "            # we by definition only have the 0th axis\n",
      "            axis = self.axis or 0\n",
      "\n",
      "            key = com.apply_if_callable(key, self.obj)\n",
      "            return self._getitem_axis(key, axis=axis)\n",
      "\n",
      "    def _get_label(self, label, axis: int):\n",
      "        if self.ndim == 1:\n",
      "            # for perf reasons we want to try _xs first\n",
      "            # as its basically direct indexing\n",
      "            # but will fail when the index is not present\n",
      "            # see GH5667\n",
      "            return self.obj._xs(label, axis=axis)\n",
      "        elif isinstance(label, tuple) and isinstance(label[axis], slice):\n",
      "            raise IndexingError(\"no slices here, handle elsewhere\")\n",
      "\n",
      "        return self.obj._xs(label, axis=axis)\n",
      "\n",
      "    def _get_loc(self, key: int, axis: int):\n",
      "        return self.obj._ixs(key, axis=axis)\n",
      "\n",
      "    def _slice(self, obj, axis: int, kind=None):\n",
      "        return self.obj._slice(obj, axis=axis, kind=kind)\n",
      "\n",
      "    def _get_setitem_indexer(self, key):\n",
      "        if self.axis is not None:\n",
      "            return self._convert_tuple(key)\n",
      "\n",
      "        ax = self.obj._get_axis(0)\n",
      "\n",
      "        if isinstance(ax, ABCMultiIndex) and self.name != \"iloc\":\n",
      "            try:\n",
      "                return ax.get_loc(key)\n",
      "            except (TypeError, KeyError, InvalidIndexError):\n",
      "                # TypeError e.g. passed a bool\n",
      "                pass\n",
      "\n",
      "        if isinstance(key, tuple):\n",
      "            try:\n",
      "                return self._convert_tuple(key)\n",
      "            except IndexingError:\n",
      "                pass\n",
      "\n",
      "        if isinstance(key, range):\n",
      "            return list(key)\n",
      "\n",
      "        axis = self.axis or 0\n",
      "        try:\n",
      "            return self._convert_to_indexer(key, axis=axis)\n",
      "        except TypeError as e:\n",
      "\n",
      "            # invalid indexer type vs 'other' indexing errors\n",
      "            if \"cannot do\" in str(e):\n",
      "                raise\n",
      "            raise IndexingError(key)\n",
      "\n",
      "    def __setitem__(self, key, value):\n",
      "        if isinstance(key, tuple):\n",
      "            key = tuple(com.apply_if_callable(x, self.obj) for x in key)\n",
      "        else:\n",
      "            key = com.apply_if_callable(key, self.obj)\n",
      "        indexer = self._get_setitem_indexer(key)\n",
      "        self._setitem_with_indexer(indexer, value)\n",
      "\n",
      "    def _validate_key(self, key, axis: int):\n",
      "        \"\"\"\n",
      "        Ensure that key is valid for current indexer.\n",
      "\n",
      "        Parameters\n",
      "        ----------\n",
      "        key : scalar, slice or list-like\n",
      "            Key requested.\n",
      "        axis : int\n",
      "            Dimension on which the indexing is being made.\n",
      "\n",
      "        Raises\n",
      "        ------\n",
      "        TypeError\n",
      "            If the key (or some element of it) has wrong type.\n",
      "        IndexError\n",
      "            If the key (or some element of it) is out of bounds.\n",
      "        KeyError\n",
      "            If the key was not found.\n",
      "        \"\"\"\n",
      "        raise AbstractMethodError(self)\n",
      "\n",
      "    def _has_valid_tuple(self, key: Tuple):\n",
      "        \"\"\"\n",
      "        Check the key for valid keys across my indexer.\n",
      "        \"\"\"\n",
      "        for i, k in enumerate(key):\n",
      "            if i >= self.ndim:\n",
      "                raise IndexingError(\"Too many indexers\")\n",
      "            try:\n",
      "                self._validate_key(k, i)\n",
      "            except ValueError:\n",
      "                raise ValueError(\n",
      "                    \"Location based indexing can only have \"\n",
      "                    f\"[{self._valid_types}] types\"\n",
      "                )\n",
      "\n",
      "    def _is_nested_tuple_indexer(self, tup: Tuple) -> bool:\n",
      "        \"\"\"\n",
      "        Returns\n",
      "        -------\n",
      "        bool\n",
      "        \"\"\"\n",
      "        if any(isinstance(ax, ABCMultiIndex) for ax in self.obj.axes):\n",
      "            return any(is_nested_tuple(tup, ax) for ax in self.obj.axes)\n",
      "        return False\n",
      "\n",
      "    def _convert_tuple(self, key):\n",
      "        keyidx = []\n",
      "        if self.axis is not None:\n",
      "            axis = self.obj._get_axis_number(self.axis)\n",
      "            for i in range(self.ndim):\n",
      "                if i == axis:\n",
      "                    keyidx.append(self._convert_to_indexer(key, axis=axis))\n",
      "                else:\n",
      "                    keyidx.append(slice(None))\n",
      "        else:\n",
      "            for i, k in enumerate(key):\n",
      "                if i >= self.ndim:\n",
      "                    raise IndexingError(\"Too many indexers\")\n",
      "                idx = self._convert_to_indexer(k, axis=i)\n",
      "                keyidx.append(idx)\n",
      "        return tuple(keyidx)\n",
      "\n",
      "    def _convert_scalar_indexer(self, key, axis: int):\n",
      "        # if we are accessing via lowered dim, use the last dim\n",
      "        ax = self.obj._get_axis(min(axis, self.ndim - 1))\n",
      "        # a scalar\n",
      "        return ax._convert_scalar_indexer(key, kind=self.name)\n",
      "\n",
      "    def _convert_slice_indexer(self, key: slice, axis: int):\n",
      "        # if we are accessing via lowered dim, use the last dim\n",
      "        ax = self.obj._get_axis(min(axis, self.ndim - 1))\n",
      "        return ax._convert_slice_indexer(key, kind=self.name)\n",
      "\n",
      "    def _has_valid_setitem_indexer(self, indexer) -> bool:\n",
      "        return True\n",
      "\n",
      "    def _has_valid_positional_setitem_indexer(self, indexer) -> bool:\n",
      "        \"\"\"\n",
      "        Validate that a positional indexer cannot enlarge its target\n",
      "        will raise if needed, does not modify the indexer externally.\n",
      "\n",
      "        Returns\n",
      "        -------\n",
      "        bool\n",
      "        \"\"\"\n",
      "        if isinstance(indexer, dict):\n",
      "            raise IndexError(f\"{self.name} cannot enlarge its target object\")\n",
      "        else:\n",
      "            if not isinstance(indexer, tuple):\n",
      "                indexer = _tuplify(self.ndim, indexer)\n",
      "            for ax, i in zip(self.obj.axes, indexer):\n",
      "                if isinstance(i, slice):\n",
      "                    # should check the stop slice?\n",
      "                    pass\n",
      "                elif is_list_like_indexer(i):\n",
      "                    # should check the elements?\n",
      "                    pass\n",
      "                elif is_integer(i):\n",
      "                    if i >= len(ax):\n",
      "                        raise IndexError(\n",
      "                            f\"{self.name} cannot enlarge its target object\"\n",
      "                        )\n",
      "                elif isinstance(i, dict):\n",
      "                    raise IndexError(f\"{self.name} cannot enlarge its target object\")\n",
      "\n",
      "        return True\n",
      "\n",
      "    def _setitem_with_indexer(self, indexer, value):\n",
      "        self._has_valid_setitem_indexer(indexer)\n",
      "\n",
      "        # also has the side effect of consolidating in-place\n",
      "        from pandas import Series\n",
      "\n",
      "        info_axis = self.obj._info_axis_number\n",
      "\n",
      "        # maybe partial set\n",
      "        take_split_path = self.obj._is_mixed_type\n",
      "\n",
      "        # if there is only one block/type, still have to take split path\n",
      "        # unless the block is one-dimensional or it can hold the value\n",
      "        if not take_split_path and self.obj._data.blocks:\n",
      "            (blk,) = self.obj._data.blocks\n",
      "            if 1 < blk.ndim:  # in case of dict, keys are indices\n",
      "                val = list(value.values()) if isinstance(value, dict) else value\n",
      "                take_split_path = not blk._can_hold_element(val)\n",
      "\n",
      "        # if we have any multi-indexes that have non-trivial slices\n",
      "        # (not null slices) then we must take the split path, xref\n",
      "        # GH 10360, GH 27841\n",
      "        if isinstance(indexer, tuple) and len(indexer) == len(self.obj.axes):\n",
      "            for i, ax in zip(indexer, self.obj.axes):\n",
      "                if isinstance(ax, ABCMultiIndex) and not (\n",
      "                    is_integer(i) or com.is_null_slice(i)\n",
      "                ):\n",
      "                    take_split_path = True\n",
      "                    break\n",
      "\n",
      "        if isinstance(indexer, tuple):\n",
      "            nindexer = []\n",
      "            for i, idx in enumerate(indexer):\n",
      "                if isinstance(idx, dict):\n",
      "\n",
      "                    # reindex the axis to the new value\n",
      "                    # and set inplace\n",
      "                    key, _ = convert_missing_indexer(idx)\n",
      "\n",
      "                    # if this is the items axes, then take the main missing\n",
      "                    # path first\n",
      "                    # this correctly sets the dtype and avoids cache issues\n",
      "                    # essentially this separates out the block that is needed\n",
      "                    # to possibly be modified\n",
      "                    if self.ndim > 1 and i == self.obj._info_axis_number:\n",
      "\n",
      "                        # add the new item, and set the value\n",
      "                        # must have all defined axes if we have a scalar\n",
      "                        # or a list-like on the non-info axes if we have a\n",
      "                        # list-like\n",
      "                        len_non_info_axes = (\n",
      "                            len(_ax) for _i, _ax in enumerate(self.obj.axes) if _i != i\n",
      "                        )\n",
      "                        if any(not l for l in len_non_info_axes):\n",
      "                            if not is_list_like_indexer(value):\n",
      "                                raise ValueError(\n",
      "                                    \"cannot set a frame with no \"\n",
      "                                    \"defined index and a scalar\"\n",
      "                                )\n",
      "                            self.obj[key] = value\n",
      "                            return self.obj\n",
      "\n",
      "                        # add a new item with the dtype setup\n",
      "                        self.obj[key] = _infer_fill_value(value)\n",
      "\n",
      "                        new_indexer = convert_from_missing_indexer_tuple(\n",
      "                            indexer, self.obj.axes\n",
      "                        )\n",
      "                        self._setitem_with_indexer(new_indexer, value)\n",
      "\n",
      "                        return self.obj\n",
      "\n",
      "                    # reindex the axis\n",
      "                    # make sure to clear the cache because we are\n",
      "                    # just replacing the block manager here\n",
      "                    # so the object is the same\n",
      "                    index = self.obj._get_axis(i)\n",
      "                    labels = index.insert(len(index), key)\n",
      "                    self.obj._data = self.obj.reindex(labels, axis=i)._data\n",
      "                    self.obj._maybe_update_cacher(clear=True)\n",
      "                    self.obj._is_copy = None\n",
      "\n",
      "                    nindexer.append(labels.get_loc(key))\n",
      "\n",
      "                else:\n",
      "                    nindexer.append(idx)\n",
      "\n",
      "            indexer = tuple(nindexer)\n",
      "        else:\n",
      "\n",
      "            indexer, missing = convert_missing_indexer(indexer)\n",
      "\n",
      "            if missing:\n",
      "                return self._setitem_with_indexer_missing(indexer, value)\n",
      "\n",
      "        # set\n",
      "        item_labels = self.obj._get_axis(info_axis)\n",
      "\n",
      "        # align and set the values\n",
      "        if take_split_path:\n",
      "            # Above we only set take_split_path to True for 2D cases\n",
      "            assert self.ndim == 2\n",
      "            assert info_axis == 1\n",
      "\n",
      "            if not isinstance(indexer, tuple):\n",
      "                indexer = _tuplify(self.ndim, indexer)\n",
      "\n",
      "            if isinstance(value, ABCSeries):\n",
      "                value = self._align_series(indexer, value)\n",
      "\n",
      "            info_idx = indexer[info_axis]\n",
      "            if is_integer(info_idx):\n",
      "                info_idx = [info_idx]\n",
      "            labels = item_labels[info_idx]\n",
      "\n",
      "            # if we have a partial multiindex, then need to adjust the plane\n",
      "            # indexer here\n",
      "            if len(labels) == 1 and isinstance(\n",
      "                self.obj[labels[0]].axes[0], ABCMultiIndex\n",
      "            ):\n",
      "                item = labels[0]\n",
      "                obj = self.obj[item]\n",
      "                index = obj.index\n",
      "                idx = indexer[:info_axis][0]\n",
      "\n",
      "                plane_indexer = tuple([idx]) + indexer[info_axis + 1 :]\n",
      "                lplane_indexer = length_of_indexer(plane_indexer[0], index)\n",
      "\n",
      "                # require that we are setting the right number of values that\n",
      "                # we are indexing\n",
      "                if (\n",
      "                    is_list_like_indexer(value)\n",
      "                    and np.iterable(value)\n",
      "                    and lplane_indexer != len(value)\n",
      "                ):\n",
      "\n",
      "                    if len(obj[idx]) != len(value):\n",
      "                        raise ValueError(\n",
      "                            \"cannot set using a multi-index \"\n",
      "                            \"selection indexer with a different \"\n",
      "                            \"length than the value\"\n",
      "                        )\n",
      "\n",
      "                    # make sure we have an ndarray\n",
      "                    value = getattr(value, \"values\", value).ravel()\n",
      "\n",
      "                    # we can directly set the series here\n",
      "                    # as we select a slice indexer on the mi\n",
      "                    if isinstance(idx, slice):\n",
      "                        idx = index._convert_slice_indexer(idx)\n",
      "                    obj._consolidate_inplace()\n",
      "                    obj = obj.copy()\n",
      "                    obj._data = obj._data.setitem(indexer=tuple([idx]), value=value)\n",
      "                    self.obj[item] = obj\n",
      "                    return\n",
      "\n",
      "            # non-mi\n",
      "            else:\n",
      "                plane_indexer = indexer[:info_axis] + indexer[info_axis + 1 :]\n",
      "                plane_axis = self.obj.axes[:info_axis][0]\n",
      "                lplane_indexer = length_of_indexer(plane_indexer[0], plane_axis)\n",
      "\n",
      "            def setter(item, v):\n",
      "                s = self.obj[item]\n",
      "                pi = plane_indexer[0] if lplane_indexer == 1 else plane_indexer\n",
      "\n",
      "                # perform the equivalent of a setitem on the info axis\n",
      "                # as we have a null slice or a slice with full bounds\n",
      "                # which means essentially reassign to the columns of a\n",
      "                # multi-dim object\n",
      "                # GH6149 (null slice), GH10408 (full bounds)\n",
      "                if isinstance(pi, tuple) and all(\n",
      "                    com.is_null_slice(idx) or com.is_full_slice(idx, len(self.obj))\n",
      "                    for idx in pi\n",
      "                ):\n",
      "                    s = v\n",
      "                else:\n",
      "                    # set the item, possibly having a dtype change\n",
      "                    s._consolidate_inplace()\n",
      "                    s = s.copy()\n",
      "                    s._data = s._data.setitem(indexer=pi, value=v)\n",
      "                    s._maybe_update_cacher(clear=True)\n",
      "\n",
      "                # reset the sliced object if unique\n",
      "                self.obj[item] = s\n",
      "\n",
      "            # we need an iterable, with a ndim of at least 1\n",
      "            # eg. don't pass through np.array(0)\n",
      "            if is_list_like_indexer(value) and getattr(value, \"ndim\", 1) > 0:\n",
      "\n",
      "                # we have an equal len Frame\n",
      "                if isinstance(value, ABCDataFrame):\n",
      "                    sub_indexer = list(indexer)\n",
      "                    multiindex_indexer = isinstance(labels, ABCMultiIndex)\n",
      "\n",
      "                    for item in labels:\n",
      "                        if item in value:\n",
      "                            sub_indexer[info_axis] = item\n",
      "                            v = self._align_series(\n",
      "                                tuple(sub_indexer), value[item], multiindex_indexer\n",
      "                            )\n",
      "                        else:\n",
      "                            v = np.nan\n",
      "\n",
      "                        setter(item, v)\n",
      "\n",
      "                # we have an equal len ndarray/convertible to our labels\n",
      "                # hasattr first, to avoid coercing to ndarray without reason.\n",
      "                # But we may be relying on the ndarray coercion to check ndim.\n",
      "                # Why not just convert to an ndarray earlier on if needed?\n",
      "                elif np.ndim(value) == 2:\n",
      "\n",
      "                    # note that this coerces the dtype if we are mixed\n",
      "                    # GH 7551\n",
      "                    value = np.array(value, dtype=object)\n",
      "                    if len(labels) != value.shape[1]:\n",
      "                        raise ValueError(\n",
      "                            \"Must have equal len keys and value \"\n",
      "                            \"when setting with an ndarray\"\n",
      "                        )\n",
      "\n",
      "                    for i, item in enumerate(labels):\n",
      "\n",
      "                        # setting with a list, recoerces\n",
      "                        setter(item, value[:, i].tolist())\n",
      "\n",
      "                # we have an equal len list/ndarray\n",
      "                elif _can_do_equal_len(\n",
      "                    labels, value, plane_indexer, lplane_indexer, self.obj\n",
      "                ):\n",
      "                    setter(labels[0], value)\n",
      "\n",
      "                # per label values\n",
      "                else:\n",
      "\n",
      "                    if len(labels) != len(value):\n",
      "                        raise ValueError(\n",
      "                            \"Must have equal len keys and value \"\n",
      "                            \"when setting with an iterable\"\n",
      "                        )\n",
      "\n",
      "                    for item, v in zip(labels, value):\n",
      "                        setter(item, v)\n",
      "            else:\n",
      "\n",
      "                # scalar\n",
      "                for item in labels:\n",
      "                    setter(item, value)\n",
      "\n",
      "        else:\n",
      "            if isinstance(indexer, tuple):\n",
      "                indexer = maybe_convert_ix(*indexer)\n",
      "\n",
      "                # if we are setting on the info axis ONLY\n",
      "                # set using those methods to avoid block-splitting\n",
      "                # logic here\n",
      "                if (\n",
      "                    len(indexer) > info_axis\n",
      "                    and is_integer(indexer[info_axis])\n",
      "                    and all(\n",
      "                        com.is_null_slice(idx)\n",
      "                        for i, idx in enumerate(indexer)\n",
      "                        if i != info_axis\n",
      "                    )\n",
      "                    and item_labels.is_unique\n",
      "                ):\n",
      "                    self.obj[item_labels[indexer[info_axis]]] = value\n",
      "                    return\n",
      "\n",
      "            if isinstance(value, (ABCSeries, dict)):\n",
      "                # TODO(EA): ExtensionBlock.setitem this causes issues with\n",
      "                # setting for extensionarrays that store dicts. Need to decide\n",
      "                # if it's worth supporting that.\n",
      "                value = self._align_series(indexer, Series(value))\n",
      "\n",
      "            elif isinstance(value, ABCDataFrame):\n",
      "                value = self._align_frame(indexer, value)\n",
      "\n",
      "            # check for chained assignment\n",
      "            self.obj._check_is_chained_assignment_possible()\n",
      "\n",
      "            # actually do the set\n",
      "            self.obj._consolidate_inplace()\n",
      "            self.obj._data = self.obj._data.setitem(indexer=indexer, value=value)\n",
      "            self.obj._maybe_update_cacher(clear=True)\n",
      "\n",
      "    def _setitem_with_indexer_missing(self, indexer, value):\n",
      "        \"\"\"\n",
      "        Insert new row(s) or column(s) into the Series or DataFrame.\n",
      "        \"\"\"\n",
      "        from pandas import Series\n",
      "\n",
      "        # reindex the axis to the new value\n",
      "        # and set inplace\n",
      "        if self.ndim == 1:\n",
      "            index = self.obj.index\n",
      "            new_index = index.insert(len(index), indexer)\n",
      "\n",
      "            # we have a coerced indexer, e.g. a float\n",
      "            # that matches in an Int64Index, so\n",
      "            # we will not create a duplicate index, rather\n",
      "            # index to that element\n",
      "            # e.g. 0.0 -> 0\n",
      "            # GH#12246\n",
      "            if index.is_unique:\n",
      "                new_indexer = index.get_indexer([new_index[-1]])\n",
      "                if (new_indexer != -1).any():\n",
      "                    return self._setitem_with_indexer(new_indexer, value)\n",
      "\n",
      "            # this preserves dtype of the value\n",
      "            new_values = Series([value])._values\n",
      "            if len(self.obj._values):\n",
      "                # GH#22717 handle casting compatibility that np.concatenate\n",
      "                #  does incorrectly\n",
      "                new_values = concat_compat([self.obj._values, new_values])\n",
      "            self.obj._data = self.obj._constructor(\n",
      "                new_values, index=new_index, name=self.obj.name\n",
      "            )._data\n",
      "            self.obj._maybe_update_cacher(clear=True)\n",
      "            return self.obj\n",
      "\n",
      "        elif self.ndim == 2:\n",
      "\n",
      "            if not len(self.obj.columns):\n",
      "                # no columns and scalar\n",
      "                raise ValueError(\"cannot set a frame with no defined columns\")\n",
      "\n",
      "            if isinstance(value, ABCSeries):\n",
      "                # append a Series\n",
      "                value = value.reindex(index=self.obj.columns, copy=True)\n",
      "                value.name = indexer\n",
      "\n",
      "            else:\n",
      "                # a list-list\n",
      "                if is_list_like_indexer(value):\n",
      "                    # must have conforming columns\n",
      "                    if len(value) != len(self.obj.columns):\n",
      "                        raise ValueError(\"cannot set a row with mismatched columns\")\n",
      "\n",
      "                value = Series(value, index=self.obj.columns, name=indexer)\n",
      "\n",
      "            self.obj._data = self.obj.append(value)._data\n",
      "            self.obj._maybe_update_cacher(clear=True)\n",
      "            return self.obj\n",
      "\n",
      "    def _align_series(self, indexer, ser: ABCSeries, multiindex_indexer: bool = False):\n",
      "        \"\"\"\n",
      "        Parameters\n",
      "        ----------\n",
      "        indexer : tuple, slice, scalar\n",
      "            Indexer used to get the locations that will be set to `ser`.\n",
      "        ser : pd.Series\n",
      "            Values to assign to the locations specified by `indexer`.\n",
      "        multiindex_indexer : boolean, optional\n",
      "            Defaults to False. Should be set to True if `indexer` was from\n",
      "            a `pd.MultiIndex`, to avoid unnecessary broadcasting.\n",
      "\n",
      "        Returns\n",
      "        -------\n",
      "        `np.array` of `ser` broadcast to the appropriate shape for assignment\n",
      "        to the locations selected by `indexer`\n",
      "        \"\"\"\n",
      "        if isinstance(indexer, (slice, np.ndarray, list, Index)):\n",
      "            indexer = tuple([indexer])\n",
      "\n",
      "        if isinstance(indexer, tuple):\n",
      "\n",
      "            # flatten np.ndarray indexers\n",
      "            def ravel(i):\n",
      "                return i.ravel() if isinstance(i, np.ndarray) else i\n",
      "\n",
      "            indexer = tuple(map(ravel, indexer))\n",
      "\n",
      "            aligners = [not com.is_null_slice(idx) for idx in indexer]\n",
      "            sum_aligners = sum(aligners)\n",
      "            single_aligner = sum_aligners == 1\n",
      "            is_frame = self.ndim == 2\n",
      "            obj = self.obj\n",
      "\n",
      "            # are we a single alignable value on a non-primary\n",
      "            # dim (e.g. panel: 1,2, or frame: 0) ?\n",
      "            # hence need to align to a single axis dimension\n",
      "            # rather that find all valid dims\n",
      "\n",
      "            # frame\n",
      "            if is_frame:\n",
      "                single_aligner = single_aligner and aligners[0]\n",
      "\n",
      "            # we have a frame, with multiple indexers on both axes; and a\n",
      "            # series, so need to broadcast (see GH5206)\n",
      "            if sum_aligners == self.ndim and all(is_sequence(_) for _ in indexer):\n",
      "                ser = ser.reindex(obj.axes[0][indexer[0]], copy=True)._values\n",
      "\n",
      "                # single indexer\n",
      "                if len(indexer) > 1 and not multiindex_indexer:\n",
      "                    len_indexer = len(indexer[1])\n",
      "                    ser = np.tile(ser, len_indexer).reshape(len_indexer, -1).T\n",
      "\n",
      "                return ser\n",
      "\n",
      "            for i, idx in enumerate(indexer):\n",
      "                ax = obj.axes[i]\n",
      "\n",
      "                # multiple aligners (or null slices)\n",
      "                if is_sequence(idx) or isinstance(idx, slice):\n",
      "                    if single_aligner and com.is_null_slice(idx):\n",
      "                        continue\n",
      "                    new_ix = ax[idx]\n",
      "                    if not is_list_like_indexer(new_ix):\n",
      "                        new_ix = Index([new_ix])\n",
      "                    else:\n",
      "                        new_ix = Index(new_ix)\n",
      "                    if ser.index.equals(new_ix) or not len(new_ix):\n",
      "                        return ser._values.copy()\n",
      "\n",
      "                    return ser.reindex(new_ix)._values\n",
      "\n",
      "                # 2 dims\n",
      "                elif single_aligner:\n",
      "\n",
      "                    # reindex along index\n",
      "                    ax = self.obj.axes[1]\n",
      "                    if ser.index.equals(ax) or not len(ax):\n",
      "                        return ser._values.copy()\n",
      "                    return ser.reindex(ax)._values\n",
      "\n",
      "        elif is_scalar(indexer):\n",
      "            ax = self.obj._get_axis(1)\n",
      "\n",
      "            if ser.index.equals(ax):\n",
      "                return ser._values.copy()\n",
      "\n",
      "            return ser.reindex(ax)._values\n",
      "\n",
      "        raise ValueError(\"Incompatible indexer with Series\")\n",
      "\n",
      "    def _align_frame(self, indexer, df: ABCDataFrame):\n",
      "        is_frame = self.ndim == 2\n",
      "\n",
      "        if isinstance(indexer, tuple):\n",
      "\n",
      "            idx, cols = None, None\n",
      "            sindexers = []\n",
      "            for i, ix in enumerate(indexer):\n",
      "                ax = self.obj.axes[i]\n",
      "                if is_sequence(ix) or isinstance(ix, slice):\n",
      "                    if isinstance(ix, np.ndarray):\n",
      "                        ix = ix.ravel()\n",
      "                    if idx is None:\n",
      "                        idx = ax[ix]\n",
      "                    elif cols is None:\n",
      "                        cols = ax[ix]\n",
      "                    else:\n",
      "                        break\n",
      "                else:\n",
      "                    sindexers.append(i)\n",
      "\n",
      "            if idx is not None and cols is not None:\n",
      "\n",
      "                if df.index.equals(idx) and df.columns.equals(cols):\n",
      "                    val = df.copy()._values\n",
      "                else:\n",
      "                    val = df.reindex(idx, columns=cols)._values\n",
      "                return val\n",
      "\n",
      "        elif (isinstance(indexer, slice) or is_list_like_indexer(indexer)) and is_frame:\n",
      "            ax = self.obj.index[indexer]\n",
      "            if df.index.equals(ax):\n",
      "                val = df.copy()._values\n",
      "            else:\n",
      "\n",
      "                # we have a multi-index and are trying to align\n",
      "                # with a particular, level GH3738\n",
      "                if (\n",
      "                    isinstance(ax, ABCMultiIndex)\n",
      "                    and isinstance(df.index, ABCMultiIndex)\n",
      "                    and ax.nlevels != df.index.nlevels\n",
      "                ):\n",
      "                    raise TypeError(\n",
      "                        \"cannot align on a multi-index with out \"\n",
      "                        \"specifying the join levels\"\n",
      "                    )\n",
      "\n",
      "                val = df.reindex(index=ax)._values\n",
      "            return val\n",
      "\n",
      "        raise ValueError(\"Incompatible indexer with DataFrame\")\n",
      "\n",
      "    def _getitem_tuple(self, tup: Tuple):\n",
      "        try:\n",
      "            return self._getitem_lowerdim(tup)\n",
      "        except IndexingError:\n",
      "            pass\n",
      "\n",
      "        # no multi-index, so validate all of the indexers\n",
      "        self._has_valid_tuple(tup)\n",
      "\n",
      "        # ugly hack for GH #836\n",
      "        if self._multi_take_opportunity(tup):\n",
      "            return self._multi_take(tup)\n",
      "\n",
      "        # no shortcut needed\n",
      "        retval = self.obj\n",
      "        for i, key in enumerate(tup):\n",
      "            if com.is_null_slice(key):\n",
      "                continue\n",
      "\n",
      "            retval = getattr(retval, self.name)._getitem_axis(key, axis=i)\n",
      "\n",
      "        return retval\n",
      "\n",
      "    def _multi_take_opportunity(self, tup: Tuple) -> bool:\n",
      "        \"\"\"\n",
      "        Check whether there is the possibility to use ``_multi_take``.\n",
      "\n",
      "        Currently the limit is that all axes being indexed, must be indexed with\n",
      "        list-likes.\n",
      "\n",
      "        Parameters\n",
      "        ----------\n",
      "        tup : tuple\n",
      "            Tuple of indexers, one per axis.\n",
      "\n",
      "        Returns\n",
      "        -------\n",
      "        bool\n",
      "            Whether the current indexing,\n",
      "            can be passed through `_multi_take`.\n",
      "        \"\"\"\n",
      "        if not all(is_list_like_indexer(x) for x in tup):\n",
      "            return False\n",
      "\n",
      "        # just too complicated\n",
      "        if any(com.is_bool_indexer(x) for x in tup):\n",
      "            return False\n",
      "\n",
      "        return True\n",
      "\n",
      "    def _multi_take(self, tup: Tuple):\n",
      "        \"\"\"\n",
      "        Create the indexers for the passed tuple of keys, and\n",
      "        executes the take operation. This allows the take operation to be\n",
      "        executed all at once, rather than once for each dimension.\n",
      "        Improving efficiency.\n",
      "\n",
      "        Parameters\n",
      "        ----------\n",
      "        tup : tuple\n",
      "            Tuple of indexers, one per axis.\n",
      "\n",
      "        Returns\n",
      "        -------\n",
      "        values: same type as the object being indexed\n",
      "        \"\"\"\n",
      "        # GH 836\n",
      "        o = self.obj\n",
      "        d = {\n",
      "            axis: self._get_listlike_indexer(key, axis)\n",
      "            for (key, axis) in zip(tup, o._AXIS_ORDERS)\n",
      "        }\n",
      "        return o._reindex_with_indexers(d, copy=True, allow_dups=True)\n",
      "\n",
      "    def _convert_for_reindex(self, key, axis: int):\n",
      "        return key\n",
      "\n",
      "    def _handle_lowerdim_multi_index_axis0(self, tup: Tuple):\n",
      "        # we have an axis0 multi-index, handle or raise\n",
      "        axis = self.axis or 0\n",
      "        try:\n",
      "            # fast path for series or for tup devoid of slices\n",
      "            return self._get_label(tup, axis=axis)\n",
      "        except TypeError:\n",
      "            # slices are unhashable\n",
      "            pass\n",
      "        except KeyError as ek:\n",
      "            # raise KeyError if number of indexers match\n",
      "            # else IndexingError will be raised\n",
      "            if len(tup) <= self.obj.index.nlevels and len(tup) > self.ndim:\n",
      "                raise ek\n",
      "\n",
      "        return None\n",
      "\n",
      "    def _getitem_lowerdim(self, tup: Tuple):\n",
      "\n",
      "        # we can directly get the axis result since the axis is specified\n",
      "        if self.axis is not None:\n",
      "            axis = self.obj._get_axis_number(self.axis)\n",
      "            return self._getitem_axis(tup, axis=axis)\n",
      "\n",
      "        # we may have a nested tuples indexer here\n",
      "        if self._is_nested_tuple_indexer(tup):\n",
      "            return self._getitem_nested_tuple(tup)\n",
      "\n",
      "        # we maybe be using a tuple to represent multiple dimensions here\n",
      "        ax0 = self.obj._get_axis(0)\n",
      "        # ...but iloc should handle the tuple as simple integer-location\n",
      "        # instead of checking it as multiindex representation (GH 13797)\n",
      "        if isinstance(ax0, ABCMultiIndex) and self.name != \"iloc\":\n",
      "            result = self._handle_lowerdim_multi_index_axis0(tup)\n",
      "            if result is not None:\n",
      "                return result\n",
      "\n",
      "        if len(tup) > self.ndim:\n",
      "            raise IndexingError(\"Too many indexers. handle elsewhere\")\n",
      "\n",
      "        for i, key in enumerate(tup):\n",
      "            if is_label_like(key) or isinstance(key, tuple):\n",
      "                section = self._getitem_axis(key, axis=i)\n",
      "\n",
      "                # we have yielded a scalar ?\n",
      "                if not is_list_like_indexer(section):\n",
      "                    return section\n",
      "\n",
      "                elif section.ndim == self.ndim:\n",
      "                    # we're in the middle of slicing through a MultiIndex\n",
      "                    # revise the key wrt to `section` by inserting an _NS\n",
      "                    new_key = tup[:i] + (_NS,) + tup[i + 1 :]\n",
      "\n",
      "                else:\n",
      "                    new_key = tup[:i] + tup[i + 1 :]\n",
      "\n",
      "                    # unfortunately need an odious kludge here because of\n",
      "                    # DataFrame transposing convention\n",
      "                    if (\n",
      "                        isinstance(section, ABCDataFrame)\n",
      "                        and i > 0\n",
      "                        and len(new_key) == 2\n",
      "                    ):\n",
      "                        a, b = new_key\n",
      "                        new_key = b, a\n",
      "\n",
      "                    if len(new_key) == 1:\n",
      "                        new_key = new_key[0]\n",
      "\n",
      "                # Slices should return views, but calling iloc/loc with a null\n",
      "                # slice returns a new object.\n",
      "                if com.is_null_slice(new_key):\n",
      "                    return section\n",
      "                # This is an elided recursive call to iloc/loc/etc'\n",
      "                return getattr(section, self.name)[new_key]\n",
      "\n",
      "        raise IndexingError(\"not applicable\")\n",
      "\n",
      "    def _getitem_nested_tuple(self, tup: Tuple):\n",
      "        # we have a nested tuple so have at least 1 multi-index level\n",
      "        # we should be able to match up the dimensionality here\n",
      "\n",
      "        # we have too many indexers for our dim, but have at least 1\n",
      "        # multi-index dimension, try to see if we have something like\n",
      "        # a tuple passed to a series with a multi-index\n",
      "        if len(tup) > self.ndim:\n",
      "            result = self._handle_lowerdim_multi_index_axis0(tup)\n",
      "            if result is not None:\n",
      "                return result\n",
      "\n",
      "            # this is a series with a multi-index specified a tuple of\n",
      "            # selectors\n",
      "            axis = self.axis or 0\n",
      "            return self._getitem_axis(tup, axis=axis)\n",
      "\n",
      "        # handle the multi-axis by taking sections and reducing\n",
      "        # this is iterative\n",
      "        obj = self.obj\n",
      "        axis = 0\n",
      "        for i, key in enumerate(tup):\n",
      "\n",
      "            if com.is_null_slice(key):\n",
      "                axis += 1\n",
      "                continue\n",
      "\n",
      "            current_ndim = obj.ndim\n",
      "            obj = getattr(obj, self.name)._getitem_axis(key, axis=axis)\n",
      "            axis += 1\n",
      "\n",
      "            # if we have a scalar, we are done\n",
      "            if is_scalar(obj) or not hasattr(obj, \"ndim\"):\n",
      "                break\n",
      "\n",
      "            # has the dim of the obj changed?\n",
      "            # GH 7199\n",
      "            if obj.ndim < current_ndim:\n",
      "                axis -= 1\n",
      "\n",
      "        return obj\n",
      "\n",
      "    # TODO: remove once geopandas no longer needs __getitem__\n",
      "    def _getitem_axis(self, key, axis: int):\n",
      "        if is_iterator(key):\n",
      "            key = list(key)\n",
      "        self._validate_key(key, axis)\n",
      "\n",
      "        labels = self.obj._get_axis(axis)\n",
      "        if isinstance(key, slice):\n",
      "            return self._get_slice_axis(key, axis=axis)\n",
      "        elif is_list_like_indexer(key) and not (\n",
      "            isinstance(key, tuple) and isinstance(labels, ABCMultiIndex)\n",
      "        ):\n",
      "\n",
      "            if hasattr(key, \"ndim\") and key.ndim > 1:\n",
      "                raise ValueError(\"Cannot index with multidimensional key\")\n",
      "\n",
      "            return self._getitem_iterable(key, axis=axis)\n",
      "        else:\n",
      "\n",
      "            # maybe coerce a float scalar to integer\n",
      "            key = labels._maybe_cast_indexer(key)\n",
      "\n",
      "            if is_integer(key):\n",
      "                if axis == 0 and isinstance(labels, ABCMultiIndex):\n",
      "                    try:\n",
      "                        return self._get_label(key, axis=axis)\n",
      "                    except (KeyError, TypeError):\n",
      "                        if self.obj.index.levels[0].is_integer():\n",
      "                            raise\n",
      "\n",
      "                # this is the fallback! (for a non-float, non-integer index)\n",
      "                if not labels.is_floating() and not labels.is_integer():\n",
      "                    return self._get_loc(key, axis=axis)\n",
      "\n",
      "            return self._get_label(key, axis=axis)\n",
      "\n",
      "    def _get_listlike_indexer(self, key, axis: int, raise_missing: bool = False):\n",
      "        \"\"\"\n",
      "        Transform a list-like of keys into a new index and an indexer.\n",
      "\n",
      "        Parameters\n",
      "        ----------\n",
      "        key : list-like\n",
      "            Targeted labels.\n",
      "        axis: int\n",
      "            Dimension on which the indexing is being made.\n",
      "        raise_missing: bool, default False\n",
      "            Whether to raise a KeyError if some labels were not found.\n",
      "            Will be removed in the future, and then this method will always behave as\n",
      "            if ``raise_missing=True``.\n",
      "\n",
      "        Raises\n",
      "        ------\n",
      "        KeyError\n",
      "            If at least one key was requested but none was found, and\n",
      "            raise_missing=True.\n",
      "\n",
      "        Returns\n",
      "        -------\n",
      "        keyarr: Index\n",
      "            New index (coinciding with 'key' if the axis is unique).\n",
      "        values : array-like\n",
      "            Indexer for the return object, -1 denotes keys not found.\n",
      "        \"\"\"\n",
      "        o = self.obj\n",
      "        ax = o._get_axis(axis)\n",
      "\n",
      "        # Have the index compute an indexer or return None\n",
      "        # if it cannot handle:\n",
      "        indexer, keyarr = ax._convert_listlike_indexer(key, kind=self.name)\n",
      "        # We only act on all found values:\n",
      "        if indexer is not None and (indexer != -1).all():\n",
      "            self._validate_read_indexer(key, indexer, axis, raise_missing=raise_missing)\n",
      "            return ax[indexer], indexer\n",
      "\n",
      "        if ax.is_unique and not getattr(ax, \"is_overlapping\", False):\n",
      "            # If we are trying to get actual keys from empty Series, we\n",
      "            # patiently wait for a KeyError later on - otherwise, convert\n",
      "            if len(ax) or not len(key):\n",
      "                key = self._convert_for_reindex(key, axis)\n",
      "            indexer = ax.get_indexer_for(key)\n",
      "            keyarr = ax.reindex(keyarr)[0]\n",
      "        else:\n",
      "            keyarr, indexer, new_indexer = ax._reindex_non_unique(keyarr)\n",
      "\n",
      "        self._validate_read_indexer(\n",
      "            keyarr, indexer, o._get_axis_number(axis), raise_missing=raise_missing\n",
      "        )\n",
      "        return keyarr, indexer\n",
      "\n",
      "    def _getitem_iterable(self, key, axis: int):\n",
      "        \"\"\"\n",
      "        Index current object with an an iterable key.\n",
      "\n",
      "        The iterable key can be a boolean indexer or a collection of keys.\n",
      "\n",
      "        Parameters\n",
      "        ----------\n",
      "        key : iterable\n",
      "            Targeted labels or boolean indexer.\n",
      "        axis: int\n",
      "            Dimension on which the indexing is being made.\n",
      "\n",
      "        Raises\n",
      "        ------\n",
      "        KeyError\n",
      "            If no key was found. Will change in the future to raise if not all\n",
      "            keys were found.\n",
      "        IndexingError\n",
      "            If the boolean indexer is unalignable with the object being\n",
      "            indexed.\n",
      "\n",
      "        Returns\n",
      "        -------\n",
      "        scalar, DataFrame, or Series: indexed value(s).\n",
      "        \"\"\"\n",
      "        # caller is responsible for ensuring non-None axis\n",
      "        self._validate_key(key, axis)\n",
      "\n",
      "        labels = self.obj._get_axis(axis)\n",
      "\n",
      "        if com.is_bool_indexer(key):\n",
      "            # A boolean indexer\n",
      "            key = check_bool_indexer(labels, key)\n",
      "            (inds,) = key.nonzero()\n",
      "            return self.obj._take_with_is_copy(inds, axis=axis)\n",
      "        else:\n",
      "            # A collection of keys\n",
      "            keyarr, indexer = self._get_listlike_indexer(key, axis, raise_missing=False)\n",
      "            return self.obj._reindex_with_indexers(\n",
      "                {axis: [keyarr, indexer]}, copy=True, allow_dups=True\n",
      "            )\n",
      "\n",
      "    def _validate_read_indexer(\n",
      "        self, key, indexer, axis: int, raise_missing: bool = False\n",
      "    ):\n",
      "        \"\"\"\n",
      "        Check that indexer can be used to return a result.\n",
      "\n",
      "        e.g. at least one element was found,\n",
      "        unless the list of keys was actually empty.\n",
      "\n",
      "        Parameters\n",
      "        ----------\n",
      "        key : list-like\n",
      "            Targeted labels (only used to show correct error message).\n",
      "        indexer: array-like of booleans\n",
      "            Indices corresponding to the key,\n",
      "            (with -1 indicating not found).\n",
      "        axis: int\n",
      "            Dimension on which the indexing is being made.\n",
      "        raise_missing: bool\n",
      "            Whether to raise a KeyError if some labels are not found. Will be\n",
      "            removed in the future, and then this method will always behave as\n",
      "            if raise_missing=True.\n",
      "\n",
      "        Raises\n",
      "        ------\n",
      "        KeyError\n",
      "            If at least one key was requested but none was found, and\n",
      "            raise_missing=True.\n",
      "        \"\"\"\n",
      "        ax = self.obj._get_axis(axis)\n",
      "\n",
      "        if len(key) == 0:\n",
      "            return\n",
      "\n",
      "        # Count missing values:\n",
      "        missing = (indexer < 0).sum()\n",
      "\n",
      "        if missing:\n",
      "            if missing == len(indexer):\n",
      "                axis_name = self.obj._get_axis_name(axis)\n",
      "                raise KeyError(f\"None of [{key}] are in the [{axis_name}]\")\n",
      "\n",
      "            # We (temporarily) allow for some missing keys with .loc, except in\n",
      "            # some cases (e.g. setting) in which \"raise_missing\" will be False\n",
      "            if not (self.name == \"loc\" and not raise_missing):\n",
      "                not_found = list(set(key) - set(ax))\n",
      "                raise KeyError(f\"{not_found} not in index\")\n",
      "\n",
      "            # we skip the warning on Categorical/Interval\n",
      "            # as this check is actually done (check for\n",
      "            # non-missing values), but a bit later in the\n",
      "            # code, so we want to avoid warning & then\n",
      "            # just raising\n",
      "            if not (ax.is_categorical() or ax.is_interval()):\n",
      "                raise KeyError(\n",
      "                    \"Passing list-likes to .loc or [] with any missing labels \"\n",
      "                    \"is no longer supported, see \"\n",
      "                    \"https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#deprecate-loc-reindex-listlike\"  # noqa:E501\n",
      "                )\n",
      "\n",
      "    def _convert_to_indexer(self, obj, axis: int, raise_missing: bool = False):\n",
      "        \"\"\"\n",
      "        Convert indexing key into something we can use to do actual fancy\n",
      "        indexing on a ndarray.\n",
      "\n",
      "        Examples\n",
      "        ix[:5] -> slice(0, 5)\n",
      "        ix[[1,2,3]] -> [1,2,3]\n",
      "        ix[['foo', 'bar', 'baz']] -> [i, j, k] (indices of foo, bar, baz)\n",
      "\n",
      "        Going by Zen of Python?\n",
      "        'In the face of ambiguity, refuse the temptation to guess.'\n",
      "        raise AmbiguousIndexError with integer labels?\n",
      "        - No, prefer label-based indexing\n",
      "        \"\"\"\n",
      "        labels = self.obj._get_axis(axis)\n",
      "\n",
      "        if isinstance(obj, slice):\n",
      "            return self._convert_slice_indexer(obj, axis)\n",
      "\n",
      "        # try to find out correct indexer, if not type correct raise\n",
      "        try:\n",
      "            obj = self._convert_scalar_indexer(obj, axis)\n",
      "        except TypeError:\n",
      "            # but we will allow setting\n",
      "            pass\n",
      "\n",
      "        # see if we are positional in nature\n",
      "        is_int_index = labels.is_integer()\n",
      "        is_int_positional = is_integer(obj) and not is_int_index\n",
      "\n",
      "        # if we are a label return me\n",
      "        try:\n",
      "            return labels.get_loc(obj)\n",
      "        except LookupError:\n",
      "            if isinstance(obj, tuple) and isinstance(labels, ABCMultiIndex):\n",
      "                if len(obj) == labels.nlevels:\n",
      "                    return {\"key\": obj}\n",
      "                raise\n",
      "        except TypeError:\n",
      "            pass\n",
      "        except ValueError:\n",
      "            if not is_int_positional:\n",
      "                raise\n",
      "\n",
      "        # a positional\n",
      "        if is_int_positional:\n",
      "\n",
      "            # if we are setting and its not a valid location\n",
      "            # its an insert which fails by definition\n",
      "\n",
      "            if self.name == \"loc\":\n",
      "                # always valid\n",
      "                return {\"key\": obj}\n",
      "\n",
      "            if obj >= self.obj.shape[axis] and not isinstance(labels, ABCMultiIndex):\n",
      "                # a positional\n",
      "                raise ValueError(\"cannot set by positional indexing with enlargement\")\n",
      "\n",
      "            return obj\n",
      "\n",
      "        if is_nested_tuple(obj, labels):\n",
      "            return labels.get_locs(obj)\n",
      "\n",
      "        elif is_list_like_indexer(obj):\n",
      "\n",
      "            if com.is_bool_indexer(obj):\n",
      "                obj = check_bool_indexer(labels, obj)\n",
      "                (inds,) = obj.nonzero()\n",
      "                return inds\n",
      "            else:\n",
      "                # When setting, missing keys are not allowed, even with .loc:\n",
      "                return self._get_listlike_indexer(obj, axis, raise_missing=True)[1]\n",
      "        else:\n",
      "            try:\n",
      "                return labels.get_loc(obj)\n",
      "            except LookupError:\n",
      "                # allow a not found key only if we are a setter\n",
      "                if not is_list_like_indexer(obj):\n",
      "                    return {\"key\": obj}\n",
      "                raise\n",
      "\n",
      "    def _get_slice_axis(self, slice_obj: slice, axis: int):\n",
      "        # caller is responsible for ensuring non-None axis\n",
      "        obj = self.obj\n",
      "\n",
      "        if not need_slice(slice_obj):\n",
      "            return obj.copy(deep=False)\n",
      "\n",
      "        indexer = self._convert_slice_indexer(slice_obj, axis)\n",
      "        return self._slice(indexer, axis=axis, kind=\"iloc\")\n",
      "\n",
      "\n",
      "class _LocationIndexer(_NDFrameIndexer):\n",
      "    def __getitem__(self, key):\n",
      "        if type(key) is tuple:\n",
      "            key = tuple(com.apply_if_callable(x, self.obj) for x in key)\n",
      "            if self._is_scalar_access(key):\n",
      "                try:\n",
      "                    return self._getitem_scalar(key)\n",
      "                except (KeyError, IndexError, AttributeError):\n",
      "                    pass\n",
      "            return self._getitem_tuple(key)\n",
      "        else:\n",
      "            # we by definition only have the 0th axis\n",
      "            axis = self.axis or 0\n",
      "\n",
      "            maybe_callable = com.apply_if_callable(key, self.obj)\n",
      "            return self._getitem_axis(maybe_callable, axis=axis)\n",
      "\n",
      "    def _is_scalar_access(self, key: Tuple):\n",
      "        raise NotImplementedError()\n",
      "\n",
      "    def _getitem_scalar(self, key):\n",
      "        raise NotImplementedError()\n",
      "\n",
      "    def _getitem_axis(self, key, axis: int):\n",
      "        raise NotImplementedError()\n",
      "\n",
      "    def _getbool_axis(self, key, axis: int):\n",
      "        # caller is responsible for ensuring non-None axis\n",
      "        labels = self.obj._get_axis(axis)\n",
      "        key = check_bool_indexer(labels, key)\n",
      "        inds = key.nonzero()[0]\n",
      "        return self.obj._take_with_is_copy(inds, axis=axis)\n",
      "\n",
      "    def _get_slice_axis(self, slice_obj: slice, axis: int):\n",
      "        \"\"\"\n",
      "        This is pretty simple as we just have to deal with labels.\n",
      "        \"\"\"\n",
      "        # caller is responsible for ensuring non-None axis\n",
      "        obj = self.obj\n",
      "        if not need_slice(slice_obj):\n",
      "            return obj.copy(deep=False)\n",
      "\n",
      "        labels = obj._get_axis(axis)\n",
      "        indexer = labels.slice_indexer(\n",
      "            slice_obj.start, slice_obj.stop, slice_obj.step, kind=self.name\n",
      "        )\n",
      "\n",
      "        if isinstance(indexer, slice):\n",
      "            return self._slice(indexer, axis=axis, kind=\"iloc\")\n",
      "        else:\n",
      "            # DatetimeIndex overrides Index.slice_indexer and may\n",
      "            #  return a DatetimeIndex instead of a slice object.\n",
      "            return self.obj._take_with_is_copy(indexer, axis=axis)\n",
      "\n",
      "\n",
      "@Appender(IndexingMixin.loc.__doc__)\n",
      "class _LocIndexer(_LocationIndexer):\n",
      "    _valid_types = (\n",
      "        \"labels (MUST BE IN THE INDEX), slices of labels (BOTH \"\n",
      "        \"endpoints included! Can be slices of integers if the \"\n",
      "        \"index is integers), listlike of labels, boolean\"\n",
      "    )\n",
      "\n",
      "    @Appender(_NDFrameIndexer._validate_key.__doc__)\n",
      "    def _validate_key(self, key, axis: int):\n",
      "\n",
      "        # valid for a collection of labels (we check their presence later)\n",
      "        # slice of labels (where start-end in labels)\n",
      "        # slice of integers (only if in the labels)\n",
      "        # boolean\n",
      "\n",
      "        if isinstance(key, slice):\n",
      "            return\n",
      "\n",
      "        if com.is_bool_indexer(key):\n",
      "            return\n",
      "\n",
      "        if not is_list_like_indexer(key):\n",
      "            self._convert_scalar_indexer(key, axis)\n",
      "\n",
      "    def _is_scalar_access(self, key: Tuple) -> bool:\n",
      "        \"\"\"\n",
      "        Returns\n",
      "        -------\n",
      "        bool\n",
      "        \"\"\"\n",
      "        # this is a shortcut accessor to both .loc and .iloc\n",
      "        # that provide the equivalent access of .at and .iat\n",
      "        # a) avoid getting things via sections and (to minimize dtype changes)\n",
      "        # b) provide a performant path\n",
      "        if len(key) != self.ndim:\n",
      "            return False\n",
      "\n",
      "        for i, k in enumerate(key):\n",
      "            if not is_scalar(k):\n",
      "                return False\n",
      "\n",
      "            ax = self.obj.axes[i]\n",
      "            if isinstance(ax, ABCMultiIndex):\n",
      "                return False\n",
      "\n",
      "            if isinstance(k, str) and ax._supports_partial_string_indexing:\n",
      "                # partial string indexing, df.loc['2000', 'A']\n",
      "                # should not be considered scalar\n",
      "                return False\n",
      "\n",
      "            if not ax.is_unique:\n",
      "                return False\n",
      "\n",
      "        return True\n",
      "\n",
      "    def _getitem_scalar(self, key):\n",
      "        # a fast-path to scalar access\n",
      "        # if not, raise\n",
      "        values = self.obj._get_value(*key)\n",
      "        return values\n",
      "\n",
      "    def _get_partial_string_timestamp_match_key(self, key, labels):\n",
      "        \"\"\"\n",
      "        Translate any partial string timestamp matches in key, returning the\n",
      "        new key.\n",
      "\n",
      "        (GH 10331)\n",
      "        \"\"\"\n",
      "        if isinstance(labels, ABCMultiIndex):\n",
      "            if (\n",
      "                isinstance(key, str)\n",
      "                and labels.levels[0]._supports_partial_string_indexing\n",
      "            ):\n",
      "                # Convert key '2016-01-01' to\n",
      "                # ('2016-01-01'[, slice(None, None, None)]+)\n",
      "                key = tuple([key] + [slice(None)] * (len(labels.levels) - 1))\n",
      "\n",
      "            if isinstance(key, tuple):\n",
      "                # Convert (..., '2016-01-01', ...) in tuple to\n",
      "                # (..., slice('2016-01-01', '2016-01-01', None), ...)\n",
      "                new_key = []\n",
      "                for i, component in enumerate(key):\n",
      "                    if (\n",
      "                        isinstance(component, str)\n",
      "                        and labels.levels[i]._supports_partial_string_indexing\n",
      "                    ):\n",
      "                        new_key.append(slice(component, component, None))\n",
      "                    else:\n",
      "                        new_key.append(component)\n",
      "                key = tuple(new_key)\n",
      "\n",
      "        return key\n",
      "\n",
      "    def _getitem_axis(self, key, axis: int):\n",
      "        key = item_from_zerodim(key)\n",
      "        if is_iterator(key):\n",
      "            key = list(key)\n",
      "\n",
      "        labels = self.obj._get_axis(axis)\n",
      "        key = self._get_partial_string_timestamp_match_key(key, labels)\n",
      "\n",
      "        if isinstance(key, slice):\n",
      "            self._validate_key(key, axis)\n",
      "            return self._get_slice_axis(key, axis=axis)\n",
      "        elif com.is_bool_indexer(key):\n",
      "            return self._getbool_axis(key, axis=axis)\n",
      "        elif is_list_like_indexer(key):\n",
      "\n",
      "            # convert various list-like indexers\n",
      "            # to a list of keys\n",
      "            # we will use the *values* of the object\n",
      "            # and NOT the index if its a PandasObject\n",
      "            if isinstance(labels, ABCMultiIndex):\n",
      "\n",
      "                if isinstance(key, (ABCSeries, np.ndarray)) and key.ndim <= 1:\n",
      "                    # Series, or 0,1 ndim ndarray\n",
      "                    # GH 14730\n",
      "                    key = list(key)\n",
      "                elif isinstance(key, ABCDataFrame):\n",
      "                    # GH 15438\n",
      "                    raise NotImplementedError(\n",
      "                        \"Indexing a MultiIndex with a \"\n",
      "                        \"DataFrame key is not \"\n",
      "                        \"implemented\"\n",
      "                    )\n",
      "                elif hasattr(key, \"ndim\") and key.ndim > 1:\n",
      "                    raise NotImplementedError(\n",
      "                        \"Indexing a MultiIndex with a \"\n",
      "                        \"multidimensional key is not \"\n",
      "                        \"implemented\"\n",
      "                    )\n",
      "\n",
      "                if (\n",
      "                    not isinstance(key, tuple)\n",
      "                    and len(key)\n",
      "                    and not isinstance(key[0], tuple)\n",
      "                ):\n",
      "                    key = tuple([key])\n",
      "\n",
      "            # an iterable multi-selection\n",
      "            if not (isinstance(key, tuple) and isinstance(labels, ABCMultiIndex)):\n",
      "\n",
      "                if hasattr(key, \"ndim\") and key.ndim > 1:\n",
      "                    raise ValueError(\"Cannot index with multidimensional key\")\n",
      "\n",
      "                return self._getitem_iterable(key, axis=axis)\n",
      "\n",
      "            # nested tuple slicing\n",
      "            if is_nested_tuple(key, labels):\n",
      "                locs = labels.get_locs(key)\n",
      "                indexer = [slice(None)] * self.ndim\n",
      "                indexer[axis] = locs\n",
      "                return self.obj.iloc[tuple(indexer)]\n",
      "\n",
      "        # fall thru to straight lookup\n",
      "        self._validate_key(key, axis)\n",
      "        return self._get_label(key, axis=axis)\n",
      "\n",
      "\n",
      "@Appender(IndexingMixin.iloc.__doc__)\n",
      "class _iLocIndexer(_LocationIndexer):\n",
      "    _valid_types = (\n",
      "        \"integer, integer slice (START point is INCLUDED, END \"\n",
      "        \"point is EXCLUDED), listlike of integers, boolean array\"\n",
      "    )\n",
      "    _get_slice_axis = _NDFrameIndexer._get_slice_axis\n",
      "\n",
      "    def _validate_key(self, key, axis: int):\n",
      "        if com.is_bool_indexer(key):\n",
      "            if hasattr(key, \"index\") and isinstance(key.index, Index):\n",
      "                if key.index.inferred_type == \"integer\":\n",
      "                    raise NotImplementedError(\n",
      "                        \"iLocation based boolean \"\n",
      "                        \"indexing on an integer type \"\n",
      "                        \"is not available\"\n",
      "                    )\n",
      "                raise ValueError(\n",
      "                    \"iLocation based boolean indexing cannot use \"\n",
      "                    \"an indexable as a mask\"\n",
      "                )\n",
      "            return\n",
      "\n",
      "        if isinstance(key, slice):\n",
      "            return\n",
      "        elif is_integer(key):\n",
      "            self._validate_integer(key, axis)\n",
      "        elif isinstance(key, tuple):\n",
      "            # a tuple should already have been caught by this point\n",
      "            # so don't treat a tuple as a valid indexer\n",
      "            raise IndexingError(\"Too many indexers\")\n",
      "        elif is_list_like_indexer(key):\n",
      "            arr = np.array(key)\n",
      "            len_axis = len(self.obj._get_axis(axis))\n",
      "\n",
      "            # check that the key has a numeric dtype\n",
      "            if not is_numeric_dtype(arr.dtype):\n",
      "                raise IndexError(f\".iloc requires numeric indexers, got {arr}\")\n",
      "\n",
      "            # check that the key does not exceed the maximum size of the index\n",
      "            if len(arr) and (arr.max() >= len_axis or arr.min() < -len_axis):\n",
      "                raise IndexError(\"positional indexers are out-of-bounds\")\n",
      "        else:\n",
      "            raise ValueError(f\"Can only index by location with a [{self._valid_types}]\")\n",
      "\n",
      "    def _has_valid_setitem_indexer(self, indexer):\n",
      "        self._has_valid_positional_setitem_indexer(indexer)\n",
      "\n",
      "    def _is_scalar_access(self, key: Tuple) -> bool:\n",
      "        \"\"\"\n",
      "        Returns\n",
      "        -------\n",
      "        bool\n",
      "        \"\"\"\n",
      "        # this is a shortcut accessor to both .loc and .iloc\n",
      "        # that provide the equivalent access of .at and .iat\n",
      "        # a) avoid getting things via sections and (to minimize dtype changes)\n",
      "        # b) provide a performant path\n",
      "        if len(key) != self.ndim:\n",
      "            return False\n",
      "\n",
      "        for i, k in enumerate(key):\n",
      "            if not is_integer(k):\n",
      "                return False\n",
      "\n",
      "            ax = self.obj.axes[i]\n",
      "            if not ax.is_unique:\n",
      "                return False\n",
      "\n",
      "        return True\n",
      "\n",
      "    def _getitem_scalar(self, key):\n",
      "        # a fast-path to scalar access\n",
      "        # if not, raise\n",
      "        values = self.obj._get_value(*key, takeable=True)\n",
      "        return values\n",
      "\n",
      "    def _validate_integer(self, key: int, axis: int) -> None:\n",
      "        \"\"\"\n",
      "        Check that 'key' is a valid position in the desired axis.\n",
      "\n",
      "        Parameters\n",
      "        ----------\n",
      "        key : int\n",
      "            Requested position.\n",
      "        axis : int\n",
      "            Desired axis.\n",
      "\n",
      "        Raises\n",
      "        ------\n",
      "        IndexError\n",
      "            If 'key' is not a valid position in axis 'axis'.\n",
      "        \"\"\"\n",
      "        len_axis = len(self.obj._get_axis(axis))\n",
      "        if key >= len_axis or key < -len_axis:\n",
      "            raise IndexError(\"single positional indexer is out-of-bounds\")\n",
      "\n",
      "    def _getitem_tuple(self, tup: Tuple):\n",
      "\n",
      "        self._has_valid_tuple(tup)\n",
      "        try:\n",
      "            return self._getitem_lowerdim(tup)\n",
      "        except IndexingError:\n",
      "            pass\n",
      "\n",
      "        retval = self.obj\n",
      "        axis = 0\n",
      "        for i, key in enumerate(tup):\n",
      "            if com.is_null_slice(key):\n",
      "                axis += 1\n",
      "                continue\n",
      "\n",
      "            retval = getattr(retval, self.name)._getitem_axis(key, axis=axis)\n",
      "\n",
      "            # if the dim was reduced, then pass a lower-dim the next time\n",
      "            if retval.ndim < self.ndim:\n",
      "                # TODO: this is never reached in tests; can we confirm that\n",
      "                #  it is impossible?\n",
      "                axis -= 1\n",
      "\n",
      "            # try to get for the next axis\n",
      "            axis += 1\n",
      "\n",
      "        return retval\n",
      "\n",
      "    def _get_list_axis(self, key, axis: int):\n",
      "        \"\"\"\n",
      "        Return Series values by list or array of integers.\n",
      "\n",
      "        Parameters\n",
      "        ----------\n",
      "        key : list-like positional indexer\n",
      "        axis : int\n",
      "\n",
      "        Returns\n",
      "        -------\n",
      "        Series object\n",
      "\n",
      "        Notes\n",
      "        -----\n",
      "        `axis` can only be zero.\n",
      "        \"\"\"\n",
      "        try:\n",
      "            return self.obj._take_with_is_copy(key, axis=axis)\n",
      "        except IndexError:\n",
      "            # re-raise with different error message\n",
      "            raise IndexError(\"positional indexers are out-of-bounds\")\n",
      "\n",
      "    def _getitem_axis(self, key, axis: int):\n",
      "        if isinstance(key, slice):\n",
      "            return self._get_slice_axis(key, axis=axis)\n",
      "\n",
      "        if isinstance(key, list):\n",
      "            key = np.asarray(key)\n",
      "\n",
      "        if com.is_bool_indexer(key):\n",
      "            self._validate_key(key, axis)\n",
      "            return self._getbool_axis(key, axis=axis)\n",
      "\n",
      "        # a list of integers\n",
      "        elif is_list_like_indexer(key):\n",
      "            return self._get_list_axis(key, axis=axis)\n",
      "\n",
      "        # a single integer\n",
      "        else:\n",
      "            key = item_from_zerodim(key)\n",
      "            if not is_integer(key):\n",
      "                raise TypeError(\"Cannot index by location index with a non-integer key\")\n",
      "\n",
      "            # validate the location\n",
      "            self._validate_integer(key, axis)\n",
      "\n",
      "            return self._get_loc(key, axis=axis)\n",
      "\n",
      "    # raise_missing is included for compat with the parent class signature\n",
      "    def _convert_to_indexer(self, obj, axis: int, raise_missing: bool = False):\n",
      "        \"\"\"\n",
      "        Much simpler as we only have to deal with our valid types.\n",
      "        \"\"\"\n",
      "        # make need to convert a float key\n",
      "        if isinstance(obj, slice):\n",
      "            return self._convert_slice_indexer(obj, axis)\n",
      "\n",
      "        elif is_float(obj):\n",
      "            return self._convert_scalar_indexer(obj, axis)\n",
      "\n",
      "        try:\n",
      "            self._validate_key(obj, axis)\n",
      "            return obj\n",
      "        except ValueError:\n",
      "            raise ValueError(f\"Can only index by location with a [{self._valid_types}]\")\n",
      "\n",
      "\n",
      "class _ScalarAccessIndexer(_NDFrameIndexerBase):\n",
      "    \"\"\"\n",
      "    Access scalars quickly.\n",
      "    \"\"\"\n",
      "\n",
      "    def _convert_key(self, key, is_setter: bool = False):\n",
      "        raise AbstractMethodError(self)\n",
      "\n",
      "    def __getitem__(self, key):\n",
      "        if not isinstance(key, tuple):\n",
      "\n",
      "            # we could have a convertible item here (e.g. Timestamp)\n",
      "            if not is_list_like_indexer(key):\n",
      "                key = tuple([key])\n",
      "            else:\n",
      "                raise ValueError(\"Invalid call for scalar access (getting)!\")\n",
      "\n",
      "        key = self._convert_key(key)\n",
      "        return self.obj._get_value(*key, takeable=self._takeable)\n",
      "\n",
      "    def __setitem__(self, key, value):\n",
      "        if isinstance(key, tuple):\n",
      "            key = tuple(com.apply_if_callable(x, self.obj) for x in key)\n",
      "        else:\n",
      "            # scalar callable may return tuple\n",
      "            key = com.apply_if_callable(key, self.obj)\n",
      "\n",
      "        if not isinstance(key, tuple):\n",
      "            key = _tuplify(self.ndim, key)\n",
      "        if len(key) != self.ndim:\n",
      "            raise ValueError(\"Not enough indexers for scalar access (setting)!\")\n",
      "        key = list(self._convert_key(key, is_setter=True))\n",
      "        key.append(value)\n",
      "        self.obj._set_value(*key, takeable=self._takeable)\n",
      "\n",
      "\n",
      "@Appender(IndexingMixin.at.__doc__)\n",
      "class _AtIndexer(_ScalarAccessIndexer):\n",
      "    _takeable = False\n",
      "\n",
      "    def _convert_key(self, key, is_setter: bool = False):\n",
      "        \"\"\"\n",
      "        Require they keys to be the same type as the index. (so we don't\n",
      "        fallback)\n",
      "        \"\"\"\n",
      "        # allow arbitrary setting\n",
      "        if is_setter:\n",
      "            return list(key)\n",
      "\n",
      "        for ax, i in zip(self.obj.axes, key):\n",
      "            if ax.is_integer():\n",
      "                if not is_integer(i):\n",
      "                    raise ValueError(\n",
      "                        \"At based indexing on an integer index \"\n",
      "                        \"can only have integer indexers\"\n",
      "                    )\n",
      "            else:\n",
      "                if is_integer(i) and not ax.holds_integer():\n",
      "                    raise ValueError(\n",
      "                        \"At based indexing on an non-integer \"\n",
      "                        \"index can only have non-integer \"\n",
      "                        \"indexers\"\n",
      "                    )\n",
      "        return key\n",
      "\n",
      "\n",
      "@Appender(IndexingMixin.iat.__doc__)\n",
      "class _iAtIndexer(_ScalarAccessIndexer):\n",
      "    _takeable = True\n",
      "\n",
      "    def _convert_key(self, key, is_setter: bool = False):\n",
      "        \"\"\"\n",
      "        Require integer args. (and convert to label arguments)\n",
      "        \"\"\"\n",
      "        for a, i in zip(self.obj.axes, key):\n",
      "            if not is_integer(i):\n",
      "                raise ValueError(\"iAt based indexing can only have integer indexers\")\n",
      "        return key\n",
      "\n",
      "\n",
      "def _tuplify(ndim: int, loc: Hashable) -> Tuple[Union[Hashable, slice], ...]:\n",
      "    \"\"\"\n",
      "    Given an indexer for the first dimension, create an equivalent tuple\n",
      "    for indexing over all dimensions.\n",
      "\n",
      "    Parameters\n",
      "    ----------\n",
      "    ndim : int\n",
      "    loc : object\n",
      "\n",
      "    Returns\n",
      "    -------\n",
      "    tuple\n",
      "    \"\"\"\n",
      "    _tup: List[Union[Hashable, slice]]\n",
      "    _tup = [slice(None, None) for _ in range(ndim)]\n",
      "    _tup[0] = loc\n",
      "    return tuple(_tup)\n",
      "\n",
      "\n",
      "def convert_to_index_sliceable(obj, key):\n",
      "    \"\"\"\n",
      "    If we are index sliceable, then return my slicer, otherwise return None.\n",
      "    \"\"\"\n",
      "    idx = obj.index\n",
      "    if isinstance(key, slice):\n",
      "        return idx._convert_slice_indexer(key, kind=\"getitem\")\n",
      "\n",
      "    elif isinstance(key, str):\n",
      "\n",
      "        # we are an actual column\n",
      "        if key in obj._data.items:\n",
      "            return None\n",
      "\n",
      "        # We might have a datetimelike string that we can translate to a\n",
      "        # slice here via partial string indexing\n",
      "        if idx._supports_partial_string_indexing:\n",
      "            try:\n",
      "                return idx._get_string_slice(key)\n",
      "            except (KeyError, ValueError, NotImplementedError):\n",
      "                return None\n",
      "\n",
      "    return None\n",
      "\n",
      "\n",
      "def check_bool_indexer(index: Index, key) -> np.ndarray:\n",
      "    \"\"\"\n",
      "    Check if key is a valid boolean indexer for an object with such index and\n",
      "    perform reindexing or conversion if needed.\n",
      "\n",
      "    This function assumes that is_bool_indexer(key) == True.\n",
      "\n",
      "    Parameters\n",
      "    ----------\n",
      "    index : Index\n",
      "        Index of the object on which the indexing is done.\n",
      "    key : list-like\n",
      "        Boolean indexer to check.\n",
      "\n",
      "    Returns\n",
      "    -------\n",
      "    np.array\n",
      "        Resulting key.\n",
      "\n",
      "    Raises\n",
      "    ------\n",
      "    IndexError\n",
      "        If the key does not have the same length as index.\n",
      "    IndexingError\n",
      "        If the index of the key is unalignable to index.\n",
      "    \"\"\"\n",
      "    result = key\n",
      "    if isinstance(key, ABCSeries) and not key.index.equals(index):\n",
      "        result = result.reindex(index)\n",
      "        mask = isna(result._values)\n",
      "        if mask.any():\n",
      "            raise IndexingError(\n",
      "                \"Unalignable boolean Series provided as \"\n",
      "                \"indexer (index of the boolean Series and of \"\n",
      "                \"the indexed object do not match).\"\n",
      "            )\n",
      "        result = result.astype(bool)._values\n",
      "    elif is_object_dtype(key):\n",
      "        # key might be object-dtype bool, check_array_indexer needs bool array\n",
      "        result = np.asarray(result, dtype=bool)\n",
      "        result = check_array_indexer(index, result)\n",
      "    else:\n",
      "        result = check_array_indexer(index, result)\n",
      "\n",
      "    return result\n",
      "\n",
      "\n",
      "def convert_missing_indexer(indexer):\n",
      "    \"\"\"\n",
      "    Reverse convert a missing indexer, which is a dict\n",
      "    return the scalar indexer and a boolean indicating if we converted\n",
      "    \"\"\"\n",
      "    if isinstance(indexer, dict):\n",
      "\n",
      "        # a missing key (but not a tuple indexer)\n",
      "        indexer = indexer[\"key\"]\n",
      "\n",
      "        if isinstance(indexer, bool):\n",
      "            raise KeyError(\"cannot use a single bool to index into setitem\")\n",
      "        return indexer, True\n",
      "\n",
      "    return indexer, False\n",
      "\n",
      "\n",
      "def convert_from_missing_indexer_tuple(indexer, axes):\n",
      "    \"\"\"\n",
      "    Create a filtered indexer that doesn't have any missing indexers.\n",
      "    \"\"\"\n",
      "\n",
      "    def get_indexer(_i, _idx):\n",
      "        return axes[_i].get_loc(_idx[\"key\"]) if isinstance(_idx, dict) else _idx\n",
      "\n",
      "    return tuple(get_indexer(_i, _idx) for _i, _idx in enumerate(indexer))\n",
      "\n",
      "\n",
      "def maybe_convert_ix(*args):\n",
      "    \"\"\"\n",
      "    We likely want to take the cross-product.\n",
      "    \"\"\"\n",
      "    ixify = True\n",
      "    for arg in args:\n",
      "        if not isinstance(arg, (np.ndarray, list, ABCSeries, Index)):\n",
      "            ixify = False\n",
      "\n",
      "    if ixify:\n",
      "        return np.ix_(*args)\n",
      "    else:\n",
      "        return args\n",
      "\n",
      "\n",
      "def is_nested_tuple(tup, labels) -> bool:\n",
      "    \"\"\"\n",
      "    Returns\n",
      "    -------\n",
      "    bool\n",
      "    \"\"\"\n",
      "    # check for a compatible nested tuple and multiindexes among the axes\n",
      "    if not isinstance(tup, tuple):\n",
      "        return False\n",
      "\n",
      "    for i, k in enumerate(tup):\n",
      "\n",
      "        if is_list_like(k) or isinstance(k, slice):\n",
      "            return isinstance(labels, ABCMultiIndex)\n",
      "\n",
      "    return False\n",
      "\n",
      "\n",
      "def is_label_like(key) -> bool:\n",
      "    \"\"\"\n",
      "    Returns\n",
      "    -------\n",
      "    bool\n",
      "    \"\"\"\n",
      "    # select a label or row\n",
      "    return not isinstance(key, slice) and not is_list_like_indexer(key)\n",
      "\n",
      "\n",
      "def need_slice(obj) -> bool:\n",
      "    \"\"\"\n",
      "    Returns\n",
      "    -------\n",
      "    bool\n",
      "    \"\"\"\n",
      "    return (\n",
      "        obj.start is not None\n",
      "        or obj.stop is not None\n",
      "        or (obj.step is not None and obj.step != 1)\n",
      "    )\n",
      "\n",
      "\n",
      "def _non_reducing_slice(slice_):\n",
      "    \"\"\"\n",
      "    Ensurse that a slice doesn't reduce to a Series or Scalar.\n",
      "\n",
      "    Any user-paseed `subset` should have this called on it\n",
      "    to make sure we're always working with DataFrames.\n",
      "    \"\"\"\n",
      "    # default to column slice, like DataFrame\n",
      "    # ['A', 'B'] -> IndexSlices[:, ['A', 'B']]\n",
      "    kinds = (ABCSeries, np.ndarray, Index, list, str)\n",
      "    if isinstance(slice_, kinds):\n",
      "        slice_ = IndexSlice[:, slice_]\n",
      "\n",
      "    def pred(part) -> bool:\n",
      "        \"\"\"\n",
      "        Returns\n",
      "        -------\n",
      "        bool\n",
      "            True if slice does *not* reduce,\n",
      "            False if `part` is a tuple.\n",
      "        \"\"\"\n",
      "        # true when slice does *not* reduce, False when part is a tuple,\n",
      "        # i.e. MultiIndex slice\n",
      "        return (isinstance(part, slice) or is_list_like(part)) and not isinstance(\n",
      "            part, tuple\n",
      "        )\n",
      "\n",
      "    if not is_list_like(slice_):\n",
      "        if not isinstance(slice_, slice):\n",
      "            # a 1-d slice, like df.loc[1]\n",
      "            slice_ = [[slice_]]\n",
      "        else:\n",
      "            # slice(a, b, c)\n",
      "            slice_ = [slice_]  # to tuplize later\n",
      "    else:\n",
      "        slice_ = [part if pred(part) else [part] for part in slice_]\n",
      "    return tuple(slice_)\n",
      "\n",
      "\n",
      "def _maybe_numeric_slice(df, slice_, include_bool=False):\n",
      "    \"\"\"\n",
      "    Want nice defaults for background_gradient that don't break\n",
      "    with non-numeric data. But if slice_ is passed go with that.\n",
      "    \"\"\"\n",
      "    if slice_ is None:\n",
      "        dtypes = [np.number]\n",
      "        if include_bool:\n",
      "            dtypes.append(bool)\n",
      "        slice_ = IndexSlice[:, df.select_dtypes(include=dtypes).columns]\n",
      "    return slice_\n",
      "\n",
      "\n",
      "def _can_do_equal_len(labels, value, plane_indexer, lplane_indexer, obj) -> bool:\n",
      "    \"\"\"\n",
      "    Returns\n",
      "    -------\n",
      "    bool\n",
      "        True if we have an equal len settable.\n",
      "    \"\"\"\n",
      "    if not len(labels) == 1 or not np.iterable(value) or is_scalar(plane_indexer[0]):\n",
      "        return False\n",
      "\n",
      "    item = labels[0]\n",
      "    index = obj[item].index\n",
      "\n",
      "    values_len = len(value)\n",
      "    # equal len list/ndarray\n",
      "    if len(index) == values_len:\n",
      "        return True\n",
      "    elif lplane_indexer == values_len:\n",
      "        return True\n",
      "\n",
      "    return False\n"
     ]
    }
   ],
   "source": [
    "%%script bash\n",
    "cat ~/anaconda3/lib/site-packages/pandas/core/indexing.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "# END"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
