{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# package-third-party-scipy-subpackage-stats-module-\\_distn\\_infrastructure\n",
    "> [TABLE OF CONTENTS](https://nbviewer.jupyter.org/github/SeanOhAileasa/fubar-python/blob/main/fubar-python.ipynb#top)\n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# b_T_hird_P_arty-imports\n",
    "import scipy.stats._distn_infrastructure as ssm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:\\\\Users\\\\E6985\\\\anaconda3\\\\lib\\\\site-packages\\\\scipy\\\\stats\\\\_distn_infrastructure.py'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# package scipy - subpackage stats - module _distn_infrastructure alias ssm - attribute __file__ - access\n",
    "ssm.__file__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#\n",
      "# Author:  Travis Oliphant  2002-2011 with contributions from\n",
      "#          SciPy Developers 2004-2011\n",
      "#\n",
      "from scipy._lib._util import getfullargspec_no_self as _getfullargspec\n",
      "\n",
      "import sys\n",
      "import keyword\n",
      "import re\n",
      "import types\n",
      "import warnings\n",
      "import inspect\n",
      "from itertools import zip_longest\n",
      "\n",
      "from scipy._lib import doccer\n",
      "from ._distr_params import distcont, distdiscrete\n",
      "from scipy._lib._util import check_random_state\n",
      "from scipy._lib._util import _valarray as valarray\n",
      "\n",
      "from scipy.special import (comb, chndtr, entr, rel_entr, xlogy, ive)\n",
      "\n",
      "# for root finding for continuous distribution ppf, and max likelihood estimation\n",
      "from scipy import optimize\n",
      "\n",
      "# for functions of continuous distributions (e.g. moments, entropy, cdf)\n",
      "from scipy import integrate\n",
      "\n",
      "# to approximate the pdf of a continuous distribution given its cdf\n",
      "from scipy.misc import derivative\n",
      "\n",
      "from numpy import (arange, putmask, ravel, ones, shape, ndarray, zeros, floor,\n",
      "                   logical_and, log, sqrt, place, argmax, vectorize, asarray,\n",
      "                   nan, inf, isinf, NINF, empty)\n",
      "\n",
      "import numpy as np\n",
      "\n",
      "from ._constants import _XMAX\n",
      "\n",
      "\n",
      "# These are the docstring parts used for substitution in specific\n",
      "# distribution docstrings\n",
      "\n",
      "docheaders = {'methods': \"\"\"\\nMethods\\n-------\\n\"\"\",\n",
      "              'notes': \"\"\"\\nNotes\\n-----\\n\"\"\",\n",
      "              'examples': \"\"\"\\nExamples\\n--------\\n\"\"\"}\n",
      "\n",
      "_doc_rvs = \"\"\"\\\n",
      "rvs(%(shapes)s, loc=0, scale=1, size=1, random_state=None)\n",
      "    Random variates.\n",
      "\"\"\"\n",
      "_doc_pdf = \"\"\"\\\n",
      "pdf(x, %(shapes)s, loc=0, scale=1)\n",
      "    Probability density function.\n",
      "\"\"\"\n",
      "_doc_logpdf = \"\"\"\\\n",
      "logpdf(x, %(shapes)s, loc=0, scale=1)\n",
      "    Log of the probability density function.\n",
      "\"\"\"\n",
      "_doc_pmf = \"\"\"\\\n",
      "pmf(k, %(shapes)s, loc=0, scale=1)\n",
      "    Probability mass function.\n",
      "\"\"\"\n",
      "_doc_logpmf = \"\"\"\\\n",
      "logpmf(k, %(shapes)s, loc=0, scale=1)\n",
      "    Log of the probability mass function.\n",
      "\"\"\"\n",
      "_doc_cdf = \"\"\"\\\n",
      "cdf(x, %(shapes)s, loc=0, scale=1)\n",
      "    Cumulative distribution function.\n",
      "\"\"\"\n",
      "_doc_logcdf = \"\"\"\\\n",
      "logcdf(x, %(shapes)s, loc=0, scale=1)\n",
      "    Log of the cumulative distribution function.\n",
      "\"\"\"\n",
      "_doc_sf = \"\"\"\\\n",
      "sf(x, %(shapes)s, loc=0, scale=1)\n",
      "    Survival function  (also defined as ``1 - cdf``, but `sf` is sometimes more accurate).\n",
      "\"\"\"\n",
      "_doc_logsf = \"\"\"\\\n",
      "logsf(x, %(shapes)s, loc=0, scale=1)\n",
      "    Log of the survival function.\n",
      "\"\"\"\n",
      "_doc_ppf = \"\"\"\\\n",
      "ppf(q, %(shapes)s, loc=0, scale=1)\n",
      "    Percent point function (inverse of ``cdf`` --- percentiles).\n",
      "\"\"\"\n",
      "_doc_isf = \"\"\"\\\n",
      "isf(q, %(shapes)s, loc=0, scale=1)\n",
      "    Inverse survival function (inverse of ``sf``).\n",
      "\"\"\"\n",
      "_doc_moment = \"\"\"\\\n",
      "moment(n, %(shapes)s, loc=0, scale=1)\n",
      "    Non-central moment of order n\n",
      "\"\"\"\n",
      "_doc_stats = \"\"\"\\\n",
      "stats(%(shapes)s, loc=0, scale=1, moments='mv')\n",
      "    Mean('m'), variance('v'), skew('s'), and/or kurtosis('k').\n",
      "\"\"\"\n",
      "_doc_entropy = \"\"\"\\\n",
      "entropy(%(shapes)s, loc=0, scale=1)\n",
      "    (Differential) entropy of the RV.\n",
      "\"\"\"\n",
      "_doc_fit = \"\"\"\\\n",
      "fit(data)\n",
      "    Parameter estimates for generic data.\n",
      "    See `scipy.stats.rv_continuous.fit <https://docs.scipy.org/doc/scipy/reference/generated/scipy.stats.rv_continuous.fit.html#scipy.stats.rv_continuous.fit>`__ for detailed documentation of the\n",
      "    keyword arguments.\n",
      "\"\"\"\n",
      "_doc_expect = \"\"\"\\\n",
      "expect(func, args=(%(shapes_)s), loc=0, scale=1, lb=None, ub=None, conditional=False, **kwds)\n",
      "    Expected value of a function (of one argument) with respect to the distribution.\n",
      "\"\"\"\n",
      "_doc_expect_discrete = \"\"\"\\\n",
      "expect(func, args=(%(shapes_)s), loc=0, lb=None, ub=None, conditional=False)\n",
      "    Expected value of a function (of one argument) with respect to the distribution.\n",
      "\"\"\"\n",
      "_doc_median = \"\"\"\\\n",
      "median(%(shapes)s, loc=0, scale=1)\n",
      "    Median of the distribution.\n",
      "\"\"\"\n",
      "_doc_mean = \"\"\"\\\n",
      "mean(%(shapes)s, loc=0, scale=1)\n",
      "    Mean of the distribution.\n",
      "\"\"\"\n",
      "_doc_var = \"\"\"\\\n",
      "var(%(shapes)s, loc=0, scale=1)\n",
      "    Variance of the distribution.\n",
      "\"\"\"\n",
      "_doc_std = \"\"\"\\\n",
      "std(%(shapes)s, loc=0, scale=1)\n",
      "    Standard deviation of the distribution.\n",
      "\"\"\"\n",
      "_doc_interval = \"\"\"\\\n",
      "interval(alpha, %(shapes)s, loc=0, scale=1)\n",
      "    Endpoints of the range that contains alpha percent of the distribution\n",
      "\"\"\"\n",
      "_doc_allmethods = ''.join([docheaders['methods'], _doc_rvs, _doc_pdf,\n",
      "                           _doc_logpdf, _doc_cdf, _doc_logcdf, _doc_sf,\n",
      "                           _doc_logsf, _doc_ppf, _doc_isf, _doc_moment,\n",
      "                           _doc_stats, _doc_entropy, _doc_fit,\n",
      "                           _doc_expect, _doc_median,\n",
      "                           _doc_mean, _doc_var, _doc_std, _doc_interval])\n",
      "\n",
      "_doc_default_longsummary = \"\"\"\\\n",
      "As an instance of the `rv_continuous` class, `%(name)s` object inherits from it\n",
      "a collection of generic methods (see below for the full list),\n",
      "and completes them with details specific for this particular distribution.\n",
      "\"\"\"\n",
      "\n",
      "_doc_default_frozen_note = \"\"\"\n",
      "Alternatively, the object may be called (as a function) to fix the shape,\n",
      "location, and scale parameters returning a \"frozen\" continuous RV object:\n",
      "\n",
      "rv = %(name)s(%(shapes)s, loc=0, scale=1)\n",
      "    - Frozen RV object with the same methods but holding the given shape,\n",
      "      location, and scale fixed.\n",
      "\"\"\"\n",
      "_doc_default_example = \"\"\"\\\n",
      "Examples\n",
      "--------\n",
      ">>> from scipy.stats import %(name)s\n",
      ">>> import matplotlib.pyplot as plt\n",
      ">>> fig, ax = plt.subplots(1, 1)\n",
      "\n",
      "Calculate a few first moments:\n",
      "\n",
      "%(set_vals_stmt)s\n",
      ">>> mean, var, skew, kurt = %(name)s.stats(%(shapes)s, moments='mvsk')\n",
      "\n",
      "Display the probability density function (``pdf``):\n",
      "\n",
      ">>> x = np.linspace(%(name)s.ppf(0.01, %(shapes)s),\n",
      "...                 %(name)s.ppf(0.99, %(shapes)s), 100)\n",
      ">>> ax.plot(x, %(name)s.pdf(x, %(shapes)s),\n",
      "...        'r-', lw=5, alpha=0.6, label='%(name)s pdf')\n",
      "\n",
      "Alternatively, the distribution object can be called (as a function)\n",
      "to fix the shape, location and scale parameters. This returns a \"frozen\"\n",
      "RV object holding the given parameters fixed.\n",
      "\n",
      "Freeze the distribution and display the frozen ``pdf``:\n",
      "\n",
      ">>> rv = %(name)s(%(shapes)s)\n",
      ">>> ax.plot(x, rv.pdf(x), 'k-', lw=2, label='frozen pdf')\n",
      "\n",
      "Check accuracy of ``cdf`` and ``ppf``:\n",
      "\n",
      ">>> vals = %(name)s.ppf([0.001, 0.5, 0.999], %(shapes)s)\n",
      ">>> np.allclose([0.001, 0.5, 0.999], %(name)s.cdf(vals, %(shapes)s))\n",
      "True\n",
      "\n",
      "Generate random numbers:\n",
      "\n",
      ">>> r = %(name)s.rvs(%(shapes)s, size=1000)\n",
      "\n",
      "And compare the histogram:\n",
      "\n",
      ">>> ax.hist(r, density=True, histtype='stepfilled', alpha=0.2)\n",
      ">>> ax.legend(loc='best', frameon=False)\n",
      ">>> plt.show()\n",
      "\n",
      "\"\"\"\n",
      "\n",
      "_doc_default_locscale = \"\"\"\\\n",
      "The probability density above is defined in the \"standardized\" form. To shift\n",
      "and/or scale the distribution use the ``loc`` and ``scale`` parameters.\n",
      "Specifically, ``%(name)s.pdf(x, %(shapes)s, loc, scale)`` is identically\n",
      "equivalent to ``%(name)s.pdf(y, %(shapes)s) / scale`` with\n",
      "``y = (x - loc) / scale``.\n",
      "\"\"\"\n",
      "\n",
      "_doc_default = ''.join([_doc_default_longsummary,\n",
      "                        _doc_allmethods,\n",
      "                        '\\n',\n",
      "                        _doc_default_example])\n",
      "\n",
      "_doc_default_before_notes = ''.join([_doc_default_longsummary,\n",
      "                                     _doc_allmethods])\n",
      "\n",
      "docdict = {\n",
      "    'rvs': _doc_rvs,\n",
      "    'pdf': _doc_pdf,\n",
      "    'logpdf': _doc_logpdf,\n",
      "    'cdf': _doc_cdf,\n",
      "    'logcdf': _doc_logcdf,\n",
      "    'sf': _doc_sf,\n",
      "    'logsf': _doc_logsf,\n",
      "    'ppf': _doc_ppf,\n",
      "    'isf': _doc_isf,\n",
      "    'stats': _doc_stats,\n",
      "    'entropy': _doc_entropy,\n",
      "    'fit': _doc_fit,\n",
      "    'moment': _doc_moment,\n",
      "    'expect': _doc_expect,\n",
      "    'interval': _doc_interval,\n",
      "    'mean': _doc_mean,\n",
      "    'std': _doc_std,\n",
      "    'var': _doc_var,\n",
      "    'median': _doc_median,\n",
      "    'allmethods': _doc_allmethods,\n",
      "    'longsummary': _doc_default_longsummary,\n",
      "    'frozennote': _doc_default_frozen_note,\n",
      "    'example': _doc_default_example,\n",
      "    'default': _doc_default,\n",
      "    'before_notes': _doc_default_before_notes,\n",
      "    'after_notes': _doc_default_locscale\n",
      "}\n",
      "\n",
      "# Reuse common content between continuous and discrete docs, change some\n",
      "# minor bits.\n",
      "docdict_discrete = docdict.copy()\n",
      "\n",
      "docdict_discrete['pmf'] = _doc_pmf\n",
      "docdict_discrete['logpmf'] = _doc_logpmf\n",
      "docdict_discrete['expect'] = _doc_expect_discrete\n",
      "_doc_disc_methods = ['rvs', 'pmf', 'logpmf', 'cdf', 'logcdf', 'sf', 'logsf',\n",
      "                     'ppf', 'isf', 'stats', 'entropy', 'expect', 'median',\n",
      "                     'mean', 'var', 'std', 'interval']\n",
      "for obj in _doc_disc_methods:\n",
      "    docdict_discrete[obj] = docdict_discrete[obj].replace(', scale=1', '')\n",
      "\n",
      "_doc_disc_methods_err_varname = ['cdf', 'logcdf', 'sf', 'logsf']\n",
      "for obj in _doc_disc_methods_err_varname:\n",
      "    docdict_discrete[obj] = docdict_discrete[obj].replace('(x, ', '(k, ')\n",
      "\n",
      "docdict_discrete.pop('pdf')\n",
      "docdict_discrete.pop('logpdf')\n",
      "\n",
      "_doc_allmethods = ''.join([docdict_discrete[obj] for obj in _doc_disc_methods])\n",
      "docdict_discrete['allmethods'] = docheaders['methods'] + _doc_allmethods\n",
      "\n",
      "docdict_discrete['longsummary'] = _doc_default_longsummary.replace(\n",
      "    'rv_continuous', 'rv_discrete')\n",
      "\n",
      "_doc_default_frozen_note = \"\"\"\n",
      "Alternatively, the object may be called (as a function) to fix the shape and\n",
      "location parameters returning a \"frozen\" discrete RV object:\n",
      "\n",
      "rv = %(name)s(%(shapes)s, loc=0)\n",
      "    - Frozen RV object with the same methods but holding the given shape and\n",
      "      location fixed.\n",
      "\"\"\"\n",
      "docdict_discrete['frozennote'] = _doc_default_frozen_note\n",
      "\n",
      "_doc_default_discrete_example = \"\"\"\\\n",
      "Examples\n",
      "--------\n",
      ">>> from scipy.stats import %(name)s\n",
      ">>> import matplotlib.pyplot as plt\n",
      ">>> fig, ax = plt.subplots(1, 1)\n",
      "\n",
      "Calculate a few first moments:\n",
      "\n",
      "%(set_vals_stmt)s\n",
      ">>> mean, var, skew, kurt = %(name)s.stats(%(shapes)s, moments='mvsk')\n",
      "\n",
      "Display the probability mass function (``pmf``):\n",
      "\n",
      ">>> x = np.arange(%(name)s.ppf(0.01, %(shapes)s),\n",
      "...               %(name)s.ppf(0.99, %(shapes)s))\n",
      ">>> ax.plot(x, %(name)s.pmf(x, %(shapes)s), 'bo', ms=8, label='%(name)s pmf')\n",
      ">>> ax.vlines(x, 0, %(name)s.pmf(x, %(shapes)s), colors='b', lw=5, alpha=0.5)\n",
      "\n",
      "Alternatively, the distribution object can be called (as a function)\n",
      "to fix the shape and location. This returns a \"frozen\" RV object holding\n",
      "the given parameters fixed.\n",
      "\n",
      "Freeze the distribution and display the frozen ``pmf``:\n",
      "\n",
      ">>> rv = %(name)s(%(shapes)s)\n",
      ">>> ax.vlines(x, 0, rv.pmf(x), colors='k', linestyles='-', lw=1,\n",
      "...         label='frozen pmf')\n",
      ">>> ax.legend(loc='best', frameon=False)\n",
      ">>> plt.show()\n",
      "\n",
      "Check accuracy of ``cdf`` and ``ppf``:\n",
      "\n",
      ">>> prob = %(name)s.cdf(x, %(shapes)s)\n",
      ">>> np.allclose(x, %(name)s.ppf(prob, %(shapes)s))\n",
      "True\n",
      "\n",
      "Generate random numbers:\n",
      "\n",
      ">>> r = %(name)s.rvs(%(shapes)s, size=1000)\n",
      "\"\"\"\n",
      "\n",
      "\n",
      "_doc_default_discrete_locscale = \"\"\"\\\n",
      "The probability mass function above is defined in the \"standardized\" form.\n",
      "To shift distribution use the ``loc`` parameter.\n",
      "Specifically, ``%(name)s.pmf(k, %(shapes)s, loc)`` is identically\n",
      "equivalent to ``%(name)s.pmf(k - loc, %(shapes)s)``.\n",
      "\"\"\"\n",
      "\n",
      "docdict_discrete['example'] = _doc_default_discrete_example\n",
      "docdict_discrete['after_notes'] = _doc_default_discrete_locscale\n",
      "\n",
      "_doc_default_before_notes = ''.join([docdict_discrete['longsummary'],\n",
      "                                     docdict_discrete['allmethods']])\n",
      "docdict_discrete['before_notes'] = _doc_default_before_notes\n",
      "\n",
      "_doc_default_disc = ''.join([docdict_discrete['longsummary'],\n",
      "                             docdict_discrete['allmethods'],\n",
      "                             docdict_discrete['frozennote'],\n",
      "                             docdict_discrete['example']])\n",
      "docdict_discrete['default'] = _doc_default_disc\n",
      "\n",
      "# clean up all the separate docstring elements, we do not need them anymore\n",
      "for obj in [s for s in dir() if s.startswith('_doc_')]:\n",
      "    exec('del ' + obj)\n",
      "del obj\n",
      "\n",
      "\n",
      "def _moment(data, n, mu=None):\n",
      "    if mu is None:\n",
      "        mu = data.mean()\n",
      "    return ((data - mu)**n).mean()\n",
      "\n",
      "\n",
      "def _moment_from_stats(n, mu, mu2, g1, g2, moment_func, args):\n",
      "    if (n == 0):\n",
      "        return 1.0\n",
      "    elif (n == 1):\n",
      "        if mu is None:\n",
      "            val = moment_func(1, *args)\n",
      "        else:\n",
      "            val = mu\n",
      "    elif (n == 2):\n",
      "        if mu2 is None or mu is None:\n",
      "            val = moment_func(2, *args)\n",
      "        else:\n",
      "            val = mu2 + mu*mu\n",
      "    elif (n == 3):\n",
      "        if g1 is None or mu2 is None or mu is None:\n",
      "            val = moment_func(3, *args)\n",
      "        else:\n",
      "            mu3 = g1 * np.power(mu2, 1.5)  # 3rd central moment\n",
      "            val = mu3+3*mu*mu2+mu*mu*mu  # 3rd non-central moment\n",
      "    elif (n == 4):\n",
      "        if g1 is None or g2 is None or mu2 is None or mu is None:\n",
      "            val = moment_func(4, *args)\n",
      "        else:\n",
      "            mu4 = (g2+3.0)*(mu2**2.0)  # 4th central moment\n",
      "            mu3 = g1*np.power(mu2, 1.5)  # 3rd central moment\n",
      "            val = mu4+4*mu*mu3+6*mu*mu*mu2+mu*mu*mu*mu\n",
      "    else:\n",
      "        val = moment_func(n, *args)\n",
      "\n",
      "    return val\n",
      "\n",
      "\n",
      "def _skew(data):\n",
      "    \"\"\"\n",
      "    skew is third central moment / variance**(1.5)\n",
      "    \"\"\"\n",
      "    data = np.ravel(data)\n",
      "    mu = data.mean()\n",
      "    m2 = ((data - mu)**2).mean()\n",
      "    m3 = ((data - mu)**3).mean()\n",
      "    return m3 / np.power(m2, 1.5)\n",
      "\n",
      "\n",
      "def _kurtosis(data):\n",
      "    \"\"\"\n",
      "    kurtosis is fourth central moment / variance**2 - 3\n",
      "    \"\"\"\n",
      "    data = np.ravel(data)\n",
      "    mu = data.mean()\n",
      "    m2 = ((data - mu)**2).mean()\n",
      "    m4 = ((data - mu)**4).mean()\n",
      "    return m4 / m2**2 - 3\n",
      "\n",
      "\n",
      "# Frozen RV class\n",
      "class rv_frozen(object):\n",
      "\n",
      "    def __init__(self, dist, *args, **kwds):\n",
      "        self.args = args\n",
      "        self.kwds = kwds\n",
      "\n",
      "        # create a new instance\n",
      "        self.dist = dist.__class__(**dist._updated_ctor_param())\n",
      "\n",
      "        shapes, _, _ = self.dist._parse_args(*args, **kwds)\n",
      "        self.a, self.b = self.dist._get_support(*shapes)\n",
      "\n",
      "    @property\n",
      "    def random_state(self):\n",
      "        return self.dist._random_state\n",
      "\n",
      "    @random_state.setter\n",
      "    def random_state(self, seed):\n",
      "        self.dist._random_state = check_random_state(seed)\n",
      "\n",
      "    def pdf(self, x):   # raises AttributeError in frozen discrete distribution\n",
      "        return self.dist.pdf(x, *self.args, **self.kwds)\n",
      "\n",
      "    def logpdf(self, x):\n",
      "        return self.dist.logpdf(x, *self.args, **self.kwds)\n",
      "\n",
      "    def cdf(self, x):\n",
      "        return self.dist.cdf(x, *self.args, **self.kwds)\n",
      "\n",
      "    def logcdf(self, x):\n",
      "        return self.dist.logcdf(x, *self.args, **self.kwds)\n",
      "\n",
      "    def ppf(self, q):\n",
      "        return self.dist.ppf(q, *self.args, **self.kwds)\n",
      "\n",
      "    def isf(self, q):\n",
      "        return self.dist.isf(q, *self.args, **self.kwds)\n",
      "\n",
      "    def rvs(self, size=None, random_state=None):\n",
      "        kwds = self.kwds.copy()\n",
      "        kwds.update({'size': size, 'random_state': random_state})\n",
      "        return self.dist.rvs(*self.args, **kwds)\n",
      "\n",
      "    def sf(self, x):\n",
      "        return self.dist.sf(x, *self.args, **self.kwds)\n",
      "\n",
      "    def logsf(self, x):\n",
      "        return self.dist.logsf(x, *self.args, **self.kwds)\n",
      "\n",
      "    def stats(self, moments='mv'):\n",
      "        kwds = self.kwds.copy()\n",
      "        kwds.update({'moments': moments})\n",
      "        return self.dist.stats(*self.args, **kwds)\n",
      "\n",
      "    def median(self):\n",
      "        return self.dist.median(*self.args, **self.kwds)\n",
      "\n",
      "    def mean(self):\n",
      "        return self.dist.mean(*self.args, **self.kwds)\n",
      "\n",
      "    def var(self):\n",
      "        return self.dist.var(*self.args, **self.kwds)\n",
      "\n",
      "    def std(self):\n",
      "        return self.dist.std(*self.args, **self.kwds)\n",
      "\n",
      "    def moment(self, n):\n",
      "        return self.dist.moment(n, *self.args, **self.kwds)\n",
      "\n",
      "    def entropy(self):\n",
      "        return self.dist.entropy(*self.args, **self.kwds)\n",
      "\n",
      "    def pmf(self, k):\n",
      "        return self.dist.pmf(k, *self.args, **self.kwds)\n",
      "\n",
      "    def logpmf(self, k):\n",
      "        return self.dist.logpmf(k, *self.args, **self.kwds)\n",
      "\n",
      "    def interval(self, alpha):\n",
      "        return self.dist.interval(alpha, *self.args, **self.kwds)\n",
      "\n",
      "    def expect(self, func=None, lb=None, ub=None, conditional=False, **kwds):\n",
      "        # expect method only accepts shape parameters as positional args\n",
      "        # hence convert self.args, self.kwds, also loc/scale\n",
      "        # See the .expect method docstrings for the meaning of\n",
      "        # other parameters.\n",
      "        a, loc, scale = self.dist._parse_args(*self.args, **self.kwds)\n",
      "        if isinstance(self.dist, rv_discrete):\n",
      "            return self.dist.expect(func, a, loc, lb, ub, conditional, **kwds)\n",
      "        else:\n",
      "            return self.dist.expect(func, a, loc, scale, lb, ub,\n",
      "                                    conditional, **kwds)\n",
      "\n",
      "    def support(self):\n",
      "        return self.dist.support(*self.args, **self.kwds)\n",
      "\n",
      "\n",
      "# This should be rewritten\n",
      "def argsreduce(cond, *args):\n",
      "    \"\"\"Return the sequence of ravel(args[i]) where ravel(condition) is\n",
      "    True in 1D.\n",
      "\n",
      "    Examples\n",
      "    --------\n",
      "    >>> import numpy as np\n",
      "    >>> rand = np.random.random_sample\n",
      "    >>> A = rand((4, 5))\n",
      "    >>> B = 2\n",
      "    >>> C = rand((1, 5))\n",
      "    >>> cond = np.ones(A.shape)\n",
      "    >>> [A1, B1, C1] = argsreduce(cond, A, B, C)\n",
      "    >>> B1.shape\n",
      "    (20,)\n",
      "    >>> cond[2,:] = 0\n",
      "    >>> [A2, B2, C2] = argsreduce(cond, A, B, C)\n",
      "    >>> B2.shape\n",
      "    (15,)\n",
      "\n",
      "    \"\"\"\n",
      "    newargs = np.atleast_1d(*args)\n",
      "    if not isinstance(newargs, list):\n",
      "        newargs = [newargs, ]\n",
      "    expand_arr = (cond == cond)\n",
      "    return [np.extract(cond, arr1 * expand_arr) for arr1 in newargs]\n",
      "\n",
      "\n",
      "parse_arg_template = \"\"\"\n",
      "def _parse_args(self, %(shape_arg_str)s %(locscale_in)s):\n",
      "    return (%(shape_arg_str)s), %(locscale_out)s\n",
      "\n",
      "def _parse_args_rvs(self, %(shape_arg_str)s %(locscale_in)s, size=None):\n",
      "    return self._argcheck_rvs(%(shape_arg_str)s %(locscale_out)s, size=size)\n",
      "\n",
      "def _parse_args_stats(self, %(shape_arg_str)s %(locscale_in)s, moments='mv'):\n",
      "    return (%(shape_arg_str)s), %(locscale_out)s, moments\n",
      "\"\"\"\n",
      "\n",
      "\n",
      "# Both the continuous and discrete distributions depend on ncx2.\n",
      "# The function name ncx2 is an abbreviation for noncentral chi squared.\n",
      "\n",
      "def _ncx2_log_pdf(x, df, nc):\n",
      "    # We use (xs**2 + ns**2)/2 = (xs - ns)**2/2  + xs*ns, and include the\n",
      "    # factor of exp(-xs*ns) into the ive function to improve numerical\n",
      "    # stability at large values of xs. See also `rice.pdf`.\n",
      "    df2 = df/2.0 - 1.0\n",
      "    xs, ns = np.sqrt(x), np.sqrt(nc)\n",
      "    res = xlogy(df2/2.0, x/nc) - 0.5*(xs - ns)**2\n",
      "    res += np.log(ive(df2, xs*ns) / 2.0)\n",
      "    return res\n",
      "\n",
      "\n",
      "def _ncx2_pdf(x, df, nc):\n",
      "    return np.exp(_ncx2_log_pdf(x, df, nc))\n",
      "\n",
      "\n",
      "def _ncx2_cdf(x, df, nc):\n",
      "    return chndtr(x, df, nc)\n",
      "\n",
      "\n",
      "class rv_generic(object):\n",
      "    \"\"\"Class which encapsulates common functionality between rv_discrete\n",
      "    and rv_continuous.\n",
      "\n",
      "    \"\"\"\n",
      "    def __init__(self, seed=None):\n",
      "        super(rv_generic, self).__init__()\n",
      "\n",
      "        # figure out if _stats signature has 'moments' keyword\n",
      "        sig = _getfullargspec(self._stats)\n",
      "        self._stats_has_moments = ((sig.varkw is not None) or\n",
      "                                   ('moments' in sig.args) or\n",
      "                                   ('moments' in sig.kwonlyargs))\n",
      "        self._random_state = check_random_state(seed)\n",
      "\n",
      "        # For historical reasons, `size` was made an attribute that was read\n",
      "        # inside _rvs().  The code is being changed so that 'size' is an argument\n",
      "        # to self._rvs(). However some external (non-SciPy) distributions have not\n",
      "        # been updated.  Maintain backwards compatibility by checking if\n",
      "        # the self._rvs() signature has the 'size' keyword, or a **kwarg,\n",
      "        # and if not set self._size inside self.rvs() before calling self._rvs().\n",
      "        argspec = inspect.getfullargspec(self._rvs)\n",
      "        self._rvs_uses_size_attribute = (argspec.varkw is None and\n",
      "                                         'size' not in argspec.args and\n",
      "                                         'size' not in argspec.kwonlyargs)\n",
      "        # Warn on first use only\n",
      "        self._rvs_size_warned = False\n",
      "\n",
      "    @property\n",
      "    def random_state(self):\n",
      "        \"\"\" Get or set the RandomState object for generating random variates.\n",
      "\n",
      "        This can be either None, int, a RandomState instance, or a\n",
      "        np.random.Generator instance.\n",
      "\n",
      "        If None (or np.random), use the RandomState singleton used by np.random.\n",
      "        If already a RandomState or Generator instance, use it.\n",
      "        If an int, use a new RandomState instance seeded with seed.\n",
      "\n",
      "        \"\"\"\n",
      "        return self._random_state\n",
      "\n",
      "    @random_state.setter\n",
      "    def random_state(self, seed):\n",
      "        self._random_state = check_random_state(seed)\n",
      "\n",
      "    def __getstate__(self):\n",
      "        return self._updated_ctor_param(), self._random_state\n",
      "\n",
      "    def __setstate__(self, state):\n",
      "        ctor_param, r = state\n",
      "        self.__init__(**ctor_param)\n",
      "        self._random_state = r\n",
      "        return self\n",
      "\n",
      "    def _construct_argparser(\n",
      "            self, meths_to_inspect, locscale_in, locscale_out):\n",
      "        \"\"\"Construct the parser for the shape arguments.\n",
      "\n",
      "        Generates the argument-parsing functions dynamically and attaches\n",
      "        them to the instance.\n",
      "        Is supposed to be called in __init__ of a class for each distribution.\n",
      "\n",
      "        If self.shapes is a non-empty string, interprets it as a\n",
      "        comma-separated list of shape parameters.\n",
      "\n",
      "        Otherwise inspects the call signatures of `meths_to_inspect`\n",
      "        and constructs the argument-parsing functions from these.\n",
      "        In this case also sets `shapes` and `numargs`.\n",
      "        \"\"\"\n",
      "\n",
      "        if self.shapes:\n",
      "            # sanitize the user-supplied shapes\n",
      "            if not isinstance(self.shapes, str):\n",
      "                raise TypeError('shapes must be a string.')\n",
      "\n",
      "            shapes = self.shapes.replace(',', ' ').split()\n",
      "\n",
      "            for field in shapes:\n",
      "                if keyword.iskeyword(field):\n",
      "                    raise SyntaxError('keywords cannot be used as shapes.')\n",
      "                if not re.match('^[_a-zA-Z][_a-zA-Z0-9]*$', field):\n",
      "                    raise SyntaxError(\n",
      "                        'shapes must be valid python identifiers')\n",
      "        else:\n",
      "            # find out the call signatures (_pdf, _cdf etc), deduce shape\n",
      "            # arguments. Generic methods only have 'self, x', any further args\n",
      "            # are shapes.\n",
      "            shapes_list = []\n",
      "            for meth in meths_to_inspect:\n",
      "                shapes_args = _getfullargspec(meth)   # NB: does not contain self\n",
      "                args = shapes_args.args[1:]       # peel off 'x', too\n",
      "\n",
      "                if args:\n",
      "                    shapes_list.append(args)\n",
      "\n",
      "                    # *args or **kwargs are not allowed w/automatic shapes\n",
      "                    if shapes_args.varargs is not None:\n",
      "                        raise TypeError(\n",
      "                            '*args are not allowed w/out explicit shapes')\n",
      "                    if shapes_args.varkw is not None:\n",
      "                        raise TypeError(\n",
      "                            '**kwds are not allowed w/out explicit shapes')\n",
      "                    if shapes_args.kwonlyargs:\n",
      "                        raise TypeError(\n",
      "                            'kwonly args are not allowed w/out explicit shapes')\n",
      "                    if shapes_args.defaults is not None:\n",
      "                        raise TypeError('defaults are not allowed for shapes')\n",
      "\n",
      "            if shapes_list:\n",
      "                shapes = shapes_list[0]\n",
      "\n",
      "                # make sure the signatures are consistent\n",
      "                for item in shapes_list:\n",
      "                    if item != shapes:\n",
      "                        raise TypeError('Shape arguments are inconsistent.')\n",
      "            else:\n",
      "                shapes = []\n",
      "\n",
      "        # have the arguments, construct the method from template\n",
      "        shapes_str = ', '.join(shapes) + ', ' if shapes else ''  # NB: not None\n",
      "        dct = dict(shape_arg_str=shapes_str,\n",
      "                   locscale_in=locscale_in,\n",
      "                   locscale_out=locscale_out,\n",
      "                   )\n",
      "        ns = {}\n",
      "        exec(parse_arg_template % dct, ns)\n",
      "        # NB: attach to the instance, not class\n",
      "        for name in ['_parse_args', '_parse_args_stats', '_parse_args_rvs']:\n",
      "            setattr(self, name, types.MethodType(ns[name], self))\n",
      "\n",
      "        self.shapes = ', '.join(shapes) if shapes else None\n",
      "        if not hasattr(self, 'numargs'):\n",
      "            # allows more general subclassing with *args\n",
      "            self.numargs = len(shapes)\n",
      "\n",
      "    def _construct_doc(self, docdict, shapes_vals=None):\n",
      "        \"\"\"Construct the instance docstring with string substitutions.\"\"\"\n",
      "        tempdict = docdict.copy()\n",
      "        tempdict['name'] = self.name or 'distname'\n",
      "        tempdict['shapes'] = self.shapes or ''\n",
      "\n",
      "        if shapes_vals is None:\n",
      "            shapes_vals = ()\n",
      "        vals = ', '.join('%.3g' % val for val in shapes_vals)\n",
      "        tempdict['vals'] = vals\n",
      "\n",
      "        tempdict['shapes_'] = self.shapes or ''\n",
      "        if self.shapes and self.numargs == 1:\n",
      "            tempdict['shapes_'] += ','\n",
      "\n",
      "        if self.shapes:\n",
      "            tempdict['set_vals_stmt'] = '>>> %s = %s' % (self.shapes, vals)\n",
      "        else:\n",
      "            tempdict['set_vals_stmt'] = ''\n",
      "\n",
      "        if self.shapes is None:\n",
      "            # remove shapes from call parameters if there are none\n",
      "            for item in ['default', 'before_notes']:\n",
      "                tempdict[item] = tempdict[item].replace(\n",
      "                    \"\\n%(shapes)s : array_like\\n    shape parameters\", \"\")\n",
      "        for i in range(2):\n",
      "            if self.shapes is None:\n",
      "                # necessary because we use %(shapes)s in two forms (w w/o \", \")\n",
      "                self.__doc__ = self.__doc__.replace(\"%(shapes)s, \", \"\")\n",
      "            try:\n",
      "                self.__doc__ = doccer.docformat(self.__doc__, tempdict)\n",
      "            except TypeError as e:\n",
      "                raise Exception(\"Unable to construct docstring for distribution \\\"%s\\\": %s\" % (self.name, repr(e)))\n",
      "\n",
      "        # correct for empty shapes\n",
      "        self.__doc__ = self.__doc__.replace('(, ', '(').replace(', )', ')')\n",
      "\n",
      "    def _construct_default_doc(self, longname=None, extradoc=None,\n",
      "                               docdict=None, discrete='continuous'):\n",
      "        \"\"\"Construct instance docstring from the default template.\"\"\"\n",
      "        if longname is None:\n",
      "            longname = 'A'\n",
      "        if extradoc is None:\n",
      "            extradoc = ''\n",
      "        if extradoc.startswith('\\n\\n'):\n",
      "            extradoc = extradoc[2:]\n",
      "        self.__doc__ = ''.join(['%s %s random variable.' % (longname, discrete),\n",
      "                                '\\n\\n%(before_notes)s\\n', docheaders['notes'],\n",
      "                                extradoc, '\\n%(example)s'])\n",
      "        self._construct_doc(docdict)\n",
      "\n",
      "    def freeze(self, *args, **kwds):\n",
      "        \"\"\"Freeze the distribution for the given arguments.\n",
      "\n",
      "        Parameters\n",
      "        ----------\n",
      "        arg1, arg2, arg3,... : array_like\n",
      "            The shape parameter(s) for the distribution.  Should include all\n",
      "            the non-optional arguments, may include ``loc`` and ``scale``.\n",
      "\n",
      "        Returns\n",
      "        -------\n",
      "        rv_frozen : rv_frozen instance\n",
      "            The frozen distribution.\n",
      "\n",
      "        \"\"\"\n",
      "        return rv_frozen(self, *args, **kwds)\n",
      "\n",
      "    def __call__(self, *args, **kwds):\n",
      "        return self.freeze(*args, **kwds)\n",
      "    __call__.__doc__ = freeze.__doc__\n",
      "\n",
      "    # The actual calculation functions (no basic checking need be done)\n",
      "    # If these are defined, the others won't be looked at.\n",
      "    # Otherwise, the other set can be defined.\n",
      "    def _stats(self, *args, **kwds):\n",
      "        return None, None, None, None\n",
      "\n",
      "    # Noncentral moments (also known as the moment about the origin).\n",
      "    # Expressed in LaTeX, munp would be $\\mu'_{n}$, i.e. \"mu-sub-n-prime\".\n",
      "    # The primed mu is a widely used notation for the noncentral moment.\n",
      "    def _munp(self, n, *args):\n",
      "        # Silence floating point warnings from integration.\n",
      "        with np.errstate(all='ignore'):\n",
      "            vals = self.generic_moment(n, *args)\n",
      "        return vals\n",
      "\n",
      "    def _argcheck_rvs(self, *args, **kwargs):\n",
      "        # Handle broadcasting and size validation of the rvs method.\n",
      "        # Subclasses should not have to override this method.\n",
      "        # The rule is that if `size` is not None, then `size` gives the\n",
      "        # shape of the result (integer values of `size` are treated as\n",
      "        # tuples with length 1; i.e. `size=3` is the same as `size=(3,)`.)\n",
      "        #\n",
      "        # `args` is expected to contain the shape parameters (if any), the\n",
      "        # location and the scale in a flat tuple (e.g. if there are two\n",
      "        # shape parameters `a` and `b`, `args` will be `(a, b, loc, scale)`).\n",
      "        # The only keyword argument expected is 'size'.\n",
      "        size = kwargs.get('size', None)\n",
      "        all_bcast = np.broadcast_arrays(*args)\n",
      "\n",
      "        def squeeze_left(a):\n",
      "            while a.ndim > 0 and a.shape[0] == 1:\n",
      "                a = a[0]\n",
      "            return a\n",
      "\n",
      "        # Eliminate trivial leading dimensions.  In the convention\n",
      "        # used by numpy's random variate generators, trivial leading\n",
      "        # dimensions are effectively ignored.  In other words, when `size`\n",
      "        # is given, trivial leading dimensions of the broadcast parameters\n",
      "        # in excess of the number of dimensions  in size are ignored, e.g.\n",
      "        #   >>> np.random.normal([[1, 3, 5]], [[[[0.01]]]], size=3)\n",
      "        #   array([ 1.00104267,  3.00422496,  4.99799278])\n",
      "        # If `size` is not given, the exact broadcast shape is preserved:\n",
      "        #   >>> np.random.normal([[1, 3, 5]], [[[[0.01]]]])\n",
      "        #   array([[[[ 1.00862899,  3.00061431,  4.99867122]]]])\n",
      "        #\n",
      "        all_bcast = [squeeze_left(a) for a in all_bcast]\n",
      "        bcast_shape = all_bcast[0].shape\n",
      "        bcast_ndim = all_bcast[0].ndim\n",
      "\n",
      "        if size is None:\n",
      "            size_ = bcast_shape\n",
      "        else:\n",
      "            size_ = tuple(np.atleast_1d(size))\n",
      "\n",
      "        # Check compatibility of size_ with the broadcast shape of all\n",
      "        # the parameters.  This check is intended to be consistent with\n",
      "        # how the numpy random variate generators (e.g. np.random.normal,\n",
      "        # np.random.beta) handle their arguments.   The rule is that, if size\n",
      "        # is given, it determines the shape of the output.  Broadcasting\n",
      "        # can't change the output size.\n",
      "\n",
      "        # This is the standard broadcasting convention of extending the\n",
      "        # shape with fewer dimensions with enough dimensions of length 1\n",
      "        # so that the two shapes have the same number of dimensions.\n",
      "        ndiff = bcast_ndim - len(size_)\n",
      "        if ndiff < 0:\n",
      "            bcast_shape = (1,)*(-ndiff) + bcast_shape\n",
      "        elif ndiff > 0:\n",
      "            size_ = (1,)*ndiff + size_\n",
      "\n",
      "        # This compatibility test is not standard.  In \"regular\" broadcasting,\n",
      "        # two shapes are compatible if for each dimension, the lengths are the\n",
      "        # same or one of the lengths is 1.  Here, the length of a dimension in\n",
      "        # size_ must not be less than the corresponding length in bcast_shape.\n",
      "        ok = all([bcdim == 1 or bcdim == szdim\n",
      "                  for (bcdim, szdim) in zip(bcast_shape, size_)])\n",
      "        if not ok:\n",
      "            raise ValueError(\"size does not match the broadcast shape of \"\n",
      "                             \"the parameters. %s, %s, %s\" % (size, size_, bcast_shape))\n",
      "\n",
      "        param_bcast = all_bcast[:-2]\n",
      "        loc_bcast = all_bcast[-2]\n",
      "        scale_bcast = all_bcast[-1]\n",
      "\n",
      "        return param_bcast, loc_bcast, scale_bcast, size_\n",
      "\n",
      "    ## These are the methods you must define (standard form functions)\n",
      "    ## NB: generic _pdf, _logpdf, _cdf are different for\n",
      "    ## rv_continuous and rv_discrete hence are defined in there\n",
      "    def _argcheck(self, *args):\n",
      "        \"\"\"Default check for correct values on args and keywords.\n",
      "\n",
      "        Returns condition array of 1's where arguments are correct and\n",
      "         0's where they are not.\n",
      "\n",
      "        \"\"\"\n",
      "        cond = 1\n",
      "        for arg in args:\n",
      "            cond = logical_and(cond, (asarray(arg) > 0))\n",
      "        return cond\n",
      "\n",
      "    def _get_support(self, *args, **kwargs):\n",
      "        \"\"\"Return the support of the (unscaled, unshifted) distribution.\n",
      "\n",
      "        *Must* be overridden by distributions which have support dependent\n",
      "        upon the shape parameters of the distribution.  Any such override\n",
      "        *must not* set or change any of the class members, as these members\n",
      "        are shared amongst all instances of the distribution.\n",
      "\n",
      "        Parameters\n",
      "        ----------\n",
      "        arg1, arg2, ... : array_like\n",
      "            The shape parameter(s) for the distribution (see docstring of the\n",
      "            instance object for more information).\n",
      "        Returns\n",
      "        -------\n",
      "        a, b : numeric (float, or int or +/-np.inf)\n",
      "            end-points of the distribution's support for the specified\n",
      "            shape parameters.\n",
      "        \"\"\"\n",
      "        return self.a, self.b\n",
      "\n",
      "    def _support_mask(self, x, *args):\n",
      "        a, b = self._get_support(*args)\n",
      "        with np.errstate(invalid='ignore'):\n",
      "            return (a <= x) & (x <= b)\n",
      "\n",
      "    def _open_support_mask(self, x, *args):\n",
      "        a, b = self._get_support(*args)\n",
      "        with np.errstate(invalid='ignore'):\n",
      "            return (a < x) & (x < b)\n",
      "\n",
      "    def _rvs(self, *args, size=None, random_state=None):\n",
      "        # This method must handle size being a tuple, and it must\n",
      "        # properly broadcast *args and size.  size might be\n",
      "        # an empty tuple, which means a scalar random variate is to be\n",
      "        # generated.\n",
      "\n",
      "        ## Use basic inverse cdf algorithm for RV generation as default.\n",
      "        U = random_state.uniform(size=size)\n",
      "        Y = self._ppf(U, *args)\n",
      "        return Y\n",
      "\n",
      "    def _logcdf(self, x, *args):\n",
      "        with np.errstate(divide='ignore'):\n",
      "            return log(self._cdf(x, *args))\n",
      "\n",
      "    def _sf(self, x, *args):\n",
      "        return 1.0-self._cdf(x, *args)\n",
      "\n",
      "    def _logsf(self, x, *args):\n",
      "        with np.errstate(divide='ignore'):\n",
      "            return log(self._sf(x, *args))\n",
      "\n",
      "    def _ppf(self, q, *args):\n",
      "        return self._ppfvec(q, *args)\n",
      "\n",
      "    def _isf(self, q, *args):\n",
      "        return self._ppf(1.0-q, *args)  # use correct _ppf for subclasses\n",
      "\n",
      "    # These are actually called, and should not be overwritten if you\n",
      "    # want to keep error checking.\n",
      "    def rvs(self, *args, **kwds):\n",
      "        \"\"\"\n",
      "        Random variates of given type.\n",
      "\n",
      "        Parameters\n",
      "        ----------\n",
      "        arg1, arg2, arg3,... : array_like\n",
      "            The shape parameter(s) for the distribution (see docstring of the\n",
      "            instance object for more information).\n",
      "        loc : array_like, optional\n",
      "            Location parameter (default=0).\n",
      "        scale : array_like, optional\n",
      "            Scale parameter (default=1).\n",
      "        size : int or tuple of ints, optional\n",
      "            Defining number of random variates (default is 1).\n",
      "        random_state : {None, int, `~np.random.RandomState`, `~np.random.Generator`}, optional\n",
      "            If `seed` is `None` the `~np.random.RandomState` singleton is used.\n",
      "            If `seed` is an int, a new ``RandomState`` instance is used, seeded\n",
      "            with seed.\n",
      "            If `seed` is already a ``RandomState`` or ``Generator`` instance,\n",
      "            then that object is used.\n",
      "            Default is None.\n",
      "\n",
      "        Returns\n",
      "        -------\n",
      "        rvs : ndarray or scalar\n",
      "            Random variates of given `size`.\n",
      "\n",
      "        \"\"\"\n",
      "        discrete = kwds.pop('discrete', None)\n",
      "        rndm = kwds.pop('random_state', None)\n",
      "        args, loc, scale, size = self._parse_args_rvs(*args, **kwds)\n",
      "        cond = logical_and(self._argcheck(*args), (scale >= 0))\n",
      "        if not np.all(cond):\n",
      "            raise ValueError(\"Domain error in arguments.\")\n",
      "\n",
      "        if np.all(scale == 0):\n",
      "            return loc*ones(size, 'd')\n",
      "\n",
      "        # extra gymnastics needed for a custom random_state\n",
      "        if rndm is not None:\n",
      "            random_state_saved = self._random_state\n",
      "            random_state = check_random_state(rndm)\n",
      "        else:\n",
      "            random_state = self._random_state\n",
      "\n",
      "        # Maintain backwards compatibility by setting self._size\n",
      "        # for distributions that still need it.\n",
      "        if self._rvs_uses_size_attribute:\n",
      "            if not self._rvs_size_warned:\n",
      "                warnings.warn(\n",
      "                    f'The signature of {self._rvs} does not contain '\n",
      "                    f'a \"size\" keyword.  Such signatures are deprecated.',\n",
      "                    np.VisibleDeprecationWarning)\n",
      "                self._rvs_size_warned = True\n",
      "            self._size = size\n",
      "            self._random_state = random_state\n",
      "            vals = self._rvs(*args)\n",
      "        else:\n",
      "            vals = self._rvs(*args, size=size, random_state=random_state)\n",
      "\n",
      "        vals = vals * scale + loc\n",
      "\n",
      "        # do not forget to restore the _random_state\n",
      "        if rndm is not None:\n",
      "            self._random_state = random_state_saved\n",
      "\n",
      "        # Cast to int if discrete\n",
      "        if discrete:\n",
      "            if size == ():\n",
      "                vals = int(vals)\n",
      "            else:\n",
      "                vals = vals.astype(int)\n",
      "\n",
      "        return vals\n",
      "\n",
      "    def stats(self, *args, **kwds):\n",
      "        \"\"\"\n",
      "        Some statistics of the given RV.\n",
      "\n",
      "        Parameters\n",
      "        ----------\n",
      "        arg1, arg2, arg3,... : array_like\n",
      "            The shape parameter(s) for the distribution (see docstring of the\n",
      "            instance object for more information)\n",
      "        loc : array_like, optional\n",
      "            location parameter (default=0)\n",
      "        scale : array_like, optional (continuous RVs only)\n",
      "            scale parameter (default=1)\n",
      "        moments : str, optional\n",
      "            composed of letters ['mvsk'] defining which moments to compute:\n",
      "            'm' = mean,\n",
      "            'v' = variance,\n",
      "            's' = (Fisher's) skew,\n",
      "            'k' = (Fisher's) kurtosis.\n",
      "            (default is 'mv')\n",
      "\n",
      "        Returns\n",
      "        -------\n",
      "        stats : sequence\n",
      "            of requested moments.\n",
      "\n",
      "        \"\"\"\n",
      "        args, loc, scale, moments = self._parse_args_stats(*args, **kwds)\n",
      "        # scale = 1 by construction for discrete RVs\n",
      "        loc, scale = map(asarray, (loc, scale))\n",
      "        args = tuple(map(asarray, args))\n",
      "        cond = self._argcheck(*args) & (scale > 0) & (loc == loc)\n",
      "        output = []\n",
      "        default = valarray(shape(cond), self.badvalue)\n",
      "\n",
      "        # Use only entries that are valid in calculation\n",
      "        if np.any(cond):\n",
      "            goodargs = argsreduce(cond, *(args+(scale, loc)))\n",
      "            scale, loc, goodargs = goodargs[-2], goodargs[-1], goodargs[:-2]\n",
      "\n",
      "            if self._stats_has_moments:\n",
      "                mu, mu2, g1, g2 = self._stats(*goodargs,\n",
      "                                              **{'moments': moments})\n",
      "            else:\n",
      "                mu, mu2, g1, g2 = self._stats(*goodargs)\n",
      "            if g1 is None:\n",
      "                mu3 = None\n",
      "            else:\n",
      "                if mu2 is None:\n",
      "                    mu2 = self._munp(2, *goodargs)\n",
      "                if g2 is None:\n",
      "                    # (mu2**1.5) breaks down for nan and inf\n",
      "                    mu3 = g1 * np.power(mu2, 1.5)\n",
      "\n",
      "            if 'm' in moments:\n",
      "                if mu is None:\n",
      "                    mu = self._munp(1, *goodargs)\n",
      "                out0 = default.copy()\n",
      "                place(out0, cond, mu * scale + loc)\n",
      "                output.append(out0)\n",
      "\n",
      "            if 'v' in moments:\n",
      "                if mu2 is None:\n",
      "                    mu2p = self._munp(2, *goodargs)\n",
      "                    if mu is None:\n",
      "                        mu = self._munp(1, *goodargs)\n",
      "                    # if mean is inf then var is also inf\n",
      "                    with np.errstate(invalid='ignore'):\n",
      "                        mu2 = np.where(np.isfinite(mu), mu2p - mu**2, np.inf)\n",
      "                out0 = default.copy()\n",
      "                place(out0, cond, mu2 * scale * scale)\n",
      "                output.append(out0)\n",
      "\n",
      "            if 's' in moments:\n",
      "                if g1 is None:\n",
      "                    mu3p = self._munp(3, *goodargs)\n",
      "                    if mu is None:\n",
      "                        mu = self._munp(1, *goodargs)\n",
      "                    if mu2 is None:\n",
      "                        mu2p = self._munp(2, *goodargs)\n",
      "                        mu2 = mu2p - mu * mu\n",
      "                    with np.errstate(invalid='ignore'):\n",
      "                        mu3 = (-mu*mu - 3*mu2)*mu + mu3p\n",
      "                        g1 = mu3 / np.power(mu2, 1.5)\n",
      "                out0 = default.copy()\n",
      "                place(out0, cond, g1)\n",
      "                output.append(out0)\n",
      "\n",
      "            if 'k' in moments:\n",
      "                if g2 is None:\n",
      "                    mu4p = self._munp(4, *goodargs)\n",
      "                    if mu is None:\n",
      "                        mu = self._munp(1, *goodargs)\n",
      "                    if mu2 is None:\n",
      "                        mu2p = self._munp(2, *goodargs)\n",
      "                        mu2 = mu2p - mu * mu\n",
      "                    if mu3 is None:\n",
      "                        mu3p = self._munp(3, *goodargs)\n",
      "                        with np.errstate(invalid='ignore'):\n",
      "                            mu3 = (-mu * mu - 3 * mu2) * mu + mu3p\n",
      "                    with np.errstate(invalid='ignore'):\n",
      "                        mu4 = ((-mu**2 - 6*mu2) * mu - 4*mu3)*mu + mu4p\n",
      "                        g2 = mu4 / mu2**2.0 - 3.0\n",
      "                out0 = default.copy()\n",
      "                place(out0, cond, g2)\n",
      "                output.append(out0)\n",
      "        else:  # no valid args\n",
      "            output = [default.copy() for _ in moments]\n",
      "\n",
      "        if len(output) == 1:\n",
      "            return output[0]\n",
      "        else:\n",
      "            return tuple(output)\n",
      "\n",
      "    def entropy(self, *args, **kwds):\n",
      "        \"\"\"\n",
      "        Differential entropy of the RV.\n",
      "\n",
      "        Parameters\n",
      "        ----------\n",
      "        arg1, arg2, arg3,... : array_like\n",
      "            The shape parameter(s) for the distribution (see docstring of the\n",
      "            instance object for more information).\n",
      "        loc : array_like, optional\n",
      "            Location parameter (default=0).\n",
      "        scale : array_like, optional  (continuous distributions only).\n",
      "            Scale parameter (default=1).\n",
      "\n",
      "        Notes\n",
      "        -----\n",
      "        Entropy is defined base `e`:\n",
      "\n",
      "        >>> drv = rv_discrete(values=((0, 1), (0.5, 0.5)))\n",
      "        >>> np.allclose(drv.entropy(), np.log(2.0))\n",
      "        True\n",
      "\n",
      "        \"\"\"\n",
      "        args, loc, scale = self._parse_args(*args, **kwds)\n",
      "        # NB: for discrete distributions scale=1 by construction in _parse_args\n",
      "        loc, scale = map(asarray, (loc, scale))\n",
      "        args = tuple(map(asarray, args))\n",
      "        cond0 = self._argcheck(*args) & (scale > 0) & (loc == loc)\n",
      "        output = zeros(shape(cond0), 'd')\n",
      "        place(output, (1-cond0), self.badvalue)\n",
      "        goodargs = argsreduce(cond0, scale, *args)\n",
      "        goodscale = goodargs[0]\n",
      "        goodargs = goodargs[1:]\n",
      "        place(output, cond0, self.vecentropy(*goodargs) + log(goodscale))\n",
      "        return output\n",
      "\n",
      "    def moment(self, n, *args, **kwds):\n",
      "        \"\"\"\n",
      "        n-th order non-central moment of distribution.\n",
      "\n",
      "        Parameters\n",
      "        ----------\n",
      "        n : int, n >= 1\n",
      "            Order of moment.\n",
      "        arg1, arg2, arg3,... : float\n",
      "            The shape parameter(s) for the distribution (see docstring of the\n",
      "            instance object for more information).\n",
      "        loc : array_like, optional\n",
      "            location parameter (default=0)\n",
      "        scale : array_like, optional\n",
      "            scale parameter (default=1)\n",
      "\n",
      "        \"\"\"\n",
      "        args, loc, scale = self._parse_args(*args, **kwds)\n",
      "        if not (self._argcheck(*args) and (scale > 0)):\n",
      "            return nan\n",
      "        if (floor(n) != n):\n",
      "            raise ValueError(\"Moment must be an integer.\")\n",
      "        if (n < 0):\n",
      "            raise ValueError(\"Moment must be positive.\")\n",
      "        mu, mu2, g1, g2 = None, None, None, None\n",
      "        if (n > 0) and (n < 5):\n",
      "            if self._stats_has_moments:\n",
      "                mdict = {'moments': {1: 'm', 2: 'v', 3: 'vs', 4: 'vk'}[n]}\n",
      "            else:\n",
      "                mdict = {}\n",
      "            mu, mu2, g1, g2 = self._stats(*args, **mdict)\n",
      "        val = _moment_from_stats(n, mu, mu2, g1, g2, self._munp, args)\n",
      "\n",
      "        # Convert to transformed  X = L + S*Y\n",
      "        # E[X^n] = E[(L+S*Y)^n] = L^n sum(comb(n, k)*(S/L)^k E[Y^k], k=0...n)\n",
      "        if loc == 0:\n",
      "            return scale**n * val\n",
      "        else:\n",
      "            result = 0\n",
      "            fac = float(scale) / float(loc)\n",
      "            for k in range(n):\n",
      "                valk = _moment_from_stats(k, mu, mu2, g1, g2, self._munp, args)\n",
      "                result += comb(n, k, exact=True)*(fac**k) * valk\n",
      "            result += fac**n * val\n",
      "            return result * loc**n\n",
      "\n",
      "    def median(self, *args, **kwds):\n",
      "        \"\"\"\n",
      "        Median of the distribution.\n",
      "\n",
      "        Parameters\n",
      "        ----------\n",
      "        arg1, arg2, arg3,... : array_like\n",
      "            The shape parameter(s) for the distribution (see docstring of the\n",
      "            instance object for more information)\n",
      "        loc : array_like, optional\n",
      "            Location parameter, Default is 0.\n",
      "        scale : array_like, optional\n",
      "            Scale parameter, Default is 1.\n",
      "\n",
      "        Returns\n",
      "        -------\n",
      "        median : float\n",
      "            The median of the distribution.\n",
      "\n",
      "        See Also\n",
      "        --------\n",
      "        rv_discrete.ppf\n",
      "            Inverse of the CDF\n",
      "\n",
      "        \"\"\"\n",
      "        return self.ppf(0.5, *args, **kwds)\n",
      "\n",
      "    def mean(self, *args, **kwds):\n",
      "        \"\"\"\n",
      "        Mean of the distribution.\n",
      "\n",
      "        Parameters\n",
      "        ----------\n",
      "        arg1, arg2, arg3,... : array_like\n",
      "            The shape parameter(s) for the distribution (see docstring of the\n",
      "            instance object for more information)\n",
      "        loc : array_like, optional\n",
      "            location parameter (default=0)\n",
      "        scale : array_like, optional\n",
      "            scale parameter (default=1)\n",
      "\n",
      "        Returns\n",
      "        -------\n",
      "        mean : float\n",
      "            the mean of the distribution\n",
      "\n",
      "        \"\"\"\n",
      "        kwds['moments'] = 'm'\n",
      "        res = self.stats(*args, **kwds)\n",
      "        if isinstance(res, ndarray) and res.ndim == 0:\n",
      "            return res[()]\n",
      "        return res\n",
      "\n",
      "    def var(self, *args, **kwds):\n",
      "        \"\"\"\n",
      "        Variance of the distribution.\n",
      "\n",
      "        Parameters\n",
      "        ----------\n",
      "        arg1, arg2, arg3,... : array_like\n",
      "            The shape parameter(s) for the distribution (see docstring of the\n",
      "            instance object for more information)\n",
      "        loc : array_like, optional\n",
      "            location parameter (default=0)\n",
      "        scale : array_like, optional\n",
      "            scale parameter (default=1)\n",
      "\n",
      "        Returns\n",
      "        -------\n",
      "        var : float\n",
      "            the variance of the distribution\n",
      "\n",
      "        \"\"\"\n",
      "        kwds['moments'] = 'v'\n",
      "        res = self.stats(*args, **kwds)\n",
      "        if isinstance(res, ndarray) and res.ndim == 0:\n",
      "            return res[()]\n",
      "        return res\n",
      "\n",
      "    def std(self, *args, **kwds):\n",
      "        \"\"\"\n",
      "        Standard deviation of the distribution.\n",
      "\n",
      "        Parameters\n",
      "        ----------\n",
      "        arg1, arg2, arg3,... : array_like\n",
      "            The shape parameter(s) for the distribution (see docstring of the\n",
      "            instance object for more information)\n",
      "        loc : array_like, optional\n",
      "            location parameter (default=0)\n",
      "        scale : array_like, optional\n",
      "            scale parameter (default=1)\n",
      "\n",
      "        Returns\n",
      "        -------\n",
      "        std : float\n",
      "            standard deviation of the distribution\n",
      "\n",
      "        \"\"\"\n",
      "        kwds['moments'] = 'v'\n",
      "        res = sqrt(self.stats(*args, **kwds))\n",
      "        return res\n",
      "\n",
      "    def interval(self, alpha, *args, **kwds):\n",
      "        \"\"\"\n",
      "        Confidence interval with equal areas around the median.\n",
      "\n",
      "        Parameters\n",
      "        ----------\n",
      "        alpha : array_like of float\n",
      "            Probability that an rv will be drawn from the returned range.\n",
      "            Each value should be in the range [0, 1].\n",
      "        arg1, arg2, ... : array_like\n",
      "            The shape parameter(s) for the distribution (see docstring of the\n",
      "            instance object for more information).\n",
      "        loc : array_like, optional\n",
      "            location parameter, Default is 0.\n",
      "        scale : array_like, optional\n",
      "            scale parameter, Default is 1.\n",
      "\n",
      "        Returns\n",
      "        -------\n",
      "        a, b : ndarray of float\n",
      "            end-points of range that contain ``100 * alpha %`` of the rv's\n",
      "            possible values.\n",
      "\n",
      "        \"\"\"\n",
      "        alpha = asarray(alpha)\n",
      "        if np.any((alpha > 1) | (alpha < 0)):\n",
      "            raise ValueError(\"alpha must be between 0 and 1 inclusive\")\n",
      "        q1 = (1.0-alpha)/2\n",
      "        q2 = (1.0+alpha)/2\n",
      "        a = self.ppf(q1, *args, **kwds)\n",
      "        b = self.ppf(q2, *args, **kwds)\n",
      "        return a, b\n",
      "\n",
      "    def support(self, *args, **kwargs):\n",
      "        \"\"\"\n",
      "        Return the support of the distribution.\n",
      "\n",
      "        Parameters\n",
      "        ----------\n",
      "        arg1, arg2, ... : array_like\n",
      "            The shape parameter(s) for the distribution (see docstring of the\n",
      "            instance object for more information).\n",
      "        loc : array_like, optional\n",
      "            location parameter, Default is 0.\n",
      "        scale : array_like, optional\n",
      "            scale parameter, Default is 1.\n",
      "        Returns\n",
      "        -------\n",
      "        a, b : float\n",
      "            end-points of the distribution's support.\n",
      "\n",
      "        \"\"\"\n",
      "        args, loc, scale = self._parse_args(*args, **kwargs)\n",
      "        _a, _b = self._get_support(*args)\n",
      "        return _a * scale + loc, _b * scale + loc\n",
      "\n",
      "\n",
      "def _get_fixed_fit_value(kwds, names):\n",
      "    \"\"\"\n",
      "    Given names such as `['f0', 'fa', 'fix_a']`, check that there is\n",
      "    at most one non-None value in `kwds` associaed with those names.\n",
      "    Return that value, or None if none of the names occur in `kwds`.\n",
      "    As a side effect, all occurrences of those names in `kwds` are\n",
      "    removed.\n",
      "    \"\"\"\n",
      "    vals = [(name, kwds.pop(name)) for name in names if name in kwds]\n",
      "    if len(vals) > 1:\n",
      "        repeated = [name for name, val in vals]\n",
      "        raise ValueError(\"fit method got multiple keyword arguments to \"\n",
      "                         \"specify the same fixed parameter: \" +\n",
      "                         ', '.join(repeated))\n",
      "    return vals[0][1] if vals else None\n",
      "\n",
      "\n",
      "##  continuous random variables: implement maybe later\n",
      "##\n",
      "##  hf  --- Hazard Function (PDF / SF)\n",
      "##  chf  --- Cumulative hazard function (-log(SF))\n",
      "##  psf --- Probability sparsity function (reciprocal of the pdf) in\n",
      "##                units of percent-point-function (as a function of q).\n",
      "##                Also, the derivative of the percent-point function.\n",
      "\n",
      "class rv_continuous(rv_generic):\n",
      "    \"\"\"\n",
      "    A generic continuous random variable class meant for subclassing.\n",
      "\n",
      "    `rv_continuous` is a base class to construct specific distribution classes\n",
      "    and instances for continuous random variables. It cannot be used\n",
      "    directly as a distribution.\n",
      "\n",
      "    Parameters\n",
      "    ----------\n",
      "    momtype : int, optional\n",
      "        The type of generic moment calculation to use: 0 for pdf, 1 (default)\n",
      "        for ppf.\n",
      "    a : float, optional\n",
      "        Lower bound of the support of the distribution, default is minus\n",
      "        infinity.\n",
      "    b : float, optional\n",
      "        Upper bound of the support of the distribution, default is plus\n",
      "        infinity.\n",
      "    xtol : float, optional\n",
      "        The tolerance for fixed point calculation for generic ppf.\n",
      "    badvalue : float, optional\n",
      "        The value in a result arrays that indicates a value that for which\n",
      "        some argument restriction is violated, default is np.nan.\n",
      "    name : str, optional\n",
      "        The name of the instance. This string is used to construct the default\n",
      "        example for distributions.\n",
      "    longname : str, optional\n",
      "        This string is used as part of the first line of the docstring returned\n",
      "        when a subclass has no docstring of its own. Note: `longname` exists\n",
      "        for backwards compatibility, do not use for new subclasses.\n",
      "    shapes : str, optional\n",
      "        The shape of the distribution. For example ``\"m, n\"`` for a\n",
      "        distribution that takes two integers as the two shape arguments for all\n",
      "        its methods. If not provided, shape parameters will be inferred from\n",
      "        the signature of the private methods, ``_pdf`` and ``_cdf`` of the\n",
      "        instance.\n",
      "    extradoc :  str, optional, deprecated\n",
      "        This string is used as the last part of the docstring returned when a\n",
      "        subclass has no docstring of its own. Note: `extradoc` exists for\n",
      "        backwards compatibility, do not use for new subclasses.\n",
      "    seed : {None, int, `~np.random.RandomState`, `~np.random.Generator`}, optional\n",
      "        This parameter defines the object to use for drawing random variates.\n",
      "        If `seed` is `None` the `~np.random.RandomState` singleton is used.\n",
      "        If `seed` is an int, a new ``RandomState`` instance is used, seeded\n",
      "        with seed.\n",
      "        If `seed` is already a ``RandomState`` or ``Generator`` instance,\n",
      "        then that object is used.\n",
      "        Default is None.\n",
      "\n",
      "    Methods\n",
      "    -------\n",
      "    rvs\n",
      "    pdf\n",
      "    logpdf\n",
      "    cdf\n",
      "    logcdf\n",
      "    sf\n",
      "    logsf\n",
      "    ppf\n",
      "    isf\n",
      "    moment\n",
      "    stats\n",
      "    entropy\n",
      "    expect\n",
      "    median\n",
      "    mean\n",
      "    std\n",
      "    var\n",
      "    interval\n",
      "    __call__\n",
      "    fit\n",
      "    fit_loc_scale\n",
      "    nnlf\n",
      "    support\n",
      "\n",
      "    Notes\n",
      "    -----\n",
      "    Public methods of an instance of a distribution class (e.g., ``pdf``,\n",
      "    ``cdf``) check their arguments and pass valid arguments to private,\n",
      "    computational methods (``_pdf``, ``_cdf``). For ``pdf(x)``, ``x`` is valid\n",
      "    if it is within the support of the distribution.\n",
      "    Whether a shape parameter is valid is decided by an ``_argcheck`` method\n",
      "    (which defaults to checking that its arguments are strictly positive.)\n",
      "\n",
      "    **Subclassing**\n",
      "\n",
      "    New random variables can be defined by subclassing the `rv_continuous` class\n",
      "    and re-defining at least the ``_pdf`` or the ``_cdf`` method (normalized\n",
      "    to location 0 and scale 1).\n",
      "\n",
      "    If positive argument checking is not correct for your RV\n",
      "    then you will also need to re-define the ``_argcheck`` method.\n",
      "\n",
      "    For most of the scipy.stats distributions, the support interval doesn't\n",
      "    depend on the shape parameters. ``x`` being in the support interval is\n",
      "    equivalent to ``self.a <= x <= self.b``.  If either of the endpoints of\n",
      "    the support do depend on the shape parameters, then\n",
      "    i) the distribution must implement the ``_get_support`` method; and\n",
      "    ii) those dependent endpoints must be omitted from the distribution's\n",
      "    call to the ``rv_continuous`` initializer.\n",
      "\n",
      "    Correct, but potentially slow defaults exist for the remaining\n",
      "    methods but for speed and/or accuracy you can over-ride::\n",
      "\n",
      "      _logpdf, _cdf, _logcdf, _ppf, _rvs, _isf, _sf, _logsf\n",
      "\n",
      "    The default method ``_rvs`` relies on the inverse of the cdf, ``_ppf``,\n",
      "    applied to a uniform random variate. In order to generate random variates\n",
      "    efficiently, either the default ``_ppf`` needs to be overwritten (e.g.\n",
      "    if the inverse cdf can expressed in an explicit form) or a sampling\n",
      "    method needs to be implemented in a custom ``_rvs`` method.\n",
      "\n",
      "    If possible, you should override ``_isf``, ``_sf`` or ``_logsf``.\n",
      "    The main reason would be to improve numerical accuracy: for example,\n",
      "    the survival function ``_sf`` is computed as ``1 - _cdf`` which can\n",
      "    result in loss of precision if ``_cdf(x)`` is close to one.\n",
      "\n",
      "    **Methods that can be overwritten by subclasses**\n",
      "    ::\n",
      "\n",
      "      _rvs\n",
      "      _pdf\n",
      "      _cdf\n",
      "      _sf\n",
      "      _ppf\n",
      "      _isf\n",
      "      _stats\n",
      "      _munp\n",
      "      _entropy\n",
      "      _argcheck\n",
      "      _get_support\n",
      "\n",
      "    There are additional (internal and private) generic methods that can\n",
      "    be useful for cross-checking and for debugging, but might work in all\n",
      "    cases when directly called.\n",
      "\n",
      "    A note on ``shapes``: subclasses need not specify them explicitly. In this\n",
      "    case, `shapes` will be automatically deduced from the signatures of the\n",
      "    overridden methods (`pdf`, `cdf` etc).\n",
      "    If, for some reason, you prefer to avoid relying on introspection, you can\n",
      "    specify ``shapes`` explicitly as an argument to the instance constructor.\n",
      "\n",
      "\n",
      "    **Frozen Distributions**\n",
      "\n",
      "    Normally, you must provide shape parameters (and, optionally, location and\n",
      "    scale parameters to each call of a method of a distribution.\n",
      "\n",
      "    Alternatively, the object may be called (as a function) to fix the shape,\n",
      "    location, and scale parameters returning a \"frozen\" continuous RV object:\n",
      "\n",
      "    rv = generic(<shape(s)>, loc=0, scale=1)\n",
      "        `rv_frozen` object with the same methods but holding the given shape,\n",
      "        location, and scale fixed\n",
      "\n",
      "    **Statistics**\n",
      "\n",
      "    Statistics are computed using numerical integration by default.\n",
      "    For speed you can redefine this using ``_stats``:\n",
      "\n",
      "     - take shape parameters and return mu, mu2, g1, g2\n",
      "     - If you can't compute one of these, return it as None\n",
      "     - Can also be defined with a keyword argument ``moments``, which is a\n",
      "       string composed of \"m\", \"v\", \"s\", and/or \"k\".\n",
      "       Only the components appearing in string should be computed and\n",
      "       returned in the order \"m\", \"v\", \"s\", or \"k\"  with missing values\n",
      "       returned as None.\n",
      "\n",
      "    Alternatively, you can override ``_munp``, which takes ``n`` and shape\n",
      "    parameters and returns the n-th non-central moment of the distribution.\n",
      "\n",
      "    Examples\n",
      "    --------\n",
      "    To create a new Gaussian distribution, we would do the following:\n",
      "\n",
      "    >>> from scipy.stats import rv_continuous\n",
      "    >>> class gaussian_gen(rv_continuous):\n",
      "    ...     \"Gaussian distribution\"\n",
      "    ...     def _pdf(self, x):\n",
      "    ...         return np.exp(-x**2 / 2.) / np.sqrt(2.0 * np.pi)\n",
      "    >>> gaussian = gaussian_gen(name='gaussian')\n",
      "\n",
      "    ``scipy.stats`` distributions are *instances*, so here we subclass\n",
      "    `rv_continuous` and create an instance. With this, we now have\n",
      "    a fully functional distribution with all relevant methods automagically\n",
      "    generated by the framework.\n",
      "\n",
      "    Note that above we defined a standard normal distribution, with zero mean\n",
      "    and unit variance. Shifting and scaling of the distribution can be done\n",
      "    by using ``loc`` and ``scale`` parameters: ``gaussian.pdf(x, loc, scale)``\n",
      "    essentially computes ``y = (x - loc) / scale`` and\n",
      "    ``gaussian._pdf(y) / scale``.\n",
      "\n",
      "    \"\"\"\n",
      "    def __init__(self, momtype=1, a=None, b=None, xtol=1e-14,\n",
      "                 badvalue=None, name=None, longname=None,\n",
      "                 shapes=None, extradoc=None, seed=None):\n",
      "\n",
      "        super(rv_continuous, self).__init__(seed)\n",
      "\n",
      "        # save the ctor parameters, cf generic freeze\n",
      "        self._ctor_param = dict(\n",
      "            momtype=momtype, a=a, b=b, xtol=xtol,\n",
      "            badvalue=badvalue, name=name, longname=longname,\n",
      "            shapes=shapes, extradoc=extradoc, seed=seed)\n",
      "\n",
      "        if badvalue is None:\n",
      "            badvalue = nan\n",
      "        if name is None:\n",
      "            name = 'Distribution'\n",
      "        self.badvalue = badvalue\n",
      "        self.name = name\n",
      "        self.a = a\n",
      "        self.b = b\n",
      "        if a is None:\n",
      "            self.a = -inf\n",
      "        if b is None:\n",
      "            self.b = inf\n",
      "        self.xtol = xtol\n",
      "        self.moment_type = momtype\n",
      "        self.shapes = shapes\n",
      "        self._construct_argparser(meths_to_inspect=[self._pdf, self._cdf],\n",
      "                                  locscale_in='loc=0, scale=1',\n",
      "                                  locscale_out='loc, scale')\n",
      "\n",
      "        # nin correction\n",
      "        self._ppfvec = vectorize(self._ppf_single, otypes='d')\n",
      "        self._ppfvec.nin = self.numargs + 1\n",
      "        self.vecentropy = vectorize(self._entropy, otypes='d')\n",
      "        self._cdfvec = vectorize(self._cdf_single, otypes='d')\n",
      "        self._cdfvec.nin = self.numargs + 1\n",
      "\n",
      "        self.extradoc = extradoc\n",
      "        if momtype == 0:\n",
      "            self.generic_moment = vectorize(self._mom0_sc, otypes='d')\n",
      "        else:\n",
      "            self.generic_moment = vectorize(self._mom1_sc, otypes='d')\n",
      "        # Because of the *args argument of _mom0_sc, vectorize cannot count the\n",
      "        # number of arguments correctly.\n",
      "        self.generic_moment.nin = self.numargs + 1\n",
      "\n",
      "        if longname is None:\n",
      "            if name[0] in ['aeiouAEIOU']:\n",
      "                hstr = \"An \"\n",
      "            else:\n",
      "                hstr = \"A \"\n",
      "            longname = hstr + name\n",
      "\n",
      "        if sys.flags.optimize < 2:\n",
      "            # Skip adding docstrings if interpreter is run with -OO\n",
      "            if self.__doc__ is None:\n",
      "                self._construct_default_doc(longname=longname,\n",
      "                                            extradoc=extradoc,\n",
      "                                            docdict=docdict,\n",
      "                                            discrete='continuous')\n",
      "            else:\n",
      "                dct = dict(distcont)\n",
      "                self._construct_doc(docdict, dct.get(self.name))\n",
      "\n",
      "    def _updated_ctor_param(self):\n",
      "        \"\"\" Return the current version of _ctor_param, possibly updated by user.\n",
      "\n",
      "            Used by freezing and pickling.\n",
      "            Keep this in sync with the signature of __init__.\n",
      "        \"\"\"\n",
      "        dct = self._ctor_param.copy()\n",
      "        dct['a'] = self.a\n",
      "        dct['b'] = self.b\n",
      "        dct['xtol'] = self.xtol\n",
      "        dct['badvalue'] = self.badvalue\n",
      "        dct['name'] = self.name\n",
      "        dct['shapes'] = self.shapes\n",
      "        dct['extradoc'] = self.extradoc\n",
      "        return dct\n",
      "\n",
      "    def _ppf_to_solve(self, x, q, *args):\n",
      "        return self.cdf(*(x, )+args)-q\n",
      "\n",
      "    def _ppf_single(self, q, *args):\n",
      "        factor = 10.\n",
      "        left, right = self._get_support(*args)\n",
      "\n",
      "        if np.isinf(left):\n",
      "            left = min(-factor, right)\n",
      "            while self._ppf_to_solve(left, q, *args) > 0.:\n",
      "                left, right = left * factor, left\n",
      "            # left is now such that cdf(left) <= q\n",
      "            # if right has changed, then cdf(right) > q\n",
      "\n",
      "        if np.isinf(right):\n",
      "            right = max(factor, left)\n",
      "            while self._ppf_to_solve(right, q, *args) < 0.:\n",
      "                left, right = right, right * factor\n",
      "            # right is now such that cdf(right) >= q\n",
      "\n",
      "        return optimize.brentq(self._ppf_to_solve,\n",
      "                               left, right, args=(q,)+args, xtol=self.xtol)\n",
      "\n",
      "    # moment from definition\n",
      "    def _mom_integ0(self, x, m, *args):\n",
      "        return x**m * self.pdf(x, *args)\n",
      "\n",
      "    def _mom0_sc(self, m, *args):\n",
      "        _a, _b = self._get_support(*args)\n",
      "        return integrate.quad(self._mom_integ0, _a, _b,\n",
      "                              args=(m,)+args)[0]\n",
      "\n",
      "    # moment calculated using ppf\n",
      "    def _mom_integ1(self, q, m, *args):\n",
      "        return (self.ppf(q, *args))**m\n",
      "\n",
      "    def _mom1_sc(self, m, *args):\n",
      "        return integrate.quad(self._mom_integ1, 0, 1, args=(m,)+args)[0]\n",
      "\n",
      "    def _pdf(self, x, *args):\n",
      "        return derivative(self._cdf, x, dx=1e-5, args=args, order=5)\n",
      "\n",
      "    ## Could also define any of these\n",
      "    def _logpdf(self, x, *args):\n",
      "        return log(self._pdf(x, *args))\n",
      "\n",
      "    def _cdf_single(self, x, *args):\n",
      "        _a, _b = self._get_support(*args)\n",
      "        return integrate.quad(self._pdf, _a, x, args=args)[0]\n",
      "\n",
      "    def _cdf(self, x, *args):\n",
      "        return self._cdfvec(x, *args)\n",
      "\n",
      "    ## generic _argcheck, _logcdf, _sf, _logsf, _ppf, _isf, _rvs are defined\n",
      "    ## in rv_generic\n",
      "\n",
      "    def pdf(self, x, *args, **kwds):\n",
      "        \"\"\"\n",
      "        Probability density function at x of the given RV.\n",
      "\n",
      "        Parameters\n",
      "        ----------\n",
      "        x : array_like\n",
      "            quantiles\n",
      "        arg1, arg2, arg3,... : array_like\n",
      "            The shape parameter(s) for the distribution (see docstring of the\n",
      "            instance object for more information)\n",
      "        loc : array_like, optional\n",
      "            location parameter (default=0)\n",
      "        scale : array_like, optional\n",
      "            scale parameter (default=1)\n",
      "\n",
      "        Returns\n",
      "        -------\n",
      "        pdf : ndarray\n",
      "            Probability density function evaluated at x\n",
      "\n",
      "        \"\"\"\n",
      "        args, loc, scale = self._parse_args(*args, **kwds)\n",
      "        x, loc, scale = map(asarray, (x, loc, scale))\n",
      "        args = tuple(map(asarray, args))\n",
      "        dtyp = np.find_common_type([x.dtype, np.float64], [])\n",
      "        x = np.asarray((x - loc)/scale, dtype=dtyp)\n",
      "        cond0 = self._argcheck(*args) & (scale > 0)\n",
      "        cond1 = self._support_mask(x, *args) & (scale > 0)\n",
      "        cond = cond0 & cond1\n",
      "        output = zeros(shape(cond), dtyp)\n",
      "        putmask(output, (1-cond0)+np.isnan(x), self.badvalue)\n",
      "        if np.any(cond):\n",
      "            goodargs = argsreduce(cond, *((x,)+args+(scale,)))\n",
      "            scale, goodargs = goodargs[-1], goodargs[:-1]\n",
      "            place(output, cond, self._pdf(*goodargs) / scale)\n",
      "        if output.ndim == 0:\n",
      "            return output[()]\n",
      "        return output\n",
      "\n",
      "    def logpdf(self, x, *args, **kwds):\n",
      "        \"\"\"\n",
      "        Log of the probability density function at x of the given RV.\n",
      "\n",
      "        This uses a more numerically accurate calculation if available.\n",
      "\n",
      "        Parameters\n",
      "        ----------\n",
      "        x : array_like\n",
      "            quantiles\n",
      "        arg1, arg2, arg3,... : array_like\n",
      "            The shape parameter(s) for the distribution (see docstring of the\n",
      "            instance object for more information)\n",
      "        loc : array_like, optional\n",
      "            location parameter (default=0)\n",
      "        scale : array_like, optional\n",
      "            scale parameter (default=1)\n",
      "\n",
      "        Returns\n",
      "        -------\n",
      "        logpdf : array_like\n",
      "            Log of the probability density function evaluated at x\n",
      "\n",
      "        \"\"\"\n",
      "        args, loc, scale = self._parse_args(*args, **kwds)\n",
      "        x, loc, scale = map(asarray, (x, loc, scale))\n",
      "        args = tuple(map(asarray, args))\n",
      "        dtyp = np.find_common_type([x.dtype, np.float64], [])\n",
      "        x = np.asarray((x - loc)/scale, dtype=dtyp)\n",
      "        cond0 = self._argcheck(*args) & (scale > 0)\n",
      "        cond1 = self._support_mask(x, *args) & (scale > 0)\n",
      "        cond = cond0 & cond1\n",
      "        output = empty(shape(cond), dtyp)\n",
      "        output.fill(NINF)\n",
      "        putmask(output, (1-cond0)+np.isnan(x), self.badvalue)\n",
      "        if np.any(cond):\n",
      "            goodargs = argsreduce(cond, *((x,)+args+(scale,)))\n",
      "            scale, goodargs = goodargs[-1], goodargs[:-1]\n",
      "            place(output, cond, self._logpdf(*goodargs) - log(scale))\n",
      "        if output.ndim == 0:\n",
      "            return output[()]\n",
      "        return output\n",
      "\n",
      "    def cdf(self, x, *args, **kwds):\n",
      "        \"\"\"\n",
      "        Cumulative distribution function of the given RV.\n",
      "\n",
      "        Parameters\n",
      "        ----------\n",
      "        x : array_like\n",
      "            quantiles\n",
      "        arg1, arg2, arg3,... : array_like\n",
      "            The shape parameter(s) for the distribution (see docstring of the\n",
      "            instance object for more information)\n",
      "        loc : array_like, optional\n",
      "            location parameter (default=0)\n",
      "        scale : array_like, optional\n",
      "            scale parameter (default=1)\n",
      "\n",
      "        Returns\n",
      "        -------\n",
      "        cdf : ndarray\n",
      "            Cumulative distribution function evaluated at `x`\n",
      "\n",
      "        \"\"\"\n",
      "        args, loc, scale = self._parse_args(*args, **kwds)\n",
      "        x, loc, scale = map(asarray, (x, loc, scale))\n",
      "        args = tuple(map(asarray, args))\n",
      "        _a, _b = self._get_support(*args)\n",
      "        dtyp = np.find_common_type([x.dtype, np.float64], [])\n",
      "        x = np.asarray((x - loc)/scale, dtype=dtyp)\n",
      "        cond0 = self._argcheck(*args) & (scale > 0)\n",
      "        cond1 = self._open_support_mask(x, *args) & (scale > 0)\n",
      "        cond2 = (x >= np.asarray(_b)) & cond0\n",
      "        cond = cond0 & cond1\n",
      "        output = zeros(shape(cond), dtyp)\n",
      "        place(output, (1-cond0)+np.isnan(x), self.badvalue)\n",
      "        place(output, cond2, 1.0)\n",
      "        if np.any(cond):  # call only if at least 1 entry\n",
      "            goodargs = argsreduce(cond, *((x,)+args))\n",
      "            place(output, cond, self._cdf(*goodargs))\n",
      "        if output.ndim == 0:\n",
      "            return output[()]\n",
      "        return output\n",
      "\n",
      "    def logcdf(self, x, *args, **kwds):\n",
      "        \"\"\"\n",
      "        Log of the cumulative distribution function at x of the given RV.\n",
      "\n",
      "        Parameters\n",
      "        ----------\n",
      "        x : array_like\n",
      "            quantiles\n",
      "        arg1, arg2, arg3,... : array_like\n",
      "            The shape parameter(s) for the distribution (see docstring of the\n",
      "            instance object for more information)\n",
      "        loc : array_like, optional\n",
      "            location parameter (default=0)\n",
      "        scale : array_like, optional\n",
      "            scale parameter (default=1)\n",
      "\n",
      "        Returns\n",
      "        -------\n",
      "        logcdf : array_like\n",
      "            Log of the cumulative distribution function evaluated at x\n",
      "\n",
      "        \"\"\"\n",
      "        args, loc, scale = self._parse_args(*args, **kwds)\n",
      "        x, loc, scale = map(asarray, (x, loc, scale))\n",
      "        args = tuple(map(asarray, args))\n",
      "        _a, _b = self._get_support(*args)\n",
      "        dtyp = np.find_common_type([x.dtype, np.float64], [])\n",
      "        x = np.asarray((x - loc)/scale, dtype=dtyp)\n",
      "        cond0 = self._argcheck(*args) & (scale > 0)\n",
      "        cond1 = self._open_support_mask(x, *args) & (scale > 0)\n",
      "        cond2 = (x >= _b) & cond0\n",
      "        cond = cond0 & cond1\n",
      "        output = empty(shape(cond), dtyp)\n",
      "        output.fill(NINF)\n",
      "        place(output, (1-cond0)*(cond1 == cond1)+np.isnan(x), self.badvalue)\n",
      "        place(output, cond2, 0.0)\n",
      "        if np.any(cond):  # call only if at least 1 entry\n",
      "            goodargs = argsreduce(cond, *((x,)+args))\n",
      "            place(output, cond, self._logcdf(*goodargs))\n",
      "        if output.ndim == 0:\n",
      "            return output[()]\n",
      "        return output\n",
      "\n",
      "    def sf(self, x, *args, **kwds):\n",
      "        \"\"\"\n",
      "        Survival function (1 - `cdf`) at x of the given RV.\n",
      "\n",
      "        Parameters\n",
      "        ----------\n",
      "        x : array_like\n",
      "            quantiles\n",
      "        arg1, arg2, arg3,... : array_like\n",
      "            The shape parameter(s) for the distribution (see docstring of the\n",
      "            instance object for more information)\n",
      "        loc : array_like, optional\n",
      "            location parameter (default=0)\n",
      "        scale : array_like, optional\n",
      "            scale parameter (default=1)\n",
      "\n",
      "        Returns\n",
      "        -------\n",
      "        sf : array_like\n",
      "            Survival function evaluated at x\n",
      "\n",
      "        \"\"\"\n",
      "        args, loc, scale = self._parse_args(*args, **kwds)\n",
      "        x, loc, scale = map(asarray, (x, loc, scale))\n",
      "        args = tuple(map(asarray, args))\n",
      "        _a, _b = self._get_support(*args)\n",
      "        dtyp = np.find_common_type([x.dtype, np.float64], [])\n",
      "        x = np.asarray((x - loc)/scale, dtype=dtyp)\n",
      "        cond0 = self._argcheck(*args) & (scale > 0)\n",
      "        cond1 = self._open_support_mask(x, *args) & (scale > 0)\n",
      "        cond2 = cond0 & (x <= _a)\n",
      "        cond = cond0 & cond1\n",
      "        output = zeros(shape(cond), dtyp)\n",
      "        place(output, (1-cond0)+np.isnan(x), self.badvalue)\n",
      "        place(output, cond2, 1.0)\n",
      "        if np.any(cond):\n",
      "            goodargs = argsreduce(cond, *((x,)+args))\n",
      "            place(output, cond, self._sf(*goodargs))\n",
      "        if output.ndim == 0:\n",
      "            return output[()]\n",
      "        return output\n",
      "\n",
      "    def logsf(self, x, *args, **kwds):\n",
      "        \"\"\"\n",
      "        Log of the survival function of the given RV.\n",
      "\n",
      "        Returns the log of the \"survival function,\" defined as (1 - `cdf`),\n",
      "        evaluated at `x`.\n",
      "\n",
      "        Parameters\n",
      "        ----------\n",
      "        x : array_like\n",
      "            quantiles\n",
      "        arg1, arg2, arg3,... : array_like\n",
      "            The shape parameter(s) for the distribution (see docstring of the\n",
      "            instance object for more information)\n",
      "        loc : array_like, optional\n",
      "            location parameter (default=0)\n",
      "        scale : array_like, optional\n",
      "            scale parameter (default=1)\n",
      "\n",
      "        Returns\n",
      "        -------\n",
      "        logsf : ndarray\n",
      "            Log of the survival function evaluated at `x`.\n",
      "\n",
      "        \"\"\"\n",
      "        args, loc, scale = self._parse_args(*args, **kwds)\n",
      "        x, loc, scale = map(asarray, (x, loc, scale))\n",
      "        args = tuple(map(asarray, args))\n",
      "        _a, _b = self._get_support(*args)\n",
      "        dtyp = np.find_common_type([x.dtype, np.float64], [])\n",
      "        x = np.asarray((x - loc)/scale, dtype=dtyp)\n",
      "        cond0 = self._argcheck(*args) & (scale > 0)\n",
      "        cond1 = self._open_support_mask(x, *args) & (scale > 0)\n",
      "        cond2 = cond0 & (x <= _a)\n",
      "        cond = cond0 & cond1\n",
      "        output = empty(shape(cond), dtyp)\n",
      "        output.fill(NINF)\n",
      "        place(output, (1-cond0)+np.isnan(x), self.badvalue)\n",
      "        place(output, cond2, 0.0)\n",
      "        if np.any(cond):\n",
      "            goodargs = argsreduce(cond, *((x,)+args))\n",
      "            place(output, cond, self._logsf(*goodargs))\n",
      "        if output.ndim == 0:\n",
      "            return output[()]\n",
      "        return output\n",
      "\n",
      "    def ppf(self, q, *args, **kwds):\n",
      "        \"\"\"\n",
      "        Percent point function (inverse of `cdf`) at q of the given RV.\n",
      "\n",
      "        Parameters\n",
      "        ----------\n",
      "        q : array_like\n",
      "            lower tail probability\n",
      "        arg1, arg2, arg3,... : array_like\n",
      "            The shape parameter(s) for the distribution (see docstring of the\n",
      "            instance object for more information)\n",
      "        loc : array_like, optional\n",
      "            location parameter (default=0)\n",
      "        scale : array_like, optional\n",
      "            scale parameter (default=1)\n",
      "\n",
      "        Returns\n",
      "        -------\n",
      "        x : array_like\n",
      "            quantile corresponding to the lower tail probability q.\n",
      "\n",
      "        \"\"\"\n",
      "        args, loc, scale = self._parse_args(*args, **kwds)\n",
      "        q, loc, scale = map(asarray, (q, loc, scale))\n",
      "        args = tuple(map(asarray, args))\n",
      "        _a, _b = self._get_support(*args)\n",
      "        cond0 = self._argcheck(*args) & (scale > 0) & (loc == loc)\n",
      "        cond1 = (0 < q) & (q < 1)\n",
      "        cond2 = cond0 & (q == 0)\n",
      "        cond3 = cond0 & (q == 1)\n",
      "        cond = cond0 & cond1\n",
      "        output = valarray(shape(cond), value=self.badvalue)\n",
      "\n",
      "        lower_bound = _a * scale + loc\n",
      "        upper_bound = _b * scale + loc\n",
      "        place(output, cond2, argsreduce(cond2, lower_bound)[0])\n",
      "        place(output, cond3, argsreduce(cond3, upper_bound)[0])\n",
      "\n",
      "        if np.any(cond):  # call only if at least 1 entry\n",
      "            goodargs = argsreduce(cond, *((q,)+args+(scale, loc)))\n",
      "            scale, loc, goodargs = goodargs[-2], goodargs[-1], goodargs[:-2]\n",
      "            place(output, cond, self._ppf(*goodargs) * scale + loc)\n",
      "        if output.ndim == 0:\n",
      "            return output[()]\n",
      "        return output\n",
      "\n",
      "    def isf(self, q, *args, **kwds):\n",
      "        \"\"\"\n",
      "        Inverse survival function (inverse of `sf`) at q of the given RV.\n",
      "\n",
      "        Parameters\n",
      "        ----------\n",
      "        q : array_like\n",
      "            upper tail probability\n",
      "        arg1, arg2, arg3,... : array_like\n",
      "            The shape parameter(s) for the distribution (see docstring of the\n",
      "            instance object for more information)\n",
      "        loc : array_like, optional\n",
      "            location parameter (default=0)\n",
      "        scale : array_like, optional\n",
      "            scale parameter (default=1)\n",
      "\n",
      "        Returns\n",
      "        -------\n",
      "        x : ndarray or scalar\n",
      "            Quantile corresponding to the upper tail probability q.\n",
      "\n",
      "        \"\"\"\n",
      "        args, loc, scale = self._parse_args(*args, **kwds)\n",
      "        q, loc, scale = map(asarray, (q, loc, scale))\n",
      "        args = tuple(map(asarray, args))\n",
      "        _a, _b = self._get_support(*args)\n",
      "        cond0 = self._argcheck(*args) & (scale > 0) & (loc == loc)\n",
      "        cond1 = (0 < q) & (q < 1)\n",
      "        cond2 = cond0 & (q == 1)\n",
      "        cond3 = cond0 & (q == 0)\n",
      "        cond = cond0 & cond1\n",
      "        output = valarray(shape(cond), value=self.badvalue)\n",
      "\n",
      "        lower_bound = _a * scale + loc\n",
      "        upper_bound = _b * scale + loc\n",
      "        place(output, cond2, argsreduce(cond2, lower_bound)[0])\n",
      "        place(output, cond3, argsreduce(cond3, upper_bound)[0])\n",
      "\n",
      "        if np.any(cond):\n",
      "            goodargs = argsreduce(cond, *((q,)+args+(scale, loc)))\n",
      "            scale, loc, goodargs = goodargs[-2], goodargs[-1], goodargs[:-2]\n",
      "            place(output, cond, self._isf(*goodargs) * scale + loc)\n",
      "        if output.ndim == 0:\n",
      "            return output[()]\n",
      "        return output\n",
      "\n",
      "    def _nnlf(self, x, *args):\n",
      "        return -np.sum(self._logpdf(x, *args), axis=0)\n",
      "\n",
      "    def _unpack_loc_scale(self, theta):\n",
      "        try:\n",
      "            loc = theta[-2]\n",
      "            scale = theta[-1]\n",
      "            args = tuple(theta[:-2])\n",
      "        except IndexError:\n",
      "            raise ValueError(\"Not enough input arguments.\")\n",
      "        return loc, scale, args\n",
      "\n",
      "    def nnlf(self, theta, x):\n",
      "        '''Return negative loglikelihood function.\n",
      "\n",
      "        Notes\n",
      "        -----\n",
      "        This is ``-sum(log pdf(x, theta), axis=0)`` where `theta` are the\n",
      "        parameters (including loc and scale).\n",
      "        '''\n",
      "        loc, scale, args = self._unpack_loc_scale(theta)\n",
      "        if not self._argcheck(*args) or scale <= 0:\n",
      "            return inf\n",
      "        x = asarray((x-loc) / scale)\n",
      "        n_log_scale = len(x) * log(scale)\n",
      "        if np.any(~self._support_mask(x, *args)):\n",
      "            return inf\n",
      "        return self._nnlf(x, *args) + n_log_scale\n",
      "\n",
      "    def _nnlf_and_penalty(self, x, args):\n",
      "        cond0 = ~self._support_mask(x, *args)\n",
      "        n_bad = np.count_nonzero(cond0, axis=0)\n",
      "        if n_bad > 0:\n",
      "            x = argsreduce(~cond0, x)[0]\n",
      "        logpdf = self._logpdf(x, *args)\n",
      "        finite_logpdf = np.isfinite(logpdf)\n",
      "        n_bad += np.sum(~finite_logpdf, axis=0)\n",
      "        if n_bad > 0:\n",
      "            penalty = n_bad * log(_XMAX) * 100\n",
      "            return -np.sum(logpdf[finite_logpdf], axis=0) + penalty\n",
      "        return -np.sum(logpdf, axis=0)\n",
      "\n",
      "    def _penalized_nnlf(self, theta, x):\n",
      "        ''' Return penalized negative loglikelihood function,\n",
      "        i.e., - sum (log pdf(x, theta), axis=0) + penalty\n",
      "           where theta are the parameters (including loc and scale)\n",
      "        '''\n",
      "        loc, scale, args = self._unpack_loc_scale(theta)\n",
      "        if not self._argcheck(*args) or scale <= 0:\n",
      "            return inf\n",
      "        x = asarray((x-loc) / scale)\n",
      "        n_log_scale = len(x) * log(scale)\n",
      "        return self._nnlf_and_penalty(x, args) + n_log_scale\n",
      "\n",
      "    # return starting point for fit (shape arguments + loc + scale)\n",
      "    def _fitstart(self, data, args=None):\n",
      "        if args is None:\n",
      "            args = (1.0,)*self.numargs\n",
      "        loc, scale = self._fit_loc_scale_support(data, *args)\n",
      "        return args + (loc, scale)\n",
      "\n",
      "    def _reduce_func(self, args, kwds):\n",
      "        \"\"\"\n",
      "        Return the (possibly reduced) function to optimize in order to find MLE\n",
      "        estimates for the .fit method.\n",
      "        \"\"\"\n",
      "        # Convert fixed shape parameters to the standard numeric form: e.g. for\n",
      "        # stats.beta, shapes='a, b'. To fix `a`, the caller can give a value\n",
      "        # for `f0`, `fa` or 'fix_a'.  The following converts the latter two\n",
      "        # into the first (numeric) form.\n",
      "        if self.shapes:\n",
      "            shapes = self.shapes.replace(',', ' ').split()\n",
      "            for j, s in enumerate(shapes):\n",
      "                key = 'f' + str(j)\n",
      "                names = [key, 'f' + s, 'fix_' + s]\n",
      "                val = _get_fixed_fit_value(kwds, names)\n",
      "                if val is not None:\n",
      "                    kwds[key] = val\n",
      "\n",
      "        args = list(args)\n",
      "        Nargs = len(args)\n",
      "        fixedn = []\n",
      "        names = ['f%d' % n for n in range(Nargs - 2)] + ['floc', 'fscale']\n",
      "        x0 = []\n",
      "        for n, key in enumerate(names):\n",
      "            if key in kwds:\n",
      "                fixedn.append(n)\n",
      "                args[n] = kwds.pop(key)\n",
      "            else:\n",
      "                x0.append(args[n])\n",
      "\n",
      "        if len(fixedn) == 0:\n",
      "            func = self._penalized_nnlf\n",
      "            restore = None\n",
      "        else:\n",
      "            if len(fixedn) == Nargs:\n",
      "                raise ValueError(\n",
      "                    \"All parameters fixed. There is nothing to optimize.\")\n",
      "\n",
      "            def restore(args, theta):\n",
      "                # Replace with theta for all numbers not in fixedn\n",
      "                # This allows the non-fixed values to vary, but\n",
      "                #  we still call self.nnlf with all parameters.\n",
      "                i = 0\n",
      "                for n in range(Nargs):\n",
      "                    if n not in fixedn:\n",
      "                        args[n] = theta[i]\n",
      "                        i += 1\n",
      "                return args\n",
      "\n",
      "            def func(theta, x):\n",
      "                newtheta = restore(args[:], theta)\n",
      "                return self._penalized_nnlf(newtheta, x)\n",
      "\n",
      "        return x0, func, restore, args\n",
      "\n",
      "    def fit(self, data, *args, **kwds):\n",
      "        \"\"\"\n",
      "        Return MLEs for shape (if applicable), location, and scale\n",
      "        parameters from data.\n",
      "\n",
      "        MLE stands for Maximum Likelihood Estimate.  Starting estimates for\n",
      "        the fit are given by input arguments; for any arguments not provided\n",
      "        with starting estimates, ``self._fitstart(data)`` is called to generate\n",
      "        such.\n",
      "\n",
      "        One can hold some parameters fixed to specific values by passing in\n",
      "        keyword arguments ``f0``, ``f1``, ..., ``fn`` (for shape parameters)\n",
      "        and ``floc`` and ``fscale`` (for location and scale parameters,\n",
      "        respectively).\n",
      "\n",
      "        Parameters\n",
      "        ----------\n",
      "        data : array_like\n",
      "            Data to use in calculating the MLEs.\n",
      "        arg1, arg2, arg3,... : floats, optional\n",
      "            Starting value(s) for any shape-characterizing arguments (those not\n",
      "            provided will be determined by a call to ``_fitstart(data)``).\n",
      "            No default value.\n",
      "        kwds : floats, optional\n",
      "            - `loc`: initial guess of the distribution's location parameter.\n",
      "            - `scale`: initial guess of the distribution's scale parameter.\n",
      "\n",
      "            Special keyword arguments are recognized as holding certain\n",
      "            parameters fixed:\n",
      "\n",
      "            - f0...fn : hold respective shape parameters fixed.\n",
      "              Alternatively, shape parameters to fix can be specified by name.\n",
      "              For example, if ``self.shapes == \"a, b\"``, ``fa`` and ``fix_a``\n",
      "              are equivalent to ``f0``, and ``fb`` and ``fix_b`` are\n",
      "              equivalent to ``f1``.\n",
      "\n",
      "            - floc : hold location parameter fixed to specified value.\n",
      "\n",
      "            - fscale : hold scale parameter fixed to specified value.\n",
      "\n",
      "            - optimizer : The optimizer to use.  The optimizer must take ``func``,\n",
      "              and starting position as the first two arguments,\n",
      "              plus ``args`` (for extra arguments to pass to the\n",
      "              function to be optimized) and ``disp=0`` to suppress\n",
      "              output as keyword arguments.\n",
      "\n",
      "        Returns\n",
      "        -------\n",
      "        mle_tuple : tuple of floats\n",
      "            MLEs for any shape parameters (if applicable), followed by those\n",
      "            for location and scale. For most random variables, shape statistics\n",
      "            will be returned, but there are exceptions (e.g. ``norm``).\n",
      "\n",
      "        Notes\n",
      "        -----\n",
      "        This fit is computed by maximizing a log-likelihood function, with\n",
      "        penalty applied for samples outside of range of the distribution. The\n",
      "        returned answer is not guaranteed to be the globally optimal MLE, it\n",
      "        may only be locally optimal, or the optimization may fail altogether.\n",
      "        If the data contain any of np.nan, np.inf, or -np.inf, the fit routine\n",
      "        will throw a RuntimeError.\n",
      "\n",
      "        Examples\n",
      "        --------\n",
      "\n",
      "        Generate some data to fit: draw random variates from the `beta`\n",
      "        distribution\n",
      "\n",
      "        >>> from scipy.stats import beta\n",
      "        >>> a, b = 1., 2.\n",
      "        >>> x = beta.rvs(a, b, size=1000)\n",
      "\n",
      "        Now we can fit all four parameters (``a``, ``b``, ``loc`` and ``scale``):\n",
      "\n",
      "        >>> a1, b1, loc1, scale1 = beta.fit(x)\n",
      "\n",
      "        We can also use some prior knowledge about the dataset: let's keep\n",
      "        ``loc`` and ``scale`` fixed:\n",
      "\n",
      "        >>> a1, b1, loc1, scale1 = beta.fit(x, floc=0, fscale=1)\n",
      "        >>> loc1, scale1\n",
      "        (0, 1)\n",
      "\n",
      "        We can also keep shape parameters fixed by using ``f``-keywords. To\n",
      "        keep the zero-th shape parameter ``a`` equal 1, use ``f0=1`` or,\n",
      "        equivalently, ``fa=1``:\n",
      "\n",
      "        >>> a1, b1, loc1, scale1 = beta.fit(x, fa=1, floc=0, fscale=1)\n",
      "        >>> a1\n",
      "        1\n",
      "\n",
      "        Not all distributions return estimates for the shape parameters.\n",
      "        ``norm`` for example just returns estimates for location and scale:\n",
      "\n",
      "        >>> from scipy.stats import norm\n",
      "        >>> x = norm.rvs(a, b, size=1000, random_state=123)\n",
      "        >>> loc1, scale1 = norm.fit(x)\n",
      "        >>> loc1, scale1\n",
      "        (0.92087172783841631, 2.0015750750324668)\n",
      "        \"\"\"\n",
      "        Narg = len(args)\n",
      "        if Narg > self.numargs:\n",
      "            raise TypeError(\"Too many input arguments.\")\n",
      "\n",
      "        if not np.isfinite(data).all():\n",
      "            raise RuntimeError(\"The data contains non-finite values.\")\n",
      "\n",
      "        start = [None]*2\n",
      "        if (Narg < self.numargs) or not ('loc' in kwds and\n",
      "                                         'scale' in kwds):\n",
      "            # get distribution specific starting locations\n",
      "            start = self._fitstart(data)\n",
      "            args += start[Narg:-2]\n",
      "        loc = kwds.pop('loc', start[-2])\n",
      "        scale = kwds.pop('scale', start[-1])\n",
      "        args += (loc, scale)\n",
      "        x0, func, restore, args = self._reduce_func(args, kwds)\n",
      "\n",
      "        optimizer = kwds.pop('optimizer', optimize.fmin)\n",
      "        # convert string to function in scipy.optimize\n",
      "        if not callable(optimizer) and isinstance(optimizer, str):\n",
      "            if not optimizer.startswith('fmin_'):\n",
      "                optimizer = \"fmin_\"+optimizer\n",
      "            if optimizer == 'fmin_':\n",
      "                optimizer = 'fmin'\n",
      "            try:\n",
      "                optimizer = getattr(optimize, optimizer)\n",
      "            except AttributeError:\n",
      "                raise ValueError(\"%s is not a valid optimizer\" % optimizer)\n",
      "\n",
      "        # by now kwds must be empty, since everybody took what they needed\n",
      "        if kwds:\n",
      "            raise TypeError(\"Unknown arguments: %s.\" % kwds)\n",
      "\n",
      "        vals = optimizer(func, x0, args=(ravel(data),), disp=0)\n",
      "        if restore is not None:\n",
      "            vals = restore(args, vals)\n",
      "        vals = tuple(vals)\n",
      "        return vals\n",
      "\n",
      "    def _fit_loc_scale_support(self, data, *args):\n",
      "        \"\"\"\n",
      "        Estimate loc and scale parameters from data accounting for support.\n",
      "\n",
      "        Parameters\n",
      "        ----------\n",
      "        data : array_like\n",
      "            Data to fit.\n",
      "        arg1, arg2, arg3,... : array_like\n",
      "            The shape parameter(s) for the distribution (see docstring of the\n",
      "            instance object for more information).\n",
      "\n",
      "        Returns\n",
      "        -------\n",
      "        Lhat : float\n",
      "            Estimated location parameter for the data.\n",
      "        Shat : float\n",
      "            Estimated scale parameter for the data.\n",
      "\n",
      "        \"\"\"\n",
      "        data = np.asarray(data)\n",
      "\n",
      "        # Estimate location and scale according to the method of moments.\n",
      "        loc_hat, scale_hat = self.fit_loc_scale(data, *args)\n",
      "\n",
      "        # Compute the support according to the shape parameters.\n",
      "        self._argcheck(*args)\n",
      "        _a, _b = self._get_support(*args)\n",
      "        a, b = _a, _b\n",
      "        support_width = b - a\n",
      "\n",
      "        # If the support is empty then return the moment-based estimates.\n",
      "        if support_width <= 0:\n",
      "            return loc_hat, scale_hat\n",
      "\n",
      "        # Compute the proposed support according to the loc and scale\n",
      "        # estimates.\n",
      "        a_hat = loc_hat + a * scale_hat\n",
      "        b_hat = loc_hat + b * scale_hat\n",
      "\n",
      "        # Use the moment-based estimates if they are compatible with the data.\n",
      "        data_a = np.min(data)\n",
      "        data_b = np.max(data)\n",
      "        if a_hat < data_a and data_b < b_hat:\n",
      "            return loc_hat, scale_hat\n",
      "\n",
      "        # Otherwise find other estimates that are compatible with the data.\n",
      "        data_width = data_b - data_a\n",
      "        rel_margin = 0.1\n",
      "        margin = data_width * rel_margin\n",
      "\n",
      "        # For a finite interval, both the location and scale\n",
      "        # should have interesting values.\n",
      "        if support_width < np.inf:\n",
      "            loc_hat = (data_a - a) - margin\n",
      "            scale_hat = (data_width + 2 * margin) / support_width\n",
      "            return loc_hat, scale_hat\n",
      "\n",
      "        # For a one-sided interval, use only an interesting location parameter.\n",
      "        if a > -np.inf:\n",
      "            return (data_a - a) - margin, 1\n",
      "        elif b < np.inf:\n",
      "            return (data_b - b) + margin, 1\n",
      "        else:\n",
      "            raise RuntimeError\n",
      "\n",
      "    def fit_loc_scale(self, data, *args):\n",
      "        \"\"\"\n",
      "        Estimate loc and scale parameters from data using 1st and 2nd moments.\n",
      "\n",
      "        Parameters\n",
      "        ----------\n",
      "        data : array_like\n",
      "            Data to fit.\n",
      "        arg1, arg2, arg3,... : array_like\n",
      "            The shape parameter(s) for the distribution (see docstring of the\n",
      "            instance object for more information).\n",
      "\n",
      "        Returns\n",
      "        -------\n",
      "        Lhat : float\n",
      "            Estimated location parameter for the data.\n",
      "        Shat : float\n",
      "            Estimated scale parameter for the data.\n",
      "\n",
      "        \"\"\"\n",
      "        mu, mu2 = self.stats(*args, **{'moments': 'mv'})\n",
      "        tmp = asarray(data)\n",
      "        muhat = tmp.mean()\n",
      "        mu2hat = tmp.var()\n",
      "        Shat = sqrt(mu2hat / mu2)\n",
      "        Lhat = muhat - Shat*mu\n",
      "        if not np.isfinite(Lhat):\n",
      "            Lhat = 0\n",
      "        if not (np.isfinite(Shat) and (0 < Shat)):\n",
      "            Shat = 1\n",
      "        return Lhat, Shat\n",
      "\n",
      "    def _entropy(self, *args):\n",
      "        def integ(x):\n",
      "            val = self._pdf(x, *args)\n",
      "            return entr(val)\n",
      "\n",
      "        # upper limit is often inf, so suppress warnings when integrating\n",
      "        _a, _b = self._get_support(*args)\n",
      "        with np.errstate(over='ignore'):\n",
      "            h = integrate.quad(integ, _a, _b)[0]\n",
      "\n",
      "        if not np.isnan(h):\n",
      "            return h\n",
      "        else:\n",
      "            # try with different limits if integration problems\n",
      "            low, upp = self.ppf([1e-10, 1. - 1e-10], *args)\n",
      "            if np.isinf(_b):\n",
      "                upper = upp\n",
      "            else:\n",
      "                upper = _b\n",
      "            if np.isinf(_a):\n",
      "                lower = low\n",
      "            else:\n",
      "                lower = _a\n",
      "            return integrate.quad(integ, lower, upper)[0]\n",
      "\n",
      "    def expect(self, func=None, args=(), loc=0, scale=1, lb=None, ub=None,\n",
      "               conditional=False, **kwds):\n",
      "        \"\"\"Calculate expected value of a function with respect to the\n",
      "        distribution by numerical integration.\n",
      "\n",
      "        The expected value of a function ``f(x)`` with respect to a\n",
      "        distribution ``dist`` is defined as::\n",
      "\n",
      "                    ub\n",
      "            E[f(x)] = Integral(f(x) * dist.pdf(x)),\n",
      "                    lb\n",
      "\n",
      "        where ``ub`` and ``lb`` are arguments and ``x`` has the ``dist.pdf(x)``\n",
      "        distribution. If the bounds ``lb`` and ``ub`` correspond to the\n",
      "        support of the distribution, e.g. ``[-inf, inf]`` in the default\n",
      "        case, then the integral is the unrestricted expectation of ``f(x)``.\n",
      "        Also, the function ``f(x)`` may be defined such that ``f(x)`` is ``0``\n",
      "        outside a finite interval in which case the expectation is\n",
      "        calculated within the finite range ``[lb, ub]``.\n",
      "\n",
      "        Parameters\n",
      "        ----------\n",
      "        func : callable, optional\n",
      "            Function for which integral is calculated. Takes only one argument.\n",
      "            The default is the identity mapping f(x) = x.\n",
      "        args : tuple, optional\n",
      "            Shape parameters of the distribution.\n",
      "        loc : float, optional\n",
      "            Location parameter (default=0).\n",
      "        scale : float, optional\n",
      "            Scale parameter (default=1).\n",
      "        lb, ub : scalar, optional\n",
      "            Lower and upper bound for integration. Default is set to the\n",
      "            support of the distribution.\n",
      "        conditional : bool, optional\n",
      "            If True, the integral is corrected by the conditional probability\n",
      "            of the integration interval.  The return value is the expectation\n",
      "            of the function, conditional on being in the given interval.\n",
      "            Default is False.\n",
      "\n",
      "        Additional keyword arguments are passed to the integration routine.\n",
      "\n",
      "        Returns\n",
      "        -------\n",
      "        expect : float\n",
      "            The calculated expected value.\n",
      "\n",
      "        Notes\n",
      "        -----\n",
      "        The integration behavior of this function is inherited from\n",
      "        `scipy.integrate.quad`. Neither this function nor\n",
      "        `scipy.integrate.quad` can verify whether the integral exists or is\n",
      "        finite. For example ``cauchy(0).mean()`` returns ``np.nan`` and\n",
      "        ``cauchy(0).expect()`` returns ``0.0``.\n",
      "\n",
      "        The function is not vectorized.\n",
      "\n",
      "        Examples\n",
      "        --------\n",
      "\n",
      "        To understand the effect of the bounds of integration consider\n",
      "        \n",
      "        >>> from scipy.stats import expon\n",
      "        >>> expon(1).expect(lambda x: 1, lb=0.0, ub=2.0)\n",
      "        0.6321205588285578\n",
      "\n",
      "        This is close to\n",
      "\n",
      "        >>> expon(1).cdf(2.0) - expon(1).cdf(0.0)\n",
      "        0.6321205588285577\n",
      "\n",
      "        If ``conditional=True``\n",
      "\n",
      "        >>> expon(1).expect(lambda x: 1, lb=0.0, ub=2.0, conditional=True)\n",
      "        1.0000000000000002\n",
      "\n",
      "        The slight deviation from 1 is due to numerical integration.\n",
      "        \"\"\"\n",
      "        lockwds = {'loc': loc,\n",
      "                   'scale': scale}\n",
      "        self._argcheck(*args)\n",
      "        _a, _b = self._get_support(*args)\n",
      "        if func is None:\n",
      "            def fun(x, *args):\n",
      "                return x * self.pdf(x, *args, **lockwds)\n",
      "        else:\n",
      "            def fun(x, *args):\n",
      "                return func(x) * self.pdf(x, *args, **lockwds)\n",
      "        if lb is None:\n",
      "            lb = loc + _a * scale\n",
      "        if ub is None:\n",
      "            ub = loc + _b * scale\n",
      "        if conditional:\n",
      "            invfac = (self.sf(lb, *args, **lockwds)\n",
      "                      - self.sf(ub, *args, **lockwds))\n",
      "        else:\n",
      "            invfac = 1.0\n",
      "        kwds['args'] = args\n",
      "        # Silence floating point warnings from integration.\n",
      "        with np.errstate(all='ignore'):\n",
      "            vals = integrate.quad(fun, lb, ub, **kwds)[0] / invfac\n",
      "        return vals\n",
      "\n",
      "\n",
      "# Helpers for the discrete distributions\n",
      "def _drv2_moment(self, n, *args):\n",
      "    \"\"\"Non-central moment of discrete distribution.\"\"\"\n",
      "    def fun(x):\n",
      "        return np.power(x, n) * self._pmf(x, *args)\n",
      "\n",
      "    _a, _b = self._get_support(*args)\n",
      "    return _expect(fun, _a, _b, self.ppf(0.5, *args), self.inc)\n",
      "\n",
      "\n",
      "def _drv2_ppfsingle(self, q, *args):  # Use basic bisection algorithm\n",
      "    _a, _b = self._get_support(*args)\n",
      "    b = _b\n",
      "    a = _a\n",
      "    if isinf(b):            # Be sure ending point is > q\n",
      "        b = int(max(100*q, 10))\n",
      "        while 1:\n",
      "            if b >= _b:\n",
      "                qb = 1.0\n",
      "                break\n",
      "            qb = self._cdf(b, *args)\n",
      "            if (qb < q):\n",
      "                b += 10\n",
      "            else:\n",
      "                break\n",
      "    else:\n",
      "        qb = 1.0\n",
      "    if isinf(a):    # be sure starting point < q\n",
      "        a = int(min(-100*q, -10))\n",
      "        while 1:\n",
      "            if a <= _a:\n",
      "                qb = 0.0\n",
      "                break\n",
      "            qa = self._cdf(a, *args)\n",
      "            if (qa > q):\n",
      "                a -= 10\n",
      "            else:\n",
      "                break\n",
      "    else:\n",
      "        qa = self._cdf(a, *args)\n",
      "\n",
      "    while 1:\n",
      "        if (qa == q):\n",
      "            return a\n",
      "        if (qb == q):\n",
      "            return b\n",
      "        if b <= a+1:\n",
      "            if qa > q:\n",
      "                return a\n",
      "            else:\n",
      "                return b\n",
      "        c = int((a+b)/2.0)\n",
      "        qc = self._cdf(c, *args)\n",
      "        if (qc < q):\n",
      "            if a != c:\n",
      "                a = c\n",
      "            else:\n",
      "                raise RuntimeError('updating stopped, endless loop')\n",
      "            qa = qc\n",
      "        elif (qc > q):\n",
      "            if b != c:\n",
      "                b = c\n",
      "            else:\n",
      "                raise RuntimeError('updating stopped, endless loop')\n",
      "            qb = qc\n",
      "        else:\n",
      "            return c\n",
      "\n",
      "\n",
      "def entropy(pk, qk=None, base=None, axis=0):\n",
      "    \"\"\"Calculate the entropy of a distribution for given probability values.\n",
      "\n",
      "    If only probabilities `pk` are given, the entropy is calculated as\n",
      "    ``S = -sum(pk * log(pk), axis=axis)``.\n",
      "\n",
      "    If `qk` is not None, then compute the Kullback-Leibler divergence\n",
      "    ``S = sum(pk * log(pk / qk), axis=axis)``.\n",
      "\n",
      "    This routine will normalize `pk` and `qk` if they don't sum to 1.\n",
      "\n",
      "    Parameters\n",
      "    ----------\n",
      "    pk : sequence\n",
      "        Defines the (discrete) distribution. ``pk[i]`` is the (possibly\n",
      "        unnormalized) probability of event ``i``.\n",
      "    qk : sequence, optional\n",
      "        Sequence against which the relative entropy is computed. Should be in\n",
      "        the same format as `pk`.\n",
      "    base : float, optional\n",
      "        The logarithmic base to use, defaults to ``e`` (natural logarithm).\n",
      "    axis: int, optional\n",
      "        The axis along which the entropy is calculated. Default is 0.\n",
      "\n",
      "    Returns\n",
      "    -------\n",
      "    S : float\n",
      "        The calculated entropy.\n",
      "\n",
      "    Examples\n",
      "    --------\n",
      "\n",
      "    >>> from scipy.stats import entropy\n",
      "\n",
      "    Bernoulli trial with different p.\n",
      "    The outcome of a fair coin is the most uncertain:\n",
      "\n",
      "    >>> entropy([1/2, 1/2], base=2)\n",
      "    1.0\n",
      "\n",
      "    The outcome of a biased coin is less uncertain:\n",
      "\n",
      "    >>> entropy([9/10, 1/10], base=2)\n",
      "    0.46899559358928117\n",
      "\n",
      "    Relative entropy:\n",
      "\n",
      "    >>> entropy([1/2, 1/2], qk=[9/10, 1/10])\n",
      "    0.5108256237659907\n",
      "\n",
      "    \"\"\"\n",
      "    pk = asarray(pk)\n",
      "    pk = 1.0*pk / np.sum(pk, axis=axis, keepdims=True)\n",
      "    if qk is None:\n",
      "        vec = entr(pk)\n",
      "    else:\n",
      "        qk = asarray(qk)\n",
      "        if qk.shape != pk.shape:\n",
      "            raise ValueError(\"qk and pk must have same shape.\")\n",
      "        qk = 1.0*qk / np.sum(qk, axis=axis, keepdims=True)\n",
      "        vec = rel_entr(pk, qk)\n",
      "    S = np.sum(vec, axis=axis)\n",
      "    if base is not None:\n",
      "        S /= log(base)\n",
      "    return S\n",
      "\n",
      "\n",
      "# Must over-ride one of _pmf or _cdf or pass in\n",
      "#  x_k, p(x_k) lists in initialization\n",
      "\n",
      "class rv_discrete(rv_generic):\n",
      "    \"\"\"\n",
      "    A generic discrete random variable class meant for subclassing.\n",
      "\n",
      "    `rv_discrete` is a base class to construct specific distribution classes\n",
      "    and instances for discrete random variables. It can also be used\n",
      "    to construct an arbitrary distribution defined by a list of support\n",
      "    points and corresponding probabilities.\n",
      "\n",
      "    Parameters\n",
      "    ----------\n",
      "    a : float, optional\n",
      "        Lower bound of the support of the distribution, default: 0\n",
      "    b : float, optional\n",
      "        Upper bound of the support of the distribution, default: plus infinity\n",
      "    moment_tol : float, optional\n",
      "        The tolerance for the generic calculation of moments.\n",
      "    values : tuple of two array_like, optional\n",
      "        ``(xk, pk)`` where ``xk`` are integers and ``pk`` are the non-zero\n",
      "        probabilities between 0 and 1 with ``sum(pk) = 1``. ``xk``\n",
      "        and ``pk`` must have the same shape.\n",
      "    inc : integer, optional\n",
      "        Increment for the support of the distribution.\n",
      "        Default is 1. (other values have not been tested)\n",
      "    badvalue : float, optional\n",
      "        The value in a result arrays that indicates a value that for which\n",
      "        some argument restriction is violated, default is np.nan.\n",
      "    name : str, optional\n",
      "        The name of the instance. This string is used to construct the default\n",
      "        example for distributions.\n",
      "    longname : str, optional\n",
      "        This string is used as part of the first line of the docstring returned\n",
      "        when a subclass has no docstring of its own. Note: `longname` exists\n",
      "        for backwards compatibility, do not use for new subclasses.\n",
      "    shapes : str, optional\n",
      "        The shape of the distribution. For example \"m, n\" for a distribution\n",
      "        that takes two integers as the two shape arguments for all its methods\n",
      "        If not provided, shape parameters will be inferred from\n",
      "        the signatures of the private methods, ``_pmf`` and ``_cdf`` of\n",
      "        the instance.\n",
      "    extradoc :  str, optional\n",
      "        This string is used as the last part of the docstring returned when a\n",
      "        subclass has no docstring of its own. Note: `extradoc` exists for\n",
      "        backwards compatibility, do not use for new subclasses.\n",
      "    seed : {None, int, `~np.random.RandomState`, `~np.random.Generator`}, optional\n",
      "        This parameter defines the object to use for drawing random variates.\n",
      "        If `seed` is `None` the `~np.random.RandomState` singleton is used.\n",
      "        If `seed` is an int, a new ``RandomState`` instance is used, seeded\n",
      "        with seed.\n",
      "        If `seed` is already a ``RandomState`` or ``Generator`` instance,\n",
      "        then that object is used.\n",
      "        Default is None.\n",
      "\n",
      "    Methods\n",
      "    -------\n",
      "    rvs\n",
      "    pmf\n",
      "    logpmf\n",
      "    cdf\n",
      "    logcdf\n",
      "    sf\n",
      "    logsf\n",
      "    ppf\n",
      "    isf\n",
      "    moment\n",
      "    stats\n",
      "    entropy\n",
      "    expect\n",
      "    median\n",
      "    mean\n",
      "    std\n",
      "    var\n",
      "    interval\n",
      "    __call__\n",
      "    support\n",
      "\n",
      "\n",
      "    Notes\n",
      "    -----\n",
      "\n",
      "    This class is similar to `rv_continuous`. Whether a shape parameter is\n",
      "    valid is decided by an ``_argcheck`` method (which defaults to checking\n",
      "    that its arguments are strictly positive.)\n",
      "    The main differences are:\n",
      "\n",
      "    - the support of the distribution is a set of integers\n",
      "    - instead of the probability density function, ``pdf`` (and the\n",
      "      corresponding private ``_pdf``), this class defines the\n",
      "      *probability mass function*, `pmf` (and the corresponding\n",
      "      private ``_pmf``.)\n",
      "    - scale parameter is not defined.\n",
      "\n",
      "    To create a new discrete distribution, we would do the following:\n",
      "\n",
      "    >>> from scipy.stats import rv_discrete\n",
      "    >>> class poisson_gen(rv_discrete):\n",
      "    ...     \"Poisson distribution\"\n",
      "    ...     def _pmf(self, k, mu):\n",
      "    ...         return exp(-mu) * mu**k / factorial(k)\n",
      "\n",
      "    and create an instance::\n",
      "\n",
      "    >>> poisson = poisson_gen(name=\"poisson\")\n",
      "\n",
      "    Note that above we defined the Poisson distribution in the standard form.\n",
      "    Shifting the distribution can be done by providing the ``loc`` parameter\n",
      "    to the methods of the instance. For example, ``poisson.pmf(x, mu, loc)``\n",
      "    delegates the work to ``poisson._pmf(x-loc, mu)``.\n",
      "\n",
      "    **Discrete distributions from a list of probabilities**\n",
      "\n",
      "    Alternatively, you can construct an arbitrary discrete rv defined\n",
      "    on a finite set of values ``xk`` with ``Prob{X=xk} = pk`` by using the\n",
      "    ``values`` keyword argument to the `rv_discrete` constructor.\n",
      "\n",
      "    Examples\n",
      "    --------\n",
      "\n",
      "    Custom made discrete distribution:\n",
      "\n",
      "    >>> from scipy import stats\n",
      "    >>> xk = np.arange(7)\n",
      "    >>> pk = (0.1, 0.2, 0.3, 0.1, 0.1, 0.0, 0.2)\n",
      "    >>> custm = stats.rv_discrete(name='custm', values=(xk, pk))\n",
      "    >>>\n",
      "    >>> import matplotlib.pyplot as plt\n",
      "    >>> fig, ax = plt.subplots(1, 1)\n",
      "    >>> ax.plot(xk, custm.pmf(xk), 'ro', ms=12, mec='r')\n",
      "    >>> ax.vlines(xk, 0, custm.pmf(xk), colors='r', lw=4)\n",
      "    >>> plt.show()\n",
      "\n",
      "    Random number generation:\n",
      "\n",
      "    >>> R = custm.rvs(size=100)\n",
      "\n",
      "    \"\"\"\n",
      "    def __new__(cls, a=0, b=inf, name=None, badvalue=None,\n",
      "                moment_tol=1e-8, values=None, inc=1, longname=None,\n",
      "                shapes=None, extradoc=None, seed=None):\n",
      "\n",
      "        if values is not None:\n",
      "            # dispatch to a subclass\n",
      "            return super(rv_discrete, cls).__new__(rv_sample)\n",
      "        else:\n",
      "            # business as usual\n",
      "            return super(rv_discrete, cls).__new__(cls)\n",
      "\n",
      "    def __init__(self, a=0, b=inf, name=None, badvalue=None,\n",
      "                 moment_tol=1e-8, values=None, inc=1, longname=None,\n",
      "                 shapes=None, extradoc=None, seed=None):\n",
      "\n",
      "        super(rv_discrete, self).__init__(seed)\n",
      "\n",
      "        # cf generic freeze\n",
      "        self._ctor_param = dict(\n",
      "            a=a, b=b, name=name, badvalue=badvalue,\n",
      "            moment_tol=moment_tol, values=values, inc=inc,\n",
      "            longname=longname, shapes=shapes, extradoc=extradoc, seed=seed)\n",
      "\n",
      "        if badvalue is None:\n",
      "            badvalue = nan\n",
      "        self.badvalue = badvalue\n",
      "        self.a = a\n",
      "        self.b = b\n",
      "        self.moment_tol = moment_tol\n",
      "        self.inc = inc\n",
      "        self._cdfvec = vectorize(self._cdf_single, otypes='d')\n",
      "        self.vecentropy = vectorize(self._entropy)\n",
      "        self.shapes = shapes\n",
      "\n",
      "        if values is not None:\n",
      "            raise ValueError(\"rv_discrete.__init__(..., values != None, ...)\")\n",
      "\n",
      "        self._construct_argparser(meths_to_inspect=[self._pmf, self._cdf],\n",
      "                                  locscale_in='loc=0',\n",
      "                                  # scale=1 for discrete RVs\n",
      "                                  locscale_out='loc, 1')\n",
      "\n",
      "        # nin correction needs to be after we know numargs\n",
      "        # correct nin for generic moment vectorization\n",
      "        _vec_generic_moment = vectorize(_drv2_moment, otypes='d')\n",
      "        _vec_generic_moment.nin = self.numargs + 2\n",
      "        self.generic_moment = types.MethodType(_vec_generic_moment, self)\n",
      "\n",
      "        # correct nin for ppf vectorization\n",
      "        _vppf = vectorize(_drv2_ppfsingle, otypes='d')\n",
      "        _vppf.nin = self.numargs + 2\n",
      "        self._ppfvec = types.MethodType(_vppf, self)\n",
      "\n",
      "        # now that self.numargs is defined, we can adjust nin\n",
      "        self._cdfvec.nin = self.numargs + 1\n",
      "\n",
      "        self._construct_docstrings(name, longname, extradoc)\n",
      "\n",
      "    def _construct_docstrings(self, name, longname, extradoc):\n",
      "        if name is None:\n",
      "            name = 'Distribution'\n",
      "        self.name = name\n",
      "        self.extradoc = extradoc\n",
      "\n",
      "        # generate docstring for subclass instances\n",
      "        if longname is None:\n",
      "            if name[0] in ['aeiouAEIOU']:\n",
      "                hstr = \"An \"\n",
      "            else:\n",
      "                hstr = \"A \"\n",
      "            longname = hstr + name\n",
      "\n",
      "        if sys.flags.optimize < 2:\n",
      "            # Skip adding docstrings if interpreter is run with -OO\n",
      "            if self.__doc__ is None:\n",
      "                self._construct_default_doc(longname=longname,\n",
      "                                            extradoc=extradoc,\n",
      "                                            docdict=docdict_discrete,\n",
      "                                            discrete='discrete')\n",
      "            else:\n",
      "                dct = dict(distdiscrete)\n",
      "                self._construct_doc(docdict_discrete, dct.get(self.name))\n",
      "\n",
      "            # discrete RV do not have the scale parameter, remove it\n",
      "            self.__doc__ = self.__doc__.replace(\n",
      "                '\\n    scale : array_like, '\n",
      "                'optional\\n        scale parameter (default=1)', '')\n",
      "\n",
      "    def _updated_ctor_param(self):\n",
      "        \"\"\" Return the current version of _ctor_param, possibly updated by user.\n",
      "\n",
      "            Used by freezing and pickling.\n",
      "            Keep this in sync with the signature of __init__.\n",
      "        \"\"\"\n",
      "        dct = self._ctor_param.copy()\n",
      "        dct['a'] = self.a\n",
      "        dct['b'] = self.b\n",
      "        dct['badvalue'] = self.badvalue\n",
      "        dct['moment_tol'] = self.moment_tol\n",
      "        dct['inc'] = self.inc\n",
      "        dct['name'] = self.name\n",
      "        dct['shapes'] = self.shapes\n",
      "        dct['extradoc'] = self.extradoc\n",
      "        return dct\n",
      "\n",
      "    def _nonzero(self, k, *args):\n",
      "        return floor(k) == k\n",
      "\n",
      "    def _pmf(self, k, *args):\n",
      "        return self._cdf(k, *args) - self._cdf(k-1, *args)\n",
      "\n",
      "    def _logpmf(self, k, *args):\n",
      "        return log(self._pmf(k, *args))\n",
      "\n",
      "    def _cdf_single(self, k, *args):\n",
      "        _a, _b = self._get_support(*args)\n",
      "        m = arange(int(_a), k+1)\n",
      "        return np.sum(self._pmf(m, *args), axis=0)\n",
      "\n",
      "    def _cdf(self, x, *args):\n",
      "        k = floor(x)\n",
      "        return self._cdfvec(k, *args)\n",
      "\n",
      "    # generic _logcdf, _sf, _logsf, _ppf, _isf, _rvs defined in rv_generic\n",
      "\n",
      "    def rvs(self, *args, **kwargs):\n",
      "        \"\"\"\n",
      "        Random variates of given type.\n",
      "\n",
      "        Parameters\n",
      "        ----------\n",
      "        arg1, arg2, arg3,... : array_like\n",
      "            The shape parameter(s) for the distribution (see docstring of the\n",
      "            instance object for more information).\n",
      "        loc : array_like, optional\n",
      "            Location parameter (default=0).\n",
      "        size : int or tuple of ints, optional\n",
      "            Defining number of random variates (Default is 1).  Note that `size`\n",
      "            has to be given as keyword, not as positional argument.\n",
      "        random_state : {None, int, `~np.random.RandomState`, `~np.random.Generator`}, optional\n",
      "            This parameter defines the object to use for drawing random\n",
      "            variates.\n",
      "            If `random_state` is `None` the `~np.random.RandomState` singleton\n",
      "            is used.\n",
      "            If `random_state` is an int, a new ``RandomState`` instance is used,\n",
      "            seeded with random_state.\n",
      "            If `random_state` is already a ``RandomState`` or ``Generator``\n",
      "            instance, then that object is used.\n",
      "            Default is None.\n",
      "\n",
      "        Returns\n",
      "        -------\n",
      "        rvs : ndarray or scalar\n",
      "            Random variates of given `size`.\n",
      "\n",
      "        \"\"\"\n",
      "        kwargs['discrete'] = True\n",
      "        return super(rv_discrete, self).rvs(*args, **kwargs)\n",
      "\n",
      "    def pmf(self, k, *args, **kwds):\n",
      "        \"\"\"\n",
      "        Probability mass function at k of the given RV.\n",
      "\n",
      "        Parameters\n",
      "        ----------\n",
      "        k : array_like\n",
      "            Quantiles.\n",
      "        arg1, arg2, arg3,... : array_like\n",
      "            The shape parameter(s) for the distribution (see docstring of the\n",
      "            instance object for more information)\n",
      "        loc : array_like, optional\n",
      "            Location parameter (default=0).\n",
      "\n",
      "        Returns\n",
      "        -------\n",
      "        pmf : array_like\n",
      "            Probability mass function evaluated at k\n",
      "\n",
      "        \"\"\"\n",
      "        args, loc, _ = self._parse_args(*args, **kwds)\n",
      "        k, loc = map(asarray, (k, loc))\n",
      "        args = tuple(map(asarray, args))\n",
      "        _a, _b = self._get_support(*args)\n",
      "        k = asarray((k-loc))\n",
      "        cond0 = self._argcheck(*args)\n",
      "        cond1 = (k >= _a) & (k <= _b) & self._nonzero(k, *args)\n",
      "        cond = cond0 & cond1\n",
      "        output = zeros(shape(cond), 'd')\n",
      "        place(output, (1-cond0) + np.isnan(k), self.badvalue)\n",
      "        if np.any(cond):\n",
      "            goodargs = argsreduce(cond, *((k,)+args))\n",
      "            place(output, cond, np.clip(self._pmf(*goodargs), 0, 1))\n",
      "        if output.ndim == 0:\n",
      "            return output[()]\n",
      "        return output\n",
      "\n",
      "    def logpmf(self, k, *args, **kwds):\n",
      "        \"\"\"\n",
      "        Log of the probability mass function at k of the given RV.\n",
      "\n",
      "        Parameters\n",
      "        ----------\n",
      "        k : array_like\n",
      "            Quantiles.\n",
      "        arg1, arg2, arg3,... : array_like\n",
      "            The shape parameter(s) for the distribution (see docstring of the\n",
      "            instance object for more information).\n",
      "        loc : array_like, optional\n",
      "            Location parameter. Default is 0.\n",
      "\n",
      "        Returns\n",
      "        -------\n",
      "        logpmf : array_like\n",
      "            Log of the probability mass function evaluated at k.\n",
      "\n",
      "        \"\"\"\n",
      "        args, loc, _ = self._parse_args(*args, **kwds)\n",
      "        k, loc = map(asarray, (k, loc))\n",
      "        args = tuple(map(asarray, args))\n",
      "        _a, _b = self._get_support(*args)\n",
      "        k = asarray((k-loc))\n",
      "        cond0 = self._argcheck(*args)\n",
      "        cond1 = (k >= _a) & (k <= _b) & self._nonzero(k, *args)\n",
      "        cond = cond0 & cond1\n",
      "        output = empty(shape(cond), 'd')\n",
      "        output.fill(NINF)\n",
      "        place(output, (1-cond0) + np.isnan(k), self.badvalue)\n",
      "        if np.any(cond):\n",
      "            goodargs = argsreduce(cond, *((k,)+args))\n",
      "            place(output, cond, self._logpmf(*goodargs))\n",
      "        if output.ndim == 0:\n",
      "            return output[()]\n",
      "        return output\n",
      "\n",
      "    def cdf(self, k, *args, **kwds):\n",
      "        \"\"\"\n",
      "        Cumulative distribution function of the given RV.\n",
      "\n",
      "        Parameters\n",
      "        ----------\n",
      "        k : array_like, int\n",
      "            Quantiles.\n",
      "        arg1, arg2, arg3,... : array_like\n",
      "            The shape parameter(s) for the distribution (see docstring of the\n",
      "            instance object for more information).\n",
      "        loc : array_like, optional\n",
      "            Location parameter (default=0).\n",
      "\n",
      "        Returns\n",
      "        -------\n",
      "        cdf : ndarray\n",
      "            Cumulative distribution function evaluated at `k`.\n",
      "\n",
      "        \"\"\"\n",
      "        args, loc, _ = self._parse_args(*args, **kwds)\n",
      "        k, loc = map(asarray, (k, loc))\n",
      "        args = tuple(map(asarray, args))\n",
      "        _a, _b = self._get_support(*args)\n",
      "        k = asarray((k-loc))\n",
      "        cond0 = self._argcheck(*args)\n",
      "        cond1 = (k >= _a) & (k < _b)\n",
      "        cond2 = (k >= _b)\n",
      "        cond = cond0 & cond1\n",
      "        output = zeros(shape(cond), 'd')\n",
      "        place(output, (1-cond0) + np.isnan(k), self.badvalue)\n",
      "        place(output, cond2*(cond0 == cond0), 1.0)\n",
      "\n",
      "        if np.any(cond):\n",
      "            goodargs = argsreduce(cond, *((k,)+args))\n",
      "            place(output, cond, np.clip(self._cdf(*goodargs), 0, 1))\n",
      "        if output.ndim == 0:\n",
      "            return output[()]\n",
      "        return output\n",
      "\n",
      "    def logcdf(self, k, *args, **kwds):\n",
      "        \"\"\"\n",
      "        Log of the cumulative distribution function at k of the given RV.\n",
      "\n",
      "        Parameters\n",
      "        ----------\n",
      "        k : array_like, int\n",
      "            Quantiles.\n",
      "        arg1, arg2, arg3,... : array_like\n",
      "            The shape parameter(s) for the distribution (see docstring of the\n",
      "            instance object for more information).\n",
      "        loc : array_like, optional\n",
      "            Location parameter (default=0).\n",
      "\n",
      "        Returns\n",
      "        -------\n",
      "        logcdf : array_like\n",
      "            Log of the cumulative distribution function evaluated at k.\n",
      "\n",
      "        \"\"\"\n",
      "        args, loc, _ = self._parse_args(*args, **kwds)\n",
      "        k, loc = map(asarray, (k, loc))\n",
      "        args = tuple(map(asarray, args))\n",
      "        _a, _b = self._get_support(*args)\n",
      "        k = asarray((k-loc))\n",
      "        cond0 = self._argcheck(*args)\n",
      "        cond1 = (k >= _a) & (k < _b)\n",
      "        cond2 = (k >= _b)\n",
      "        cond = cond0 & cond1\n",
      "        output = empty(shape(cond), 'd')\n",
      "        output.fill(NINF)\n",
      "        place(output, (1-cond0) + np.isnan(k), self.badvalue)\n",
      "        place(output, cond2*(cond0 == cond0), 0.0)\n",
      "\n",
      "        if np.any(cond):\n",
      "            goodargs = argsreduce(cond, *((k,)+args))\n",
      "            place(output, cond, self._logcdf(*goodargs))\n",
      "        if output.ndim == 0:\n",
      "            return output[()]\n",
      "        return output\n",
      "\n",
      "    def sf(self, k, *args, **kwds):\n",
      "        \"\"\"\n",
      "        Survival function (1 - `cdf`) at k of the given RV.\n",
      "\n",
      "        Parameters\n",
      "        ----------\n",
      "        k : array_like\n",
      "            Quantiles.\n",
      "        arg1, arg2, arg3,... : array_like\n",
      "            The shape parameter(s) for the distribution (see docstring of the\n",
      "            instance object for more information).\n",
      "        loc : array_like, optional\n",
      "            Location parameter (default=0).\n",
      "\n",
      "        Returns\n",
      "        -------\n",
      "        sf : array_like\n",
      "            Survival function evaluated at k.\n",
      "\n",
      "        \"\"\"\n",
      "        args, loc, _ = self._parse_args(*args, **kwds)\n",
      "        k, loc = map(asarray, (k, loc))\n",
      "        args = tuple(map(asarray, args))\n",
      "        _a, _b = self._get_support(*args)\n",
      "        k = asarray(k-loc)\n",
      "        cond0 = self._argcheck(*args)\n",
      "        cond1 = (k >= _a) & (k < _b)\n",
      "        cond2 = (k < _a) & cond0\n",
      "        cond = cond0 & cond1\n",
      "        output = zeros(shape(cond), 'd')\n",
      "        place(output, (1-cond0) + np.isnan(k), self.badvalue)\n",
      "        place(output, cond2, 1.0)\n",
      "        if np.any(cond):\n",
      "            goodargs = argsreduce(cond, *((k,)+args))\n",
      "            place(output, cond, np.clip(self._sf(*goodargs), 0, 1))\n",
      "        if output.ndim == 0:\n",
      "            return output[()]\n",
      "        return output\n",
      "\n",
      "    def logsf(self, k, *args, **kwds):\n",
      "        \"\"\"\n",
      "        Log of the survival function of the given RV.\n",
      "\n",
      "        Returns the log of the \"survival function,\" defined as 1 - `cdf`,\n",
      "        evaluated at `k`.\n",
      "\n",
      "        Parameters\n",
      "        ----------\n",
      "        k : array_like\n",
      "            Quantiles.\n",
      "        arg1, arg2, arg3,... : array_like\n",
      "            The shape parameter(s) for the distribution (see docstring of the\n",
      "            instance object for more information).\n",
      "        loc : array_like, optional\n",
      "            Location parameter (default=0).\n",
      "\n",
      "        Returns\n",
      "        -------\n",
      "        logsf : ndarray\n",
      "            Log of the survival function evaluated at `k`.\n",
      "\n",
      "        \"\"\"\n",
      "        args, loc, _ = self._parse_args(*args, **kwds)\n",
      "        k, loc = map(asarray, (k, loc))\n",
      "        args = tuple(map(asarray, args))\n",
      "        _a, _b = self._get_support(*args)\n",
      "        k = asarray(k-loc)\n",
      "        cond0 = self._argcheck(*args)\n",
      "        cond1 = (k >= _a) & (k < _b)\n",
      "        cond2 = (k < _a) & cond0\n",
      "        cond = cond0 & cond1\n",
      "        output = empty(shape(cond), 'd')\n",
      "        output.fill(NINF)\n",
      "        place(output, (1-cond0) + np.isnan(k), self.badvalue)\n",
      "        place(output, cond2, 0.0)\n",
      "        if np.any(cond):\n",
      "            goodargs = argsreduce(cond, *((k,)+args))\n",
      "            place(output, cond, self._logsf(*goodargs))\n",
      "        if output.ndim == 0:\n",
      "            return output[()]\n",
      "        return output\n",
      "\n",
      "    def ppf(self, q, *args, **kwds):\n",
      "        \"\"\"\n",
      "        Percent point function (inverse of `cdf`) at q of the given RV.\n",
      "\n",
      "        Parameters\n",
      "        ----------\n",
      "        q : array_like\n",
      "            Lower tail probability.\n",
      "        arg1, arg2, arg3,... : array_like\n",
      "            The shape parameter(s) for the distribution (see docstring of the\n",
      "            instance object for more information).\n",
      "        loc : array_like, optional\n",
      "            Location parameter (default=0).\n",
      "\n",
      "        Returns\n",
      "        -------\n",
      "        k : array_like\n",
      "            Quantile corresponding to the lower tail probability, q.\n",
      "\n",
      "        \"\"\"\n",
      "        args, loc, _ = self._parse_args(*args, **kwds)\n",
      "        q, loc = map(asarray, (q, loc))\n",
      "        args = tuple(map(asarray, args))\n",
      "        _a, _b = self._get_support(*args)\n",
      "        cond0 = self._argcheck(*args) & (loc == loc)\n",
      "        cond1 = (q > 0) & (q < 1)\n",
      "        cond2 = (q == 1) & cond0\n",
      "        cond = cond0 & cond1\n",
      "        output = valarray(shape(cond), value=self.badvalue, typecode='d')\n",
      "        # output type 'd' to handle nin and inf\n",
      "        place(output, (q == 0)*(cond == cond), _a-1 + loc)\n",
      "        place(output, cond2, _b + loc)\n",
      "        if np.any(cond):\n",
      "            goodargs = argsreduce(cond, *((q,)+args+(loc,)))\n",
      "            loc, goodargs = goodargs[-1], goodargs[:-1]\n",
      "            place(output, cond, self._ppf(*goodargs) + loc)\n",
      "\n",
      "        if output.ndim == 0:\n",
      "            return output[()]\n",
      "        return output\n",
      "\n",
      "    def isf(self, q, *args, **kwds):\n",
      "        \"\"\"\n",
      "        Inverse survival function (inverse of `sf`) at q of the given RV.\n",
      "\n",
      "        Parameters\n",
      "        ----------\n",
      "        q : array_like\n",
      "            Upper tail probability.\n",
      "        arg1, arg2, arg3,... : array_like\n",
      "            The shape parameter(s) for the distribution (see docstring of the\n",
      "            instance object for more information).\n",
      "        loc : array_like, optional\n",
      "            Location parameter (default=0).\n",
      "\n",
      "        Returns\n",
      "        -------\n",
      "        k : ndarray or scalar\n",
      "            Quantile corresponding to the upper tail probability, q.\n",
      "\n",
      "        \"\"\"\n",
      "        args, loc, _ = self._parse_args(*args, **kwds)\n",
      "        q, loc = map(asarray, (q, loc))\n",
      "        args = tuple(map(asarray, args))\n",
      "        _a, _b = self._get_support(*args)\n",
      "        cond0 = self._argcheck(*args) & (loc == loc)\n",
      "        cond1 = (q > 0) & (q < 1)\n",
      "        cond2 = (q == 1) & cond0\n",
      "        cond = cond0 & cond1\n",
      "\n",
      "        # same problem as with ppf; copied from ppf and changed\n",
      "        output = valarray(shape(cond), value=self.badvalue, typecode='d')\n",
      "        # output type 'd' to handle nin and inf\n",
      "        place(output, (q == 0)*(cond == cond), _b)\n",
      "        place(output, cond2, _a-1)\n",
      "\n",
      "        # call place only if at least 1 valid argument\n",
      "        if np.any(cond):\n",
      "            goodargs = argsreduce(cond, *((q,)+args+(loc,)))\n",
      "            loc, goodargs = goodargs[-1], goodargs[:-1]\n",
      "            # PB same as ticket 766\n",
      "            place(output, cond, self._isf(*goodargs) + loc)\n",
      "\n",
      "        if output.ndim == 0:\n",
      "            return output[()]\n",
      "        return output\n",
      "\n",
      "    def _entropy(self, *args):\n",
      "        if hasattr(self, 'pk'):\n",
      "            return entropy(self.pk)\n",
      "        else:\n",
      "            _a, _b = self._get_support(*args)\n",
      "            return _expect(lambda x: entr(self.pmf(x, *args)),\n",
      "                           _a, _b, self.ppf(0.5, *args), self.inc)\n",
      "\n",
      "    def expect(self, func=None, args=(), loc=0, lb=None, ub=None,\n",
      "               conditional=False, maxcount=1000, tolerance=1e-10, chunksize=32):\n",
      "        \"\"\"\n",
      "        Calculate expected value of a function with respect to the distribution\n",
      "        for discrete distribution by numerical summation.\n",
      "\n",
      "        Parameters\n",
      "        ----------\n",
      "        func : callable, optional\n",
      "            Function for which the expectation value is calculated.\n",
      "            Takes only one argument.\n",
      "            The default is the identity mapping f(k) = k.\n",
      "        args : tuple, optional\n",
      "            Shape parameters of the distribution.\n",
      "        loc : float, optional\n",
      "            Location parameter.\n",
      "            Default is 0.\n",
      "        lb, ub : int, optional\n",
      "            Lower and upper bound for the summation, default is set to the\n",
      "            support of the distribution, inclusive (``ul <= k <= ub``).\n",
      "        conditional : bool, optional\n",
      "            If true then the expectation is corrected by the conditional\n",
      "            probability of the summation interval. The return value is the\n",
      "            expectation of the function, `func`, conditional on being in\n",
      "            the given interval (k such that ``ul <= k <= ub``).\n",
      "            Default is False.\n",
      "        maxcount : int, optional\n",
      "            Maximal number of terms to evaluate (to avoid an endless loop for\n",
      "            an infinite sum). Default is 1000.\n",
      "        tolerance : float, optional\n",
      "            Absolute tolerance for the summation. Default is 1e-10.\n",
      "        chunksize : int, optional\n",
      "            Iterate over the support of a distributions in chunks of this size.\n",
      "            Default is 32.\n",
      "\n",
      "        Returns\n",
      "        -------\n",
      "        expect : float\n",
      "            Expected value.\n",
      "\n",
      "        Notes\n",
      "        -----\n",
      "        For heavy-tailed distributions, the expected value may or may not exist,\n",
      "        depending on the function, `func`. If it does exist, but the sum converges\n",
      "        slowly, the accuracy of the result may be rather low. For instance, for\n",
      "        ``zipf(4)``, accuracy for mean, variance in example is only 1e-5.\n",
      "        increasing `maxcount` and/or `chunksize` may improve the result, but may\n",
      "        also make zipf very slow.\n",
      "\n",
      "        The function is not vectorized.\n",
      "\n",
      "        \"\"\"\n",
      "        if func is None:\n",
      "            def fun(x):\n",
      "                # loc and args from outer scope\n",
      "                return (x+loc)*self._pmf(x, *args)\n",
      "        else:\n",
      "            def fun(x):\n",
      "                # loc and args from outer scope\n",
      "                return func(x+loc)*self._pmf(x, *args)\n",
      "        # used pmf because _pmf does not check support in randint and there\n",
      "        # might be problems(?) with correct self.a, self.b at this stage maybe\n",
      "        # not anymore, seems to work now with _pmf\n",
      "\n",
      "        self._argcheck(*args)  # (re)generate scalar self.a and self.b\n",
      "        _a, _b = self._get_support(*args)\n",
      "        if lb is None:\n",
      "            lb = _a\n",
      "        else:\n",
      "            lb = lb - loc   # convert bound for standardized distribution\n",
      "        if ub is None:\n",
      "            ub = _b\n",
      "        else:\n",
      "            ub = ub - loc   # convert bound for standardized distribution\n",
      "        if conditional:\n",
      "            invfac = self.sf(lb-1, *args) - self.sf(ub, *args)\n",
      "        else:\n",
      "            invfac = 1.0\n",
      "\n",
      "        # iterate over the support, starting from the median\n",
      "        x0 = self.ppf(0.5, *args)\n",
      "        res = _expect(fun, lb, ub, x0, self.inc, maxcount, tolerance, chunksize)\n",
      "        return res / invfac\n",
      "\n",
      "\n",
      "def _expect(fun, lb, ub, x0, inc, maxcount=1000, tolerance=1e-10,\n",
      "            chunksize=32):\n",
      "    \"\"\"Helper for computing the expectation value of `fun`.\"\"\"\n",
      "\n",
      "    # short-circuit if the support size is small enough\n",
      "    if (ub - lb) <= chunksize:\n",
      "        supp = np.arange(lb, ub+1, inc)\n",
      "        vals = fun(supp)\n",
      "        return np.sum(vals)\n",
      "\n",
      "    # otherwise, iterate starting from x0\n",
      "    if x0 < lb:\n",
      "        x0 = lb\n",
      "    if x0 > ub:\n",
      "        x0 = ub\n",
      "\n",
      "    count, tot = 0, 0.\n",
      "    # iterate over [x0, ub] inclusive\n",
      "    for x in _iter_chunked(x0, ub+1, chunksize=chunksize, inc=inc):\n",
      "        count += x.size\n",
      "        delta = np.sum(fun(x))\n",
      "        tot += delta\n",
      "        if abs(delta) < tolerance * x.size:\n",
      "            break\n",
      "        if count > maxcount:\n",
      "            warnings.warn('expect(): sum did not converge', RuntimeWarning)\n",
      "            return tot\n",
      "\n",
      "    # iterate over [lb, x0)\n",
      "    for x in _iter_chunked(x0-1, lb-1, chunksize=chunksize, inc=-inc):\n",
      "        count += x.size\n",
      "        delta = np.sum(fun(x))\n",
      "        tot += delta\n",
      "        if abs(delta) < tolerance * x.size:\n",
      "            break\n",
      "        if count > maxcount:\n",
      "            warnings.warn('expect(): sum did not converge', RuntimeWarning)\n",
      "            break\n",
      "\n",
      "    return tot\n",
      "\n",
      "\n",
      "def _iter_chunked(x0, x1, chunksize=4, inc=1):\n",
      "    \"\"\"Iterate from x0 to x1 in chunks of chunksize and steps inc.\n",
      "\n",
      "    x0 must be finite, x1 need not be. In the latter case, the iterator is\n",
      "    infinite.\n",
      "    Handles both x0 < x1 and x0 > x1. In the latter case, iterates downwards\n",
      "    (make sure to set inc < 0.)\n",
      "\n",
      "    >>> [x for x in _iter_chunked(2, 5, inc=2)]\n",
      "    [array([2, 4])]\n",
      "    >>> [x for x in _iter_chunked(2, 11, inc=2)]\n",
      "    [array([2, 4, 6, 8]), array([10])]\n",
      "    >>> [x for x in _iter_chunked(2, -5, inc=-2)]\n",
      "    [array([ 2,  0, -2, -4])]\n",
      "    >>> [x for x in _iter_chunked(2, -9, inc=-2)]\n",
      "    [array([ 2,  0, -2, -4]), array([-6, -8])]\n",
      "\n",
      "    \"\"\"\n",
      "    if inc == 0:\n",
      "        raise ValueError('Cannot increment by zero.')\n",
      "    if chunksize <= 0:\n",
      "        raise ValueError('Chunk size must be positive; got %s.' % chunksize)\n",
      "\n",
      "    s = 1 if inc > 0 else -1\n",
      "    stepsize = abs(chunksize * inc)\n",
      "\n",
      "    x = x0\n",
      "    while (x - x1) * inc < 0:\n",
      "        delta = min(stepsize, abs(x - x1))\n",
      "        step = delta * s\n",
      "        supp = np.arange(x, x + step, inc)\n",
      "        x += step\n",
      "        yield supp\n",
      "\n",
      "\n",
      "class rv_sample(rv_discrete):\n",
      "    \"\"\"A 'sample' discrete distribution defined by the support and values.\n",
      "\n",
      "       The ctor ignores most of the arguments, only needs the `values` argument.\n",
      "    \"\"\"\n",
      "    def __init__(self, a=0, b=inf, name=None, badvalue=None,\n",
      "                 moment_tol=1e-8, values=None, inc=1, longname=None,\n",
      "                 shapes=None, extradoc=None, seed=None):\n",
      "\n",
      "        super(rv_discrete, self).__init__(seed)\n",
      "\n",
      "        if values is None:\n",
      "            raise ValueError(\"rv_sample.__init__(..., values=None,...)\")\n",
      "\n",
      "        # cf generic freeze\n",
      "        self._ctor_param = dict(\n",
      "            a=a, b=b, name=name, badvalue=badvalue,\n",
      "            moment_tol=moment_tol, values=values, inc=inc,\n",
      "            longname=longname, shapes=shapes, extradoc=extradoc, seed=seed)\n",
      "\n",
      "        if badvalue is None:\n",
      "            badvalue = nan\n",
      "        self.badvalue = badvalue\n",
      "        self.moment_tol = moment_tol\n",
      "        self.inc = inc\n",
      "        self.shapes = shapes\n",
      "        self.vecentropy = self._entropy\n",
      "\n",
      "        xk, pk = values\n",
      "\n",
      "        if np.shape(xk) != np.shape(pk):\n",
      "            raise ValueError(\"xk and pk must have the same shape.\")\n",
      "        if np.less(pk, 0.0).any():\n",
      "            raise ValueError(\"All elements of pk must be non-negative.\")\n",
      "        if not np.allclose(np.sum(pk), 1):\n",
      "            raise ValueError(\"The sum of provided pk is not 1.\")\n",
      "\n",
      "        indx = np.argsort(np.ravel(xk))\n",
      "        self.xk = np.take(np.ravel(xk), indx, 0)\n",
      "        self.pk = np.take(np.ravel(pk), indx, 0)\n",
      "        self.a = self.xk[0]\n",
      "        self.b = self.xk[-1]\n",
      "\n",
      "        self.qvals = np.cumsum(self.pk, axis=0)\n",
      "\n",
      "        self.shapes = ' '   # bypass inspection\n",
      "        self._construct_argparser(meths_to_inspect=[self._pmf],\n",
      "                                  locscale_in='loc=0',\n",
      "                                  # scale=1 for discrete RVs\n",
      "                                  locscale_out='loc, 1')\n",
      "\n",
      "        self._construct_docstrings(name, longname, extradoc)\n",
      "\n",
      "    def _get_support(self, *args):\n",
      "        \"\"\"Return the support of the (unscaled, unshifted) distribution.\n",
      "\n",
      "        Parameters\n",
      "        ----------\n",
      "        arg1, arg2, ... : array_like\n",
      "            The shape parameter(s) for the distribution (see docstring of the\n",
      "            instance object for more information).\n",
      "        Returns\n",
      "        -------\n",
      "        a, b : numeric (float, or int or +/-np.inf)\n",
      "            end-points of the distribution's support.\n",
      "        \"\"\"\n",
      "        return self.a, self.b\n",
      "\n",
      "    def _pmf(self, x):\n",
      "        return np.select([x == k for k in self.xk],\n",
      "                         [np.broadcast_arrays(p, x)[0] for p in self.pk], 0)\n",
      "\n",
      "    def _cdf(self, x):\n",
      "        xx, xxk = np.broadcast_arrays(x[:, None], self.xk)\n",
      "        indx = np.argmax(xxk > xx, axis=-1) - 1\n",
      "        return self.qvals[indx]\n",
      "\n",
      "    def _ppf(self, q):\n",
      "        qq, sqq = np.broadcast_arrays(q[..., None], self.qvals)\n",
      "        indx = argmax(sqq >= qq, axis=-1)\n",
      "        return self.xk[indx]\n",
      "\n",
      "    def _rvs(self, size=None, random_state=None):\n",
      "        # Need to define it explicitly, otherwise .rvs() with size=None\n",
      "        # fails due to explicit broadcasting in _ppf\n",
      "        U = random_state.uniform(size=size)\n",
      "        if size is None:\n",
      "            U = np.array(U, ndmin=1)\n",
      "            Y = self._ppf(U)[0]\n",
      "        else:\n",
      "            Y = self._ppf(U)\n",
      "        return Y\n",
      "\n",
      "    def _entropy(self):\n",
      "        return entropy(self.pk)\n",
      "\n",
      "    def generic_moment(self, n):\n",
      "        n = asarray(n)\n",
      "        return np.sum(self.xk**n[np.newaxis, ...] * self.pk, axis=0)\n",
      "\n",
      "\n",
      "def _check_shape(argshape, size):\n",
      "    \"\"\"\n",
      "    This is a utility function used by `_rvs()` in the class geninvgauss_gen.\n",
      "    It compares the tuple argshape to the tuple size.\n",
      "\n",
      "    Parameters\n",
      "    ----------\n",
      "    argshape : tuple of integers\n",
      "        Shape of the arguments.\n",
      "    size : tuple of integers or integer\n",
      "        Size argument of rvs().\n",
      "\n",
      "    Returns\n",
      "    -------\n",
      "    The function returns two tuples, scalar_shape and bc.\n",
      "\n",
      "    scalar_shape : tuple\n",
      "        Shape to which the 1-d array of random variates returned by\n",
      "        _rvs_scalar() is converted when it is copied into the\n",
      "        output array of _rvs().\n",
      "\n",
      "    bc : tuple of booleans\n",
      "        bc is an tuple the same length as size. bc[j] is True if the data\n",
      "        associated with that index is generated in one call of _rvs_scalar().\n",
      "\n",
      "    \"\"\"\n",
      "    scalar_shape = []\n",
      "    bc = []\n",
      "    for argdim, sizedim in zip_longest(argshape[::-1], size[::-1],\n",
      "                                       fillvalue=1):\n",
      "        if sizedim > argdim or (argdim == sizedim == 1):\n",
      "            scalar_shape.append(sizedim)\n",
      "            bc.append(True)\n",
      "        else:\n",
      "            bc.append(False)\n",
      "    return tuple(scalar_shape[::-1]), tuple(bc[::-1])\n",
      "\n",
      "\n",
      "def get_distribution_names(namespace_pairs, rv_base_class):\n",
      "    \"\"\"\n",
      "    Collect names of statistical distributions and their generators.\n",
      "\n",
      "    Parameters\n",
      "    ----------\n",
      "    namespace_pairs : sequence\n",
      "        A snapshot of (name, value) pairs in the namespace of a module.\n",
      "    rv_base_class : class\n",
      "        The base class of random variable generator classes in a module.\n",
      "\n",
      "    Returns\n",
      "    -------\n",
      "    distn_names : list of strings\n",
      "        Names of the statistical distributions.\n",
      "    distn_gen_names : list of strings\n",
      "        Names of the generators of the statistical distributions.\n",
      "        Note that these are not simply the names of the statistical\n",
      "        distributions, with a _gen suffix added.\n",
      "\n",
      "    \"\"\"\n",
      "    distn_names = []\n",
      "    distn_gen_names = []\n",
      "    for name, value in namespace_pairs:\n",
      "        if name.startswith('_'):\n",
      "            continue\n",
      "        if name.endswith('_gen') and issubclass(value, rv_base_class):\n",
      "            distn_gen_names.append(name)\n",
      "        if isinstance(value, rv_base_class):\n",
      "            distn_names.append(name)\n",
      "    return distn_names, distn_gen_names\n"
     ]
    }
   ],
   "source": [
    "%%script bash\n",
    "cat ~/anaconda3/lib/site-packages/scipy/stats/_distn_infrastructure.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "# END"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
